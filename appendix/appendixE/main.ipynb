{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "30700417-2534-4749-85c4-85f233599479",
   "metadata": {},
   "source": [
    "# Parameter-efficient fine-tuning with LoRA"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "871d6a05-bed6-4f9a-9e9f-538cd3967540",
   "metadata": {},
   "source": [
    "## Principle: replacing weights W with W+AB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c507ccbd-ad90-4c2c-a115-33c0da016646",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-12-12 15:48:52.168640: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "/home/phm1605/anaconda3/envs/python310/lib/python3.10/site-packages/google/protobuf/runtime_version.py:98: UserWarning: Protobuf gencode version 5.28.3 is exactly one major version older than the runtime version 6.31.1 at tensorflow/core/framework/attr_value.proto. Please update the gencode to avoid compatibility violations in the next runtime release.\n",
      "  warnings.warn(\n",
      "/home/phm1605/anaconda3/envs/python310/lib/python3.10/site-packages/google/protobuf/runtime_version.py:98: UserWarning: Protobuf gencode version 5.28.3 is exactly one major version older than the runtime version 6.31.1 at tensorflow/core/framework/tensor.proto. Please update the gencode to avoid compatibility violations in the next runtime release.\n",
      "  warnings.warn(\n",
      "/home/phm1605/anaconda3/envs/python310/lib/python3.10/site-packages/google/protobuf/runtime_version.py:98: UserWarning: Protobuf gencode version 5.28.3 is exactly one major version older than the runtime version 6.31.1 at tensorflow/core/framework/resource_handle.proto. Please update the gencode to avoid compatibility violations in the next runtime release.\n",
      "  warnings.warn(\n",
      "/home/phm1605/anaconda3/envs/python310/lib/python3.10/site-packages/google/protobuf/runtime_version.py:98: UserWarning: Protobuf gencode version 5.28.3 is exactly one major version older than the runtime version 6.31.1 at tensorflow/core/framework/tensor_shape.proto. Please update the gencode to avoid compatibility violations in the next runtime release.\n",
      "  warnings.warn(\n",
      "/home/phm1605/anaconda3/envs/python310/lib/python3.10/site-packages/google/protobuf/runtime_version.py:98: UserWarning: Protobuf gencode version 5.28.3 is exactly one major version older than the runtime version 6.31.1 at tensorflow/core/framework/types.proto. Please update the gencode to avoid compatibility violations in the next runtime release.\n",
      "  warnings.warn(\n",
      "/home/phm1605/anaconda3/envs/python310/lib/python3.10/site-packages/google/protobuf/runtime_version.py:98: UserWarning: Protobuf gencode version 5.28.3 is exactly one major version older than the runtime version 6.31.1 at tensorflow/core/framework/full_type.proto. Please update the gencode to avoid compatibility violations in the next runtime release.\n",
      "  warnings.warn(\n",
      "/home/phm1605/anaconda3/envs/python310/lib/python3.10/site-packages/google/protobuf/runtime_version.py:98: UserWarning: Protobuf gencode version 5.28.3 is exactly one major version older than the runtime version 6.31.1 at tensorflow/core/framework/function.proto. Please update the gencode to avoid compatibility violations in the next runtime release.\n",
      "  warnings.warn(\n",
      "/home/phm1605/anaconda3/envs/python310/lib/python3.10/site-packages/google/protobuf/runtime_version.py:98: UserWarning: Protobuf gencode version 5.28.3 is exactly one major version older than the runtime version 6.31.1 at tensorflow/core/framework/node_def.proto. Please update the gencode to avoid compatibility violations in the next runtime release.\n",
      "  warnings.warn(\n",
      "/home/phm1605/anaconda3/envs/python310/lib/python3.10/site-packages/google/protobuf/runtime_version.py:98: UserWarning: Protobuf gencode version 5.28.3 is exactly one major version older than the runtime version 6.31.1 at tensorflow/core/framework/op_def.proto. Please update the gencode to avoid compatibility violations in the next runtime release.\n",
      "  warnings.warn(\n",
      "/home/phm1605/anaconda3/envs/python310/lib/python3.10/site-packages/google/protobuf/runtime_version.py:98: UserWarning: Protobuf gencode version 5.28.3 is exactly one major version older than the runtime version 6.31.1 at tensorflow/core/framework/graph.proto. Please update the gencode to avoid compatibility violations in the next runtime release.\n",
      "  warnings.warn(\n",
      "/home/phm1605/anaconda3/envs/python310/lib/python3.10/site-packages/google/protobuf/runtime_version.py:98: UserWarning: Protobuf gencode version 5.28.3 is exactly one major version older than the runtime version 6.31.1 at tensorflow/core/framework/graph_debug_info.proto. Please update the gencode to avoid compatibility violations in the next runtime release.\n",
      "  warnings.warn(\n",
      "/home/phm1605/anaconda3/envs/python310/lib/python3.10/site-packages/google/protobuf/runtime_version.py:98: UserWarning: Protobuf gencode version 5.28.3 is exactly one major version older than the runtime version 6.31.1 at tensorflow/core/framework/versions.proto. Please update the gencode to avoid compatibility violations in the next runtime release.\n",
      "  warnings.warn(\n",
      "/home/phm1605/anaconda3/envs/python310/lib/python3.10/site-packages/google/protobuf/runtime_version.py:98: UserWarning: Protobuf gencode version 5.28.3 is exactly one major version older than the runtime version 6.31.1 at tensorflow/core/protobuf/config.proto. Please update the gencode to avoid compatibility violations in the next runtime release.\n",
      "  warnings.warn(\n",
      "/home/phm1605/anaconda3/envs/python310/lib/python3.10/site-packages/google/protobuf/runtime_version.py:98: UserWarning: Protobuf gencode version 5.28.3 is exactly one major version older than the runtime version 6.31.1 at xla/tsl/protobuf/coordination_config.proto. Please update the gencode to avoid compatibility violations in the next runtime release.\n",
      "  warnings.warn(\n",
      "/home/phm1605/anaconda3/envs/python310/lib/python3.10/site-packages/google/protobuf/runtime_version.py:98: UserWarning: Protobuf gencode version 5.28.3 is exactly one major version older than the runtime version 6.31.1 at tensorflow/core/framework/cost_graph.proto. Please update the gencode to avoid compatibility violations in the next runtime release.\n",
      "  warnings.warn(\n",
      "/home/phm1605/anaconda3/envs/python310/lib/python3.10/site-packages/google/protobuf/runtime_version.py:98: UserWarning: Protobuf gencode version 5.28.3 is exactly one major version older than the runtime version 6.31.1 at tensorflow/core/framework/step_stats.proto. Please update the gencode to avoid compatibility violations in the next runtime release.\n",
      "  warnings.warn(\n",
      "/home/phm1605/anaconda3/envs/python310/lib/python3.10/site-packages/google/protobuf/runtime_version.py:98: UserWarning: Protobuf gencode version 5.28.3 is exactly one major version older than the runtime version 6.31.1 at tensorflow/core/framework/allocation_description.proto. Please update the gencode to avoid compatibility violations in the next runtime release.\n",
      "  warnings.warn(\n",
      "/home/phm1605/anaconda3/envs/python310/lib/python3.10/site-packages/google/protobuf/runtime_version.py:98: UserWarning: Protobuf gencode version 5.28.3 is exactly one major version older than the runtime version 6.31.1 at tensorflow/core/framework/tensor_description.proto. Please update the gencode to avoid compatibility violations in the next runtime release.\n",
      "  warnings.warn(\n",
      "/home/phm1605/anaconda3/envs/python310/lib/python3.10/site-packages/google/protobuf/runtime_version.py:98: UserWarning: Protobuf gencode version 5.28.3 is exactly one major version older than the runtime version 6.31.1 at tensorflow/core/protobuf/cluster.proto. Please update the gencode to avoid compatibility violations in the next runtime release.\n",
      "  warnings.warn(\n",
      "/home/phm1605/anaconda3/envs/python310/lib/python3.10/site-packages/google/protobuf/runtime_version.py:98: UserWarning: Protobuf gencode version 5.28.3 is exactly one major version older than the runtime version 6.31.1 at tensorflow/core/protobuf/debug.proto. Please update the gencode to avoid compatibility violations in the next runtime release.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import tiktoken\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from gpt_download import download_and_load_gpt2\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cbf7cd70-f677-4c75-8456-1ad790ca360d",
   "metadata": {},
   "source": [
    "## Prepare dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fce1db1f-eebd-4f1d-8b32-fa7c6159f3c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SpamDataset(Dataset):\n",
    "    # csv_file: 2 columns of \"Label\" (0 or 1) and \"Text\" (string)\n",
    "    def __init__(self, csv_file, tokenizer, max_length=None, pad_token_id=50256):\n",
    "        self.data = pd.read_csv(csv_file)\n",
    "        # [[3,643,2], [7,1],...]\n",
    "        self.encoded_texts = [\n",
    "            tokenizer.encode(text) for text in self.data[\"Text\"]\n",
    "        ]\n",
    "        \n",
    "        if max_length is None:\n",
    "            self.max_length = self._longest_encoded_length()\n",
    "        else: # truncate sentence if too long\n",
    "            self.max_length = max_length\n",
    "            self.encoded_texts = [\n",
    "                encoded_text[:self.max_length]\n",
    "                for encoded_text in self.encoded_texts\n",
    "            ]\n",
    "        # pad sequence with <50256> to the length of longest sequence\n",
    "        self.encoded_texts = [\n",
    "            encoded_text + [pad_token_id]*(self.max_length-len(encoded_text))\n",
    "            for encoded_text in self.encoded_texts\n",
    "        ]\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        encoded = self.encoded_texts[index] # will have same length <max_length>\n",
    "        label = self.data.iloc[index][\"Label\"]\n",
    "        return (\n",
    "            torch.tensor(encoded, dtype=torch.long), # (max_length,)\n",
    "            torch.tensor(label, dtype=torch.long) # (1,)\n",
    "        )\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def _longest_encoded_length(self):\n",
    "        max_length = 0\n",
    "        for encoded_text in self.encoded_texts:\n",
    "            encoded_length = len(encoded_text)\n",
    "            if encoded_length > max_length:\n",
    "                max_length = encoded_length\n",
    "        return max_length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2c1bc4f8-cf23-4de2-beb4-6f09dd8a5173",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = tiktoken.get_encoding(\"gpt2\")\n",
    "train_dataset = SpamDataset(\"train.csv\", max_length=None, tokenizer=tokenizer)\n",
    "val_dataset = SpamDataset(\"validation.csv\", max_length=train_dataset.max_length, tokenizer=tokenizer)\n",
    "test_dataset = SpamDataset(\"test.csv\", max_length=train_dataset.max_length, tokenizer=tokenizer)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "836451a0-1d88-45de-9846-479249268d14",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_workers = 0\n",
    "batch_size = 8\n",
    "torch.manual_seed(123)\n",
    "train_loader = DataLoader(\n",
    "    dataset=train_dataset,\n",
    "    batch_size=batch_size,\n",
    "    shuffle=True,\n",
    "    num_workers=num_workers,\n",
    "    drop_last=True\n",
    ")\n",
    "val_loader = DataLoader(\n",
    "    dataset=val_dataset,\n",
    "    batch_size=batch_size,\n",
    "    num_workers=num_workers,\n",
    "    drop_last=False\n",
    ")\n",
    "test_loader = DataLoader(\n",
    "    dataset=test_dataset,\n",
    "    batch_size=batch_size,\n",
    "    num_workers=num_workers,\n",
    "    drop_last=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8ed02228-9276-4903-b6de-ce447364fe4f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loader:\n",
      "Input batch dimensions: torch.Size([8, 103])\n",
      "Label batch dimensions: torch.Size([8])\n"
     ]
    }
   ],
   "source": [
    "# Check if DataLoader works well for 1 batch\n",
    "print(\"Train loader:\")\n",
    "for input_batch, target_batch in train_loader:\n",
    "    pass \n",
    "print(\"Input batch dimensions:\", input_batch.shape) # (8,103)\n",
    "print(\"Label batch dimensions:\", target_batch.shape) # (8,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7eae3497-0419-47c0-ad5f-d2c55b2723b4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "130 training batches\n",
      "19 validation batches\n",
      "38 test batches\n"
     ]
    }
   ],
   "source": [
    "print(f\"{len(train_loader)} training batches\")\n",
    "print(f\"{len(val_loader)} validation batches\")\n",
    "print(f\"{len(test_loader)} test batches\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69a7ff87-5149-40d2-a7df-52b3a075f49b",
   "metadata": {},
   "source": [
    "## Initialize model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c98954f3-ba97-49ae-9ec3-fec2172f22e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LayerNorm(nn.Module):\n",
    "    def __init__(self, emb_dim):\n",
    "        super().__init__()\n",
    "        self.eps = 1e-5\n",
    "        # optional trainable params\n",
    "        self.scale = nn.Parameter(torch.ones(emb_dim))\n",
    "        self.shift = nn.Parameter(torch.zeros(emb_dim))\n",
    "    \n",
    "    def forward(self, x):\n",
    "        mean = x.mean(dim=-1, keepdim=True) # (batch,1)\n",
    "        # biased variance: divided by 1/(n-1)\n",
    "        # unbiased variance: divided by 1/n\n",
    "        var = x.var(dim=-1, keepdim=True, unbiased=False) # (batch,1)\n",
    "        norm_x = (x-mean) / torch.sqrt(var+self.eps) # (batch,emb_dim)\n",
    "        return self.scale * norm_x + self.shift # (batch,emb_dim)\n",
    "\n",
    "class GeLU(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "    \n",
    "    def forward(self, x):\n",
    "        return 0.5*x*(1+torch.tanh( torch.sqrt(torch.tensor(2.0/torch.pi))*(x+0.044715*torch.pow(x,3)) ))\n",
    "\n",
    "class FeedForward(nn.Module):\n",
    "    def __init__(self, cfg):\n",
    "        super().__init__()\n",
    "        self.layers = nn.Sequential(\n",
    "            nn.Linear(cfg[\"emb_dim\"], 4*cfg[\"emb_dim\"]),\n",
    "            GeLU(),\n",
    "            nn.Linear(4*cfg[\"emb_dim\"], cfg[\"emb_dim\"])\n",
    "        )\n",
    "    \n",
    "    def forward(self, x):\n",
    "        return self.layers(x)\n",
    "\n",
    "class MultiHeadAttention(nn.Module):\n",
    "    def __init__(self, d_in, d_out, context_length, dropout, num_heads, qkv_bias=False):\n",
    "        super().__init__()\n",
    "        assert (d_out % num_heads == 0), \"d_out must be divisible by num_heads\"\n",
    "        self.d_out = d_out # 4\n",
    "        self.num_heads = num_heads # 2\n",
    "        self.head_dim = d_out // num_heads # 2\n",
    "        \n",
    "        # bigger weight matrices\n",
    "        self.W_query = nn.Linear(d_in, d_out, bias=qkv_bias) # (3,4)\n",
    "        self.W_key = nn.Linear(d_in, d_out, bias=qkv_bias) # (3,4)\n",
    "        self.W_value = nn.Linear(d_in, d_out, bias=qkv_bias) # (3,4)\n",
    "        \n",
    "        self.out_proj = nn.Linear(d_out, d_out)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        self.register_buffer(\n",
    "            \"mask\",\n",
    "            torch.triu(torch.ones(context_length, context_length), diagonal=1)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        b, num_tokens, d_in = x.shape\n",
    "        \n",
    "        # compute big kqv matrices\n",
    "        keys = self.W_key(x) # (b,n,3)=>(b,n_token,4)\n",
    "        queries = self.W_query(x) # (b,n,3)=>(b,n_token,4)\n",
    "        values = self.W_value(x) # (b,n,3)=>(b,n_token,4)\n",
    "        # ... then splits\n",
    "        keys = keys.view(b, num_tokens, self.num_heads, self.head_dim) # (b,n_token,n_head=2,head_dim=2)\n",
    "        queries = queries.view(b, num_tokens, self.num_heads, self.head_dim) # (b,n_token,n_head,head_dim)\n",
    "        values = values.view(b, num_tokens, self.num_heads, self.head_dim) # (b,n_token,n_head,head_dim)\n",
    "        # swap <num_heads> to after-batch location\n",
    "        keys = keys.transpose(1,2) # (b,n_head=2,n_token,head_dim=2)\n",
    "        queries = queries.transpose(1,2) # (b,n_head=2,n_token,head_dim=2)\n",
    "        values = values.transpose(1,2) # (b,n_head=2,n_token,head_dim=2)\n",
    "\n",
    "        attn_scores = queries @ keys.transpose(2,3) # (b,n_head,n_token,head_dim)@(b,n_head,head_dim,n_token)=>(b,n_head,n_token,n_token)\n",
    "        mask_bool = self.mask.bool()[:num_tokens,:num_tokens]\n",
    "        attn_scores.masked_fill_(mask_bool, -torch.inf) # (n,n) with upper-right is -inf\n",
    "        attn_weights = torch.softmax(\n",
    "            attn_scores / keys.shape[-1]**0.5, dim=-1)\n",
    "        attn_weights = self.dropout(attn_weights) # (b,n_head,n_token,n_token)\n",
    "\n",
    "        context_vec = (attn_weights @ values).transpose(1,2) # (b,n_head,n_token,head_dim=2)=>transpose to (b,n_token,n_head,head_dim=2)\n",
    "        context_vec = context_vec.contiguous().view(b,num_tokens,self.d_out) # (b,n_token,n_head*head_dim)=(b,n_token,4)\n",
    "        context_vec = self.out_proj(context_vec) # (b,n_token,4)\n",
    "\n",
    "        return context_vec # (b,n_token,4)\n",
    "\n",
    "class TransformerBlock(nn.Module):\n",
    "    def __init__(self, cfg):\n",
    "        super().__init__()\n",
    "        self.att = MultiHeadAttention(\n",
    "            d_in=cfg[\"emb_dim\"],\n",
    "            d_out=cfg[\"emb_dim\"],\n",
    "            context_length=cfg[\"context_length\"],\n",
    "            num_heads=cfg[\"n_heads\"],\n",
    "            dropout=cfg[\"drop_rate\"],\n",
    "            qkv_bias=cfg[\"qkv_bias\"]\n",
    "        )\n",
    "        self.ff = FeedForward(cfg)\n",
    "        self.norm1 = LayerNorm(cfg[\"emb_dim\"])\n",
    "        self.norm2 = LayerNorm(cfg[\"emb_dim\"])\n",
    "        self.drop_shortcut = nn.Dropout(cfg[\"drop_rate\"])\n",
    "\n",
    "    def forward(self, x):\n",
    "        shortcut = x\n",
    "        x = self.norm1(x)\n",
    "        x = self.att(x)\n",
    "        x = self.drop_shortcut(x)\n",
    "        x = x + shortcut \n",
    "\n",
    "        shortcut = x\n",
    "        x = self.norm2(x)\n",
    "        x = self.ff(x)\n",
    "        x = self.drop_shortcut(x)\n",
    "        x = x + shortcut \n",
    "        return x \n",
    "\n",
    "class GPTModel(nn.Module):\n",
    "    def __init__(self, cfg):\n",
    "        super().__init__()\n",
    "        self.tok_emb = nn.Embedding(cfg[\"vocab_size\"], cfg[\"emb_dim\"])\n",
    "        self.pos_emb = nn.Embedding(cfg[\"context_length\"], cfg[\"emb_dim\"])\n",
    "        self.drop_emb = nn.Dropout(cfg[\"drop_rate\"])\n",
    "        self.trf_blocks = nn.Sequential(\n",
    "            *[TransformerBlock(cfg) for _ in range(cfg[\"n_layers\"])])\n",
    "        self.final_norm = LayerNorm(cfg[\"emb_dim\"])\n",
    "        self.out_head = nn.Linear(cfg[\"emb_dim\"], cfg[\"vocab_size\"], bias=False)\n",
    "\n",
    "    def forward(self, in_idx):\n",
    "        # in_idx: (batch,seq_len), each element is a token-index (integer shows location)\n",
    "        batch_size, seq_len = in_idx.shape\n",
    "        tok_embeds = self.tok_emb(in_idx) # (batch,seq_len)=>(batch,seq_len,emb_dim)\n",
    "        pos_embeds = self.pos_emb(torch.arange(seq_len, device=in_idx.device)) # (1,seq_len)=>(1,seq_len,emb_dim)\n",
    "        x = tok_embeds + pos_embeds # (batch,seq_len,emb_dim)\n",
    "        x = self.drop_emb(x) # (batch,seq_len,emb_dim)\n",
    "        x = self.trf_blocks(x) # (batch,seq_len,emb_dim)\n",
    "        x = self.final_norm(x) # (batch,seq_len,emb_dim)\n",
    "        logits = self.out_head(x) # (batch,seq_len,vocab_len)\n",
    "        return logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "366ce3e6-de1f-42ac-acc2-a2735ee5d5f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# small utils function: check if <left> and <right> has matching shape\n",
    "# if yes then return <Parameter> as the right tensor\n",
    "def assign(left, right):\n",
    "    if left.shape != right.shape:\n",
    "        raise ValueError(f\"Shape mismatch. Left: {left.shape}, Right: {right.shape}\")\n",
    "    return torch.nn.Parameter(torch.tensor(right))\n",
    "\n",
    "def load_weights_into_gpt(gpt, params):\n",
    "    # load positional encoding\n",
    "    gpt.pos_emb.weight = assign(gpt.pos_emb.weight, params['wpe'])\n",
    "    # load token embedding\n",
    "    gpt.tok_emb.weight = assign(gpt.tok_emb.weight, params['wte'])\n",
    "    # load transformers blocks\n",
    "    for b in range(len(params[\"blocks\"])):\n",
    "        # params[\"blocks\"][b][\"attn\"]: <multi-head-attn> part\n",
    "        # <multi-head-attn>[\"c_attn\"]: convolution attention (of qkv) inside\n",
    "        # split to 3 parts <query>,<key>,<value>\n",
    "        q_w, k_w, v_w = np.split( params[\"blocks\"][b][\"attn\"][\"c_attn\"][\"w\"], 3, axis=-1) # each (768,768)\n",
    "        gpt.trf_blocks[b].att.W_query.weight = assign(gpt.trf_blocks[b].att.W_query.weight, q_w.T)\n",
    "        gpt.trf_blocks[b].att.W_key.weight = assign(gpt.trf_blocks[b].att.W_key.weight, k_w.T)\n",
    "        gpt.trf_blocks[b].att.W_value.weight = assign(gpt.trf_blocks[b].att.W_value.weight, v_w.T)\n",
    "\n",
    "        # bias of <attn> in <multi-head-attention>\n",
    "        q_b, k_b, v_b = np.split( params[\"blocks\"][b][\"attn\"][\"c_attn\"][\"b\"], 3, axis=-1) # each (768,)\n",
    "        gpt.trf_blocks[b].att.W_query.bias = assign(gpt.trf_blocks[b].att.W_query.bias, q_b)\n",
    "        gpt.trf_blocks[b].att.W_key.bias = assign(gpt.trf_blocks[b].att.W_key.bias, k_b)\n",
    "        gpt.trf_blocks[b].att.W_value.bias = assign(gpt.trf_blocks[b].att.W_value.bias, v_b)\n",
    "\n",
    "        # out-projection of <attn> in <multi-head-attention>\n",
    "        gpt.trf_blocks[b].att.out_proj.weight = assign(gpt.trf_blocks[b].att.out_proj.weight, params[\"blocks\"][b][\"attn\"][\"c_proj\"][\"w\"].T)\n",
    "        gpt.trf_blocks[b].att.out_proj.bias = assign(gpt.trf_blocks[b].att.out_proj.bias, params[\"blocks\"][b][\"attn\"][\"c_proj\"][\"b\"])\n",
    "\n",
    "        # feed-forward; layer0 & layer1 (layer1 is GeLU)\n",
    "        gpt.trf_blocks[b].ff.layers[0].weight = assign(gpt.trf_blocks[b].ff.layers[0].weight, params[\"blocks\"][b][\"mlp\"][\"c_fc\"][\"w\"].T)\n",
    "        gpt.trf_blocks[b].ff.layers[0].bias = assign(gpt.trf_blocks[b].ff.layers[0].bias, params[\"blocks\"][b][\"mlp\"][\"c_fc\"][\"b\"])\n",
    "        gpt.trf_blocks[b].ff.layers[2].weight = assign(gpt.trf_blocks[b].ff.layers[2].weight, params[\"blocks\"][b][\"mlp\"][\"c_proj\"][\"w\"].T)\n",
    "        gpt.trf_blocks[b].ff.layers[2].bias = assign(gpt.trf_blocks[b].ff.layers[2].bias, params[\"blocks\"][b][\"mlp\"][\"c_proj\"][\"b\"])\n",
    "\n",
    "        # layer normalization\n",
    "        gpt.trf_blocks[b].norm1.scale = assign(gpt.trf_blocks[b].norm1.scale, params[\"blocks\"][b][\"ln_1\"][\"g\"])\n",
    "        gpt.trf_blocks[b].norm1.shift = assign(gpt.trf_blocks[b].norm1.shift, params[\"blocks\"][b][\"ln_1\"][\"b\"])\n",
    "        gpt.trf_blocks[b].norm2.scale = assign(gpt.trf_blocks[b].norm2.scale, params[\"blocks\"][b][\"ln_2\"][\"g\"])\n",
    "        gpt.trf_blocks[b].norm2.shift = assign(gpt.trf_blocks[b].norm2.shift, params[\"blocks\"][b][\"ln_2\"][\"b\"])\n",
    "\n",
    "    # Final layer normalization\n",
    "    gpt.final_norm.scale = assign(gpt.final_norm.scale, params[\"g\"])\n",
    "    gpt.final_norm.shift = assign(gpt.final_norm.shift, params[\"b\"])\n",
    "    # Out weight\n",
    "    gpt.out_head.weight = assign(gpt.out_head.weight, params[\"wte\"]) # we use the token embedding weights again (\"weight tying\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "029d43dd-f6dc-4737-ae77-992fdec9bb2e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File already exists and is up-to-date: gpt2/124M/checkpoint\n",
      "File already exists and is up-to-date: gpt2/124M/encoder.json\n",
      "File already exists and is up-to-date: gpt2/124M/hparams.json\n",
      "File already exists and is up-to-date: gpt2/124M/model.ckpt.data-00000-of-00001\n",
      "File already exists and is up-to-date: gpt2/124M/model.ckpt.index\n",
      "File already exists and is up-to-date: gpt2/124M/model.ckpt.meta\n",
      "File already exists and is up-to-date: gpt2/124M/vocab.bpe\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GPTModel(\n",
       "  (tok_emb): Embedding(50257, 768)\n",
       "  (pos_emb): Embedding(1024, 768)\n",
       "  (drop_emb): Dropout(p=0.0, inplace=False)\n",
       "  (trf_blocks): Sequential(\n",
       "    (0): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GeLU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.0, inplace=False)\n",
       "    )\n",
       "    (1): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GeLU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.0, inplace=False)\n",
       "    )\n",
       "    (2): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GeLU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.0, inplace=False)\n",
       "    )\n",
       "    (3): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GeLU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.0, inplace=False)\n",
       "    )\n",
       "    (4): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GeLU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.0, inplace=False)\n",
       "    )\n",
       "    (5): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GeLU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.0, inplace=False)\n",
       "    )\n",
       "    (6): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GeLU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.0, inplace=False)\n",
       "    )\n",
       "    (7): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GeLU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.0, inplace=False)\n",
       "    )\n",
       "    (8): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GeLU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.0, inplace=False)\n",
       "    )\n",
       "    (9): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GeLU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.0, inplace=False)\n",
       "    )\n",
       "    (10): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GeLU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.0, inplace=False)\n",
       "    )\n",
       "    (11): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GeLU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.0, inplace=False)\n",
       "    )\n",
       "  )\n",
       "  (final_norm): LayerNorm()\n",
       "  (out_head): Linear(in_features=768, out_features=50257, bias=False)\n",
       ")"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "CHOOSE_MODEL = \"gpt2-small (124M)\"\n",
    "INPUT_PROMPT = \"Every effort moves\"\n",
    "BASE_CONFIG = {\n",
    "    \"vocab_size\": 50257,\n",
    "    \"context_length\": 1024,\n",
    "    \"drop_rate\": 0.0,\n",
    "    \"qkv_bias\": True\n",
    "}\n",
    "model_configs = {\n",
    "    \"gpt2-small (124M)\": {\"emb_dim\":768, \"n_layers\":12, \"n_heads\":12},\n",
    "    \"gpt2-medium (355M)\": {\"emb_dim\":1024, \"n_layers\":24, \"n_heads\":16},\n",
    "    \"gpt2-large (774M)\": {\"emb_dim\":1280, \"n_layers\":36, \"n_heads\":20},\n",
    "    \"gpt2-xl (1558M)\": {\"emb_dim\":1600, \"n_layers\":48, \"n_heads\":25}\n",
    "}\n",
    "BASE_CONFIG.update(model_configs[CHOOSE_MODEL])\n",
    "model_size = CHOOSE_MODEL.split(\" \")[-1].lstrip(\"(\").rstrip(\")\") # 355M\n",
    "settings, params = download_and_load_gpt2(\n",
    "    model_size=model_size, models_dir=\"gpt2\"\n",
    ")\n",
    "model = GPTModel(BASE_CONFIG)\n",
    "load_weights_into_gpt(model, params)\n",
    "model.eval()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "535e0812-235c-4953-b2d9-7da508f34d89",
   "metadata": {},
   "outputs": [],
   "source": [
    "def text_to_token_ids(text, tokenizer):\n",
    "    encoded = tokenizer.encode(text, allowed_special={'<|endoftext|>'}) # (n_tokens,)\n",
    "    encoded_tensor = torch.tensor(encoded).unsqueeze(0) # (1,n_tokens)\n",
    "    return encoded_tensor\n",
    "\n",
    "def token_ids_to_text(token_ids, tokenizer):\n",
    "    flat = token_ids.squeeze(0) # (n_tokens,)\n",
    "    return tokenizer.decode(flat.tolist())\n",
    "\n",
    "def generate_text_simple(model, idx, max_new_tokens, context_size):\n",
    "    # idx: (batch, n_tokens_long)\n",
    "    for _ in range(max_new_tokens):\n",
    "        idx_cond = idx[:,-context_size:] # take last <context_size> tokens as context => (batch,context_size)\n",
    "        with torch.no_grad():\n",
    "            logits = model(idx_cond) # (batch,context_size,vocab_len)\n",
    "        logits = logits[:,-1,:] # last tokenS - (batch,vocab_len)\n",
    "        probas = torch.softmax(logits,dim=-1) # (batch,vocab_len)\n",
    "        idx_next = torch.argmax(probas, dim=-1, keepdim=True) # (batch,1)\n",
    "        idx = torch.cat((idx, idx_next), dim=1) #(batch,n_tokens_long+1)\n",
    "    return idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "56fe099b-1659-45f6-bd82-3757012711a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Every effort moves you forward.\n",
      "\n",
      "The first step is to understand the importance of your work\n"
     ]
    }
   ],
   "source": [
    "# Check if model is correctly loaded, we use it to generate some text\n",
    "text_1 = \"Every effort moves you\"\n",
    "token_ids = generate_text_simple(\n",
    "    model=model,\n",
    "    idx=text_to_token_ids(text_1, tokenizer),\n",
    "    max_new_tokens=15,\n",
    "    context_size=BASE_CONFIG[\"context_length\"]\n",
    ")\n",
    "# token_ids: (1,19)\n",
    "print(token_ids_to_text(token_ids, tokenizer))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "2ada2c90-7c8c-4c3c-b473-6ebcc63feb37",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/phm1605/anaconda3/envs/python310/lib/python3.10/site-packages/torch/cuda/__init__.py:283: UserWarning: \n",
      "    Found GPU1 NVIDIA GeForce GT 1030 which is of cuda capability 6.1.\n",
      "    Minimum and Maximum cuda capability supported by this version of PyTorch is\n",
      "    (7.0) - (12.0)\n",
      "    \n",
      "  warnings.warn(\n",
      "/home/phm1605/anaconda3/envs/python310/lib/python3.10/site-packages/torch/cuda/__init__.py:304: UserWarning: \n",
      "    Please install PyTorch with a following CUDA\n",
      "    configurations:  12.6 following instructions at\n",
      "    https://pytorch.org/get-started/locally/\n",
      "    \n",
      "  warnings.warn(matched_cuda_warn.format(matched_arches))\n",
      "/home/phm1605/anaconda3/envs/python310/lib/python3.10/site-packages/torch/cuda/__init__.py:326: UserWarning: \n",
      "NVIDIA GeForce GT 1030 with CUDA capability sm_61 is not compatible with the current PyTorch installation.\n",
      "The current PyTorch install supports CUDA capabilities sm_70 sm_75 sm_80 sm_86 sm_90 sm_100 sm_120.\n",
      "If you want to use the NVIDIA GeForce GT 1030 GPU with PyTorch, please check the instructions at https://pytorch.org/get-started/locally/\n",
      "\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finish create classifier to fine-tune\n"
     ]
    }
   ],
   "source": [
    "# Prepare model for classification\n",
    "num_classes = 2\n",
    "model.out_head = torch.nn.Linear(in_features=768, out_features=num_classes)\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "model.to(device)\n",
    "print(\"Finish create classifier to fine-tune\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a6b33909-7367-4eec-8ff8-6270ab976f0c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training accuracy: 48.75%\n",
      "Validation accuracy: 45.00%\n",
      "Test accuracy: 48.75%\n"
     ]
    }
   ],
   "source": [
    "# Check accuracy (should be bad, we haven't fine-tuned yet)\n",
    "# Calculating classification accuracy\n",
    "def calc_accuracy_loader(data_loader, model, device, num_batches=None):\n",
    "    model.eval()\n",
    "    correct_predictions, num_examples = 0, 0\n",
    "    if num_batches is None:\n",
    "        num_batches = len(data_loader)\n",
    "    else:\n",
    "        num_batches = min(num_batches, len(data_loader))\n",
    "    \n",
    "    # <input_batch>: (batch,n_words)=(8,103)\n",
    "    # <target_batch>: (batch,)=(8,)\n",
    "    for i, (input_batch, target_batch) in enumerate(data_loader):\n",
    "        if i < num_batches:\n",
    "            input_batch = input_batch.to(device)\n",
    "            target_batch = target_batch.to(device)\n",
    "            with torch.no_grad():\n",
    "                logits = model(input_batch)[:,-1,:] # last of (batch,n_words,n_class)=>(batch,2)\n",
    "            predicted_labels = torch.argmax(logits, dim=-1) # (batch,)\n",
    "            \n",
    "            num_examples += predicted_labels.shape[0]\n",
    "            correct_predictions += (predicted_labels==target_batch).sum().item()\n",
    "        else:\n",
    "            break\n",
    "    return correct_predictions / num_examples\n",
    "\n",
    "train_accuracy = calc_accuracy_loader(\n",
    "    train_loader, model, device, num_batches=10\n",
    ")\n",
    "val_accuracy = calc_accuracy_loader(\n",
    "    val_loader, model, device, num_batches=10\n",
    ")\n",
    "test_accuracy = calc_accuracy_loader(\n",
    "    test_loader, model, device, num_batches=10\n",
    ")\n",
    "\n",
    "print(f\"Training accuracy: {train_accuracy*100:.2f}%\")\n",
    "print(f\"Validation accuracy: {val_accuracy*100:.2f}%\")\n",
    "print(f\"Test accuracy: {test_accuracy*100:.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7839780-149b-44f2-b57f-de6fb28e76c1",
   "metadata": {},
   "source": [
    "## Parameter efficient fine-tuning with LoRA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "7170134e-fc81-49b5-afce-aa528c810a26",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create LoRA layer\n",
    "import math\n",
    "\n",
    "class LoRALayer(torch.nn.Module):\n",
    "    def __init__(self, in_dim, out_dim, rank, alpha):\n",
    "        super().__init__()\n",
    "        self.A = torch.nn.Parameter(torch.empty(in_dim,rank))\n",
    "        torch.nn.init.kaiming_uniform_(self.A, a=math.sqrt(5)) # init that A matrix\n",
    "        self.B = torch.nn.Parameter(torch.zeros(rank, out_dim))\n",
    "        self.alpha = alpha # scaling output before return; usually EQUAL, x2, or HALF the rank\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.alpha * (x @ self.A @ self.B)\n",
    "        return x\n",
    "\n",
    "class LinearWithLoRA(torch.nn.Module):\n",
    "    def __init__(self, linear, rank, alpha):\n",
    "        super().__init__()\n",
    "        self.linear = linear\n",
    "        self.lora = LoRALayer(\n",
    "            linear.in_features, linear.out_features, rank, alpha\n",
    "        )\n",
    "    def forward(self, x):\n",
    "        return self.linear(x) + self.lora(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ac5a4025-3774-465c-9175-655f365c4e20",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replace Linear layer with LinearLoRA layer\n",
    "def replace_linear_with_lora(model, rank, alpha):\n",
    "    for name, module in model.named_children():\n",
    "        if isinstance(module, torch.nn.Linear):\n",
    "            setattr(model, name, LinearWithLoRA(module, rank, alpha))\n",
    "        else:\n",
    "            replace_linear_with_lora(module, rank, alpha) # recursively replace its children"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "11c809b6-875c-41a2-bf1e-a2e7603072aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total trainable parameters before: 124,441,346\n",
      "Total trainable parameters after: 0\n"
     ]
    }
   ],
   "source": [
    "# Freeze the old model first\n",
    "total_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "print(f\"Total trainable parameters before: {total_params:,}\")\n",
    "\n",
    "for param in model.parameters():\n",
    "    param.requires_grad = False\n",
    "total_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "print(f\"Total trainable parameters after: {total_params:,}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "c21fda81-c35d-45ce-a743-85e734359e3b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total trainable LoRA parameters: 2,666,528\n"
     ]
    }
   ],
   "source": [
    "# Wrap \"Linear\" into \"Linear with LoRA\"\n",
    "replace_linear_with_lora(model, rank=16, alpha=16)\n",
    "total_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "print(f\"Total trainable LoRA parameters: {total_params:,}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "8825e7f1-d20a-4da8-8bba-3ac8e76ad525",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GPTModel(\n",
       "  (tok_emb): Embedding(50257, 768)\n",
       "  (pos_emb): Embedding(1024, 768)\n",
       "  (drop_emb): Dropout(p=0.0, inplace=False)\n",
       "  (trf_blocks): Sequential(\n",
       "    (0): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): LinearWithLoRA(\n",
       "          (linear): Linear(in_features=768, out_features=768, bias=True)\n",
       "          (lora): LoRALayer()\n",
       "        )\n",
       "        (W_key): LinearWithLoRA(\n",
       "          (linear): Linear(in_features=768, out_features=768, bias=True)\n",
       "          (lora): LoRALayer()\n",
       "        )\n",
       "        (W_value): LinearWithLoRA(\n",
       "          (linear): Linear(in_features=768, out_features=768, bias=True)\n",
       "          (lora): LoRALayer()\n",
       "        )\n",
       "        (out_proj): LinearWithLoRA(\n",
       "          (linear): Linear(in_features=768, out_features=768, bias=True)\n",
       "          (lora): LoRALayer()\n",
       "        )\n",
       "        (dropout): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): LinearWithLoRA(\n",
       "            (linear): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (lora): LoRALayer()\n",
       "          )\n",
       "          (1): GeLU()\n",
       "          (2): LinearWithLoRA(\n",
       "            (linear): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (lora): LoRALayer()\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.0, inplace=False)\n",
       "    )\n",
       "    (1): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): LinearWithLoRA(\n",
       "          (linear): Linear(in_features=768, out_features=768, bias=True)\n",
       "          (lora): LoRALayer()\n",
       "        )\n",
       "        (W_key): LinearWithLoRA(\n",
       "          (linear): Linear(in_features=768, out_features=768, bias=True)\n",
       "          (lora): LoRALayer()\n",
       "        )\n",
       "        (W_value): LinearWithLoRA(\n",
       "          (linear): Linear(in_features=768, out_features=768, bias=True)\n",
       "          (lora): LoRALayer()\n",
       "        )\n",
       "        (out_proj): LinearWithLoRA(\n",
       "          (linear): Linear(in_features=768, out_features=768, bias=True)\n",
       "          (lora): LoRALayer()\n",
       "        )\n",
       "        (dropout): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): LinearWithLoRA(\n",
       "            (linear): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (lora): LoRALayer()\n",
       "          )\n",
       "          (1): GeLU()\n",
       "          (2): LinearWithLoRA(\n",
       "            (linear): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (lora): LoRALayer()\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.0, inplace=False)\n",
       "    )\n",
       "    (2): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): LinearWithLoRA(\n",
       "          (linear): Linear(in_features=768, out_features=768, bias=True)\n",
       "          (lora): LoRALayer()\n",
       "        )\n",
       "        (W_key): LinearWithLoRA(\n",
       "          (linear): Linear(in_features=768, out_features=768, bias=True)\n",
       "          (lora): LoRALayer()\n",
       "        )\n",
       "        (W_value): LinearWithLoRA(\n",
       "          (linear): Linear(in_features=768, out_features=768, bias=True)\n",
       "          (lora): LoRALayer()\n",
       "        )\n",
       "        (out_proj): LinearWithLoRA(\n",
       "          (linear): Linear(in_features=768, out_features=768, bias=True)\n",
       "          (lora): LoRALayer()\n",
       "        )\n",
       "        (dropout): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): LinearWithLoRA(\n",
       "            (linear): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (lora): LoRALayer()\n",
       "          )\n",
       "          (1): GeLU()\n",
       "          (2): LinearWithLoRA(\n",
       "            (linear): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (lora): LoRALayer()\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.0, inplace=False)\n",
       "    )\n",
       "    (3): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): LinearWithLoRA(\n",
       "          (linear): Linear(in_features=768, out_features=768, bias=True)\n",
       "          (lora): LoRALayer()\n",
       "        )\n",
       "        (W_key): LinearWithLoRA(\n",
       "          (linear): Linear(in_features=768, out_features=768, bias=True)\n",
       "          (lora): LoRALayer()\n",
       "        )\n",
       "        (W_value): LinearWithLoRA(\n",
       "          (linear): Linear(in_features=768, out_features=768, bias=True)\n",
       "          (lora): LoRALayer()\n",
       "        )\n",
       "        (out_proj): LinearWithLoRA(\n",
       "          (linear): Linear(in_features=768, out_features=768, bias=True)\n",
       "          (lora): LoRALayer()\n",
       "        )\n",
       "        (dropout): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): LinearWithLoRA(\n",
       "            (linear): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (lora): LoRALayer()\n",
       "          )\n",
       "          (1): GeLU()\n",
       "          (2): LinearWithLoRA(\n",
       "            (linear): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (lora): LoRALayer()\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.0, inplace=False)\n",
       "    )\n",
       "    (4): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): LinearWithLoRA(\n",
       "          (linear): Linear(in_features=768, out_features=768, bias=True)\n",
       "          (lora): LoRALayer()\n",
       "        )\n",
       "        (W_key): LinearWithLoRA(\n",
       "          (linear): Linear(in_features=768, out_features=768, bias=True)\n",
       "          (lora): LoRALayer()\n",
       "        )\n",
       "        (W_value): LinearWithLoRA(\n",
       "          (linear): Linear(in_features=768, out_features=768, bias=True)\n",
       "          (lora): LoRALayer()\n",
       "        )\n",
       "        (out_proj): LinearWithLoRA(\n",
       "          (linear): Linear(in_features=768, out_features=768, bias=True)\n",
       "          (lora): LoRALayer()\n",
       "        )\n",
       "        (dropout): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): LinearWithLoRA(\n",
       "            (linear): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (lora): LoRALayer()\n",
       "          )\n",
       "          (1): GeLU()\n",
       "          (2): LinearWithLoRA(\n",
       "            (linear): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (lora): LoRALayer()\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.0, inplace=False)\n",
       "    )\n",
       "    (5): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): LinearWithLoRA(\n",
       "          (linear): Linear(in_features=768, out_features=768, bias=True)\n",
       "          (lora): LoRALayer()\n",
       "        )\n",
       "        (W_key): LinearWithLoRA(\n",
       "          (linear): Linear(in_features=768, out_features=768, bias=True)\n",
       "          (lora): LoRALayer()\n",
       "        )\n",
       "        (W_value): LinearWithLoRA(\n",
       "          (linear): Linear(in_features=768, out_features=768, bias=True)\n",
       "          (lora): LoRALayer()\n",
       "        )\n",
       "        (out_proj): LinearWithLoRA(\n",
       "          (linear): Linear(in_features=768, out_features=768, bias=True)\n",
       "          (lora): LoRALayer()\n",
       "        )\n",
       "        (dropout): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): LinearWithLoRA(\n",
       "            (linear): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (lora): LoRALayer()\n",
       "          )\n",
       "          (1): GeLU()\n",
       "          (2): LinearWithLoRA(\n",
       "            (linear): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (lora): LoRALayer()\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.0, inplace=False)\n",
       "    )\n",
       "    (6): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): LinearWithLoRA(\n",
       "          (linear): Linear(in_features=768, out_features=768, bias=True)\n",
       "          (lora): LoRALayer()\n",
       "        )\n",
       "        (W_key): LinearWithLoRA(\n",
       "          (linear): Linear(in_features=768, out_features=768, bias=True)\n",
       "          (lora): LoRALayer()\n",
       "        )\n",
       "        (W_value): LinearWithLoRA(\n",
       "          (linear): Linear(in_features=768, out_features=768, bias=True)\n",
       "          (lora): LoRALayer()\n",
       "        )\n",
       "        (out_proj): LinearWithLoRA(\n",
       "          (linear): Linear(in_features=768, out_features=768, bias=True)\n",
       "          (lora): LoRALayer()\n",
       "        )\n",
       "        (dropout): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): LinearWithLoRA(\n",
       "            (linear): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (lora): LoRALayer()\n",
       "          )\n",
       "          (1): GeLU()\n",
       "          (2): LinearWithLoRA(\n",
       "            (linear): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (lora): LoRALayer()\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.0, inplace=False)\n",
       "    )\n",
       "    (7): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): LinearWithLoRA(\n",
       "          (linear): Linear(in_features=768, out_features=768, bias=True)\n",
       "          (lora): LoRALayer()\n",
       "        )\n",
       "        (W_key): LinearWithLoRA(\n",
       "          (linear): Linear(in_features=768, out_features=768, bias=True)\n",
       "          (lora): LoRALayer()\n",
       "        )\n",
       "        (W_value): LinearWithLoRA(\n",
       "          (linear): Linear(in_features=768, out_features=768, bias=True)\n",
       "          (lora): LoRALayer()\n",
       "        )\n",
       "        (out_proj): LinearWithLoRA(\n",
       "          (linear): Linear(in_features=768, out_features=768, bias=True)\n",
       "          (lora): LoRALayer()\n",
       "        )\n",
       "        (dropout): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): LinearWithLoRA(\n",
       "            (linear): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (lora): LoRALayer()\n",
       "          )\n",
       "          (1): GeLU()\n",
       "          (2): LinearWithLoRA(\n",
       "            (linear): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (lora): LoRALayer()\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.0, inplace=False)\n",
       "    )\n",
       "    (8): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): LinearWithLoRA(\n",
       "          (linear): Linear(in_features=768, out_features=768, bias=True)\n",
       "          (lora): LoRALayer()\n",
       "        )\n",
       "        (W_key): LinearWithLoRA(\n",
       "          (linear): Linear(in_features=768, out_features=768, bias=True)\n",
       "          (lora): LoRALayer()\n",
       "        )\n",
       "        (W_value): LinearWithLoRA(\n",
       "          (linear): Linear(in_features=768, out_features=768, bias=True)\n",
       "          (lora): LoRALayer()\n",
       "        )\n",
       "        (out_proj): LinearWithLoRA(\n",
       "          (linear): Linear(in_features=768, out_features=768, bias=True)\n",
       "          (lora): LoRALayer()\n",
       "        )\n",
       "        (dropout): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): LinearWithLoRA(\n",
       "            (linear): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (lora): LoRALayer()\n",
       "          )\n",
       "          (1): GeLU()\n",
       "          (2): LinearWithLoRA(\n",
       "            (linear): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (lora): LoRALayer()\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.0, inplace=False)\n",
       "    )\n",
       "    (9): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): LinearWithLoRA(\n",
       "          (linear): Linear(in_features=768, out_features=768, bias=True)\n",
       "          (lora): LoRALayer()\n",
       "        )\n",
       "        (W_key): LinearWithLoRA(\n",
       "          (linear): Linear(in_features=768, out_features=768, bias=True)\n",
       "          (lora): LoRALayer()\n",
       "        )\n",
       "        (W_value): LinearWithLoRA(\n",
       "          (linear): Linear(in_features=768, out_features=768, bias=True)\n",
       "          (lora): LoRALayer()\n",
       "        )\n",
       "        (out_proj): LinearWithLoRA(\n",
       "          (linear): Linear(in_features=768, out_features=768, bias=True)\n",
       "          (lora): LoRALayer()\n",
       "        )\n",
       "        (dropout): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): LinearWithLoRA(\n",
       "            (linear): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (lora): LoRALayer()\n",
       "          )\n",
       "          (1): GeLU()\n",
       "          (2): LinearWithLoRA(\n",
       "            (linear): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (lora): LoRALayer()\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.0, inplace=False)\n",
       "    )\n",
       "    (10): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): LinearWithLoRA(\n",
       "          (linear): Linear(in_features=768, out_features=768, bias=True)\n",
       "          (lora): LoRALayer()\n",
       "        )\n",
       "        (W_key): LinearWithLoRA(\n",
       "          (linear): Linear(in_features=768, out_features=768, bias=True)\n",
       "          (lora): LoRALayer()\n",
       "        )\n",
       "        (W_value): LinearWithLoRA(\n",
       "          (linear): Linear(in_features=768, out_features=768, bias=True)\n",
       "          (lora): LoRALayer()\n",
       "        )\n",
       "        (out_proj): LinearWithLoRA(\n",
       "          (linear): Linear(in_features=768, out_features=768, bias=True)\n",
       "          (lora): LoRALayer()\n",
       "        )\n",
       "        (dropout): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): LinearWithLoRA(\n",
       "            (linear): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (lora): LoRALayer()\n",
       "          )\n",
       "          (1): GeLU()\n",
       "          (2): LinearWithLoRA(\n",
       "            (linear): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (lora): LoRALayer()\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.0, inplace=False)\n",
       "    )\n",
       "    (11): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): LinearWithLoRA(\n",
       "          (linear): Linear(in_features=768, out_features=768, bias=True)\n",
       "          (lora): LoRALayer()\n",
       "        )\n",
       "        (W_key): LinearWithLoRA(\n",
       "          (linear): Linear(in_features=768, out_features=768, bias=True)\n",
       "          (lora): LoRALayer()\n",
       "        )\n",
       "        (W_value): LinearWithLoRA(\n",
       "          (linear): Linear(in_features=768, out_features=768, bias=True)\n",
       "          (lora): LoRALayer()\n",
       "        )\n",
       "        (out_proj): LinearWithLoRA(\n",
       "          (linear): Linear(in_features=768, out_features=768, bias=True)\n",
       "          (lora): LoRALayer()\n",
       "        )\n",
       "        (dropout): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): LinearWithLoRA(\n",
       "            (linear): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (lora): LoRALayer()\n",
       "          )\n",
       "          (1): GeLU()\n",
       "          (2): LinearWithLoRA(\n",
       "            (linear): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (lora): LoRALayer()\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.0, inplace=False)\n",
       "    )\n",
       "  )\n",
       "  (final_norm): LayerNorm()\n",
       "  (out_head): LinearWithLoRA(\n",
       "    (linear): Linear(in_features=768, out_features=2, bias=True)\n",
       "    (lora): LoRALayer()\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check new model structure\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "257acd0d-d5db-4628-99aa-ac054c94ff1b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training accuracy: 53.75%\n",
      "Validation accuracy: 45.00%\n",
      "Test accuracy: 48.75%\n"
     ]
    }
   ],
   "source": [
    "# Check the accuracy of the new LoRA model BEFORE TUNING\n",
    "train_accuracy = calc_accuracy_loader(\n",
    "    train_loader, model, device, num_batches=10\n",
    ")\n",
    "val_accuracy = calc_accuracy_loader(\n",
    "    val_loader, model, device, num_batches=10\n",
    ")\n",
    "test_accuracy = calc_accuracy_loader(\n",
    "    test_loader, model, device, num_batches=10\n",
    ")\n",
    "print(f\"Training accuracy: {train_accuracy*100:.2f}%\")\n",
    "print(f\"Validation accuracy: {val_accuracy*100:.2f}%\")\n",
    "print(f\"Test accuracy: {test_accuracy*100:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "06083f0b-9cea-49a9-a6e5-2e7a7f195195",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep 1 (Step 000000): Train loss 1.697, Val loss 1.447\n",
      "Ep 1 (Step 000050): Train loss 0.402, Val loss 0.319\n",
      "Ep 1 (Step 000100): Train loss 0.399, Val loss 0.203\n",
      "Training accuracy: 85.00% | Validation accuracy: 92.50%\n",
      "Ep 2 (Step 000150): Train loss 0.170, Val loss 0.110\n",
      "Ep 2 (Step 000200): Train loss 0.054, Val loss 0.117\n",
      "Ep 2 (Step 000250): Train loss 0.042, Val loss 0.096\n",
      "Training accuracy: 97.50% | Validation accuracy: 100.00%\n",
      "Ep 3 (Step 000300): Train loss 0.004, Val loss 0.003\n",
      "Ep 3 (Step 000350): Train loss 0.006, Val loss 0.018\n",
      "Training accuracy: 100.00% | Validation accuracy: 97.50%\n",
      "Ep 4 (Step 000400): Train loss 0.064, Val loss 0.001\n",
      "Ep 4 (Step 000450): Train loss 0.056, Val loss 0.006\n",
      "Ep 4 (Step 000500): Train loss 0.056, Val loss 0.005\n",
      "Training accuracy: 100.00% | Validation accuracy: 100.00%\n",
      "Ep 5 (Step 000550): Train loss 0.000, Val loss 0.000\n",
      "Ep 5 (Step 000600): Train loss 0.000, Val loss 0.000\n",
      "Training accuracy: 100.00% | Validation accuracy: 100.00%\n",
      "Training completed in 1.18 minutes.\n"
     ]
    }
   ],
   "source": [
    "import time \n",
    "\n",
    "# for classification: we use <cross-entropy> loss of the last token row\n",
    "def calc_loss_batch(input_batch, target_batch, model, device):\n",
    "    input_batch = input_batch.to(device) # (batch,n_words)\n",
    "    target_batch = target_batch.to(device) # (batch,)\n",
    "    logits = model(input_batch)[:,-1,:] # (batch,n_word,n_class)=>(batch,n_class)\n",
    "    loss = torch.nn.functional.cross_entropy(logits, target_batch)\n",
    "    return loss\n",
    "\n",
    "def calc_loss_loader(data_loader, model, device, num_batches=None):\n",
    "    total_loss = 0.\n",
    "    if len(data_loader) == 0:\n",
    "        return float(\"nan\")\n",
    "    elif num_batches is None:\n",
    "        num_batches = len(data_loader)\n",
    "    else:\n",
    "        num_batches = min(num_batches, len(data_loader))\n",
    "    for i, (input_batch, target_batch) in enumerate(data_loader):\n",
    "        if i<num_batches:\n",
    "            loss = calc_loss_batch(\n",
    "                input_batch, target_batch, model, device\n",
    "            )\n",
    "            total_loss += loss.item()\n",
    "        else:\n",
    "            break\n",
    "    return total_loss / num_batches\n",
    "\n",
    "# eval_iter: num_batches to evaluate accuracy (of train/val)\n",
    "def evaluate_model(model, train_loader, val_loader, device, eval_iter):\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        train_loss = calc_loss_loader(train_loader, model, device, num_batches=eval_iter)\n",
    "        val_loss = calc_loss_loader(train_loader, model, device, num_batches=eval_iter)\n",
    "    model.train()\n",
    "    return train_loss, val_loss\n",
    "\n",
    "def train_classifier_simple(model, train_loader, val_loader, optimizer, device, num_epochs, eval_freq, eval_iter):\n",
    "    # eval_iter: num_batches to evaluate accuracy (of train/val)\n",
    "    train_losses, val_losses, train_accs, val_accs = [], [], [], []\n",
    "    # examples_seen: add up #samples-per-batch when each batch passing\n",
    "    # global_step: add up 1 after each batch passing\n",
    "    examples_seen, global_step = 0, -1\n",
    "    for epoch in range(num_epochs):\n",
    "        model.train()\n",
    "        for input_batch, target_batch in train_loader:\n",
    "            optimizer.zero_grad()\n",
    "            loss = calc_loss_batch(input_batch, target_batch, model, device)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            examples_seen += input_batch.shape[0]\n",
    "            global_step += 1\n",
    "            if global_step % eval_freq == 0:\n",
    "                train_loss, val_loss = evaluate_model(model, train_loader, val_loader, device, eval_iter)\n",
    "                train_losses.append(train_loss)\n",
    "                val_losses.append(val_loss)\n",
    "                print(f\"Ep {epoch+1} (Step {global_step:06d}): Train loss {train_loss:.3f}, Val loss {val_loss:.3f}\")\n",
    "        train_accuracy = calc_accuracy_loader(train_loader, model, device, num_batches=eval_iter)\n",
    "        val_accuracy = calc_accuracy_loader(val_loader, model, device, num_batches=eval_iter)\n",
    "        print(f\"Training accuracy: {train_accuracy*100:.2f}% | \", end=\"\")\n",
    "        print(f\"Validation accuracy: {val_accuracy*100:.2f}%\")\n",
    "        train_accs.append(train_accuracy)\n",
    "        val_accs.append(val_accuracy)\n",
    "    \n",
    "    return train_losses, val_losses, train_accs, val_accs, examples_seen \n",
    "\n",
    "start_time = time.time()\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=5e-5, weight_decay=0.1)\n",
    "num_epochs = 5\n",
    "train_losses, val_losses, train_accs, val_accs, examples_seen = train_classifier_simple(\n",
    "    model, train_loader, val_loader, optimizer, device, num_epochs=num_epochs, eval_freq=50, eval_iter=5\n",
    ")\n",
    "end_time = time.time()\n",
    "execution_time_minutes = (end_time-start_time) / 60\n",
    "print(f\"Training completed in {execution_time_minutes:.2f} minutes.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "1cf03ecd-ea61-45e4-aeba-d4ed7d6ab324",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 500x300 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Visualize loss curves\n",
    "import matplotlib.pyplot as plt \n",
    "\n",
    "def plot_values(epochs_seen, examples_seen, train_values, val_values, label=\"loss\"):\n",
    "    fig, ax1 = plt.subplots(figsize=(5,3))\n",
    "    ax1.plot(epochs_seen, train_values, label=f\"Training {label}\")\n",
    "    ax1.plot(epochs_seen, val_values, linestyle=\"-.\", label=f\"Validation {label}\")\n",
    "    ax1.set_xlabel(\"Epochs\")\n",
    "    ax1.set_ylabel(label.capitalize())\n",
    "    ax1.legend()\n",
    "\n",
    "    # Invisible plot for aligning ticks\n",
    "    ax2 = ax1.twiny()\n",
    "    ax2.plot(examples_seen, train_values, alpha=0)\n",
    "    ax2.set_xlabel(\"Examples seen\")\n",
    "\n",
    "    fig.tight_layout()\n",
    "    plt.savefig(f\"{label}-plt.pdf\")\n",
    "    plt.show()\n",
    "\n",
    "epochs_tensor = torch.linspace(0, num_epochs, len(train_losses))\n",
    "examples_seen_tensor = torch.linspace(0, examples_seen, len(train_losses))\n",
    "plot_values(\n",
    "    epochs_tensor, examples_seen_tensor, train_losses, val_losses, label=\"loss\"\n",
    ")\n",
    "                               "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "47d408a7-bc2f-420a-bfd7-af5e37bbc0e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training accuracy: 99.62%\n",
      "Validation accuracy: 98.66%\n",
      "Test accuracy: 97.33%\n"
     ]
    }
   ],
   "source": [
    "# Visualize accuracy on train/val/test set\n",
    "train_accuracy = calc_accuracy_loader(train_loader, model, device)\n",
    "val_accuracy = calc_accuracy_loader(val_loader, model, device)\n",
    "test_accuracy = calc_accuracy_loader(test_loader, model, device)\n",
    "\n",
    "print(f\"Training accuracy: {train_accuracy*100:.2f}%\")\n",
    "print(f\"Validation accuracy: {val_accuracy*100:.2f}%\")\n",
    "print(f\"Test accuracy: {test_accuracy*100:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ba1561b-bab2-4cfb-a75e-1bcf825a517b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
