{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "829eb91c-8c19-4d34-8a62-300f561b6bac",
   "metadata": {},
   "source": [
    "## Preparing the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8194434d-d64b-4912-92e4-3da2c154292f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Label</th>\n",
       "      <th>Text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ham</td>\n",
       "      <td>Go until jurong point, crazy.. Available only ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ham</td>\n",
       "      <td>Ok lar... Joking wif u oni...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>spam</td>\n",
       "      <td>Free entry in 2 a wkly comp to win FA Cup fina...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ham</td>\n",
       "      <td>U dun say so early hor... U c already then say...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ham</td>\n",
       "      <td>Nah I don't think he goes to usf, he lives aro...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5567</th>\n",
       "      <td>spam</td>\n",
       "      <td>This is the 2nd time we have tried 2 contact u...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5568</th>\n",
       "      <td>ham</td>\n",
       "      <td>Will Ì_ b going to esplanade fr home?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5569</th>\n",
       "      <td>ham</td>\n",
       "      <td>Pity, * was in mood for that. So...any other s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5570</th>\n",
       "      <td>ham</td>\n",
       "      <td>The guy did some bitching but I acted like i'd...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5571</th>\n",
       "      <td>ham</td>\n",
       "      <td>Rofl. Its true to its name</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5572 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Label                                               Text\n",
       "0      ham  Go until jurong point, crazy.. Available only ...\n",
       "1      ham                      Ok lar... Joking wif u oni...\n",
       "2     spam  Free entry in 2 a wkly comp to win FA Cup fina...\n",
       "3      ham  U dun say so early hor... U c already then say...\n",
       "4      ham  Nah I don't think he goes to usf, he lives aro...\n",
       "...    ...                                                ...\n",
       "5567  spam  This is the 2nd time we have tried 2 contact u...\n",
       "5568   ham              Will Ì_ b going to esplanade fr home?\n",
       "5569   ham  Pity, * was in mood for that. So...any other s...\n",
       "5570   ham  The guy did some bitching but I acted like i'd...\n",
       "5571   ham                         Rofl. Its true to its name\n",
       "\n",
       "[5572 rows x 2 columns]"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "import pandas as pd \n",
    "data_file_path = \"spam.csv\"\n",
    "df = pd.read_csv(data_file_path, encoding=\"latin-1\")\n",
    "df = df.iloc[:,:2]\n",
    "df.columns = [\"Label\", \"Text\"]\n",
    "df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "43680a4c-fbf5-4f83-82a9-4dcaeb662f3d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Label\n",
      "ham     4825\n",
      "spam     747\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Number of each class <ham> or <spam>\n",
    "print(df[\"Label\"].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e9e61d12-144f-4c35-ab96-7505c5d4ec62",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Label\n",
      "ham     747\n",
      "spam    747\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Under-sampling to balance dataset\n",
    "def create_balanced_dataset(df):\n",
    "    num_spam = df[df[\"Label\"]==\"spam\"].shape[0]\n",
    "    ham_subset = df[df[\"Label\"]==\"ham\"].sample(\n",
    "        num_spam, random_state=123\n",
    "    )\n",
    "    balanced_df = pd.concat([\n",
    "        ham_subset, df[df[\"Label\"] == \"spam\"]\n",
    "    ])\n",
    "    return balanced_df \n",
    "balanced_df = create_balanced_dataset(df)\n",
    "print(balanced_df[\"Label\"].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d5e02691-9d96-4673-83ad-f28f52b2eb24",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert classes to 0 and 1\n",
    "balanced_df[\"Label\"] = balanced_df[\"Label\"].map({\"ham\":0, \"spam\":1})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "56f716b4-f075-4bbd-9575-6d5aa6df0e95",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train/val/test split to 0.7/0.1/0.2\n",
    "def random_split(df, train_frac, validation_frac):\n",
    "    # shuffle DataFrame\n",
    "    df = df.sample(frac=1, random_state=123).reset_index(drop=True)\n",
    "    train_end = int(len(df) * train_frac)\n",
    "    validation_end = train_end + int(len(df) * validation_frac)\n",
    "    \n",
    "    train_df = df[:train_end]\n",
    "    validation_df = df[train_end:validation_end]\n",
    "    test_df = df[validation_end:]\n",
    "    \n",
    "    return train_df, validation_df, test_df \n",
    "\n",
    "train_df, validation_df, test_df = random_split(balanced_df, 0.7, 0.1)\n",
    "\n",
    "train_df.to_csv(\"train.csv\", index=None)\n",
    "validation_df.to_csv(\"validation.csv\", index=None)\n",
    "test_df.to_csv(\"test.csv\", index=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "576d1dd7-c21b-4f1e-8f68-e3b2c0dfcd0d",
   "metadata": {},
   "source": [
    "## Creating data loaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "09e6c669-f4e3-43d8-a8e6-c20b54325edf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[50256]\n"
     ]
    }
   ],
   "source": [
    "import tiktoken\n",
    "tokenizer = tiktoken.get_encoding(\"gpt2\")\n",
    "print(tokenizer.encode(\"<|endoftext|>\", allowed_special={\"<|endoftext|>\"}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4501e58a-8f61-4815-bbbd-c2f550c38f56",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset max length:  103\n"
     ]
    }
   ],
   "source": [
    "# Setting up Dataset\n",
    "import torch\n",
    "from torch.utils.data import Dataset \n",
    "\n",
    "class SpamDataset(Dataset):\n",
    "    # csv_file: 2 columns of \"Label\" (0 or 1) and \"Text\" (string)\n",
    "    def __init__(self, csv_file, tokenizer, max_length=None, pad_token_id=50256):\n",
    "        self.data = pd.read_csv(csv_file)\n",
    "        # [[3,643,2], [7,1],...]\n",
    "        self.encoded_texts = [\n",
    "            tokenizer.encode(text) for text in self.data[\"Text\"]\n",
    "        ]\n",
    "        \n",
    "        if max_length is None:\n",
    "            self.max_length = self._longest_encoded_length()\n",
    "        else: # truncate sentence if too long\n",
    "            self.max_length = max_length\n",
    "            self.encoded_texts = [\n",
    "                encoded_text[:self.max_length]\n",
    "                for encoded_text in self.encoded_texts\n",
    "            ]\n",
    "        # pad sequence with <50256> to the length of longest sequence\n",
    "        self.encoded_texts = [\n",
    "            encoded_text + [pad_token_id]*(self.max_length-len(encoded_text))\n",
    "            for encoded_text in self.encoded_texts\n",
    "        ]\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        encoded = self.encoded_texts[index] # will have same length <max_length>\n",
    "        label = self.data.iloc[index][\"Label\"]\n",
    "        return (\n",
    "            torch.tensor(encoded, dtype=torch.long), # (max_length,)\n",
    "            torch.tensor(label, dtype=torch.long) # (1,)\n",
    "        )\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def _longest_encoded_length(self):\n",
    "        max_length = 0\n",
    "        for encoded_text in self.encoded_texts:\n",
    "            encoded_length = len(encoded_text)\n",
    "            if encoded_length > max_length:\n",
    "                max_length = encoded_length\n",
    "        return max_length\n",
    "\n",
    "train_dataset = SpamDataset(\n",
    "    csv_file=\"train.csv\",\n",
    "    max_length=None,\n",
    "    tokenizer=tokenizer\n",
    ")\n",
    "print(\"Dataset max length: \", train_dataset.max_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b54e2f67-aff9-44d4-b31f-8b071f650f7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pad & truncate val/test dataset to <max-length> OF TRAIN\n",
    "val_dataset = SpamDataset(\n",
    "    csv_file=\"validation.csv\",\n",
    "    max_length=train_dataset.max_length,\n",
    "    tokenizer=tokenizer\n",
    ")\n",
    "test_dataset = SpamDataset(\n",
    "    csv_file=\"test.csv\",\n",
    "    max_length=train_dataset.max_length,\n",
    "    tokenizer=tokenizer\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4e40a4d5-74a5-4ae3-a99b-e5d1c4a0380a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create DataLoaders\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "num_workers = 0\n",
    "batch_size = 8\n",
    "torch.manual_seed(123)\n",
    "\n",
    "# each batch: X: <batch,max-length>=<8,103>; y: <batch,>=<8,>\n",
    "train_loader = DataLoader(\n",
    "    dataset=train_dataset,\n",
    "    batch_size=batch_size,\n",
    "    shuffle=True,\n",
    "    num_workers=num_workers,\n",
    "    drop_last=True\n",
    ")\n",
    "val_loader = DataLoader(\n",
    "    dataset=val_dataset,\n",
    "    batch_size=batch_size,\n",
    "    num_workers=num_workers,\n",
    "    drop_last=False\n",
    ")\n",
    "test_loader = DataLoader(\n",
    "    dataset=test_dataset,\n",
    "    batch_size=batch_size,\n",
    "    num_workers=num_workers,\n",
    "    drop_last=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c77f1c1e-474c-4198-8535-d484c7804390",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input batch dimensions: torch.Size([8, 103])\n",
      "Label batch dimensions: torch.Size([8])\n"
     ]
    }
   ],
   "source": [
    "# Print batch shape\n",
    "for input_batch, target_batch in train_loader:\n",
    "    pass\n",
    "print(\"Input batch dimensions:\", input_batch.shape)\n",
    "print(\"Label batch dimensions:\", target_batch.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "907e3d8a-1ede-435d-9937-426e39c53572",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "130 training batches\n",
      "19 validation batches\n",
      "38 test batches\n"
     ]
    }
   ],
   "source": [
    "# How many batches in each dataset\n",
    "print(f\"{len(train_loader)} training batches\")\n",
    "print(f\"{len(val_loader)} validation batches\")\n",
    "print(f\"{len(test_loader)} test batches\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f617a20e-f8ae-42bc-ae56-996b1d19342c",
   "metadata": {},
   "source": [
    "## Initialize model with pre-trained weights (prepare for fine-tuning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0ac7cd83-ffdf-42a1-8746-8865116bb737",
   "metadata": {},
   "outputs": [],
   "source": [
    "CHOOSE_MODEL = \"gpt2-small (124M)\"\n",
    "INPUT_PROMPT = \"Every effort moves\"\n",
    "BASE_CONFIG = {\n",
    "    \"vocab_size\": 50257,\n",
    "    \"context_length\": 1024,\n",
    "    \"drop_rate\": 0.0,\n",
    "    \"qkv_bias\": True\n",
    "}\n",
    "model_configs = {\n",
    "    \"gpt2-small (124M)\": {\"emb_dim\":768, \"n_layers\":12, \"n_heads\":12},\n",
    "    \"gpt2-medium (355M)\": {\"emb_dim\":1024, \"n_layers\":24, \"n_heads\":16},\n",
    "    \"gpt2-large (774M)\": {\"emb_dim\":1280, \"n_layers\":36, \"n_heads\":20},\n",
    "    \"gpt2-xl (1558M)\": {\"emb_dim\":1600, \"n_layers\":48, \"n_heads\":25}\n",
    "}\n",
    "BASE_CONFIG.update(model_configs[CHOOSE_MODEL])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "3651505e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-12-11 13:22:55.992799: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "/home/phm1605/anaconda3/envs/python310/lib/python3.10/site-packages/google/protobuf/runtime_version.py:98: UserWarning: Protobuf gencode version 5.28.3 is exactly one major version older than the runtime version 6.31.1 at tensorflow/core/framework/attr_value.proto. Please update the gencode to avoid compatibility violations in the next runtime release.\n",
      "  warnings.warn(\n",
      "/home/phm1605/anaconda3/envs/python310/lib/python3.10/site-packages/google/protobuf/runtime_version.py:98: UserWarning: Protobuf gencode version 5.28.3 is exactly one major version older than the runtime version 6.31.1 at tensorflow/core/framework/tensor.proto. Please update the gencode to avoid compatibility violations in the next runtime release.\n",
      "  warnings.warn(\n",
      "/home/phm1605/anaconda3/envs/python310/lib/python3.10/site-packages/google/protobuf/runtime_version.py:98: UserWarning: Protobuf gencode version 5.28.3 is exactly one major version older than the runtime version 6.31.1 at tensorflow/core/framework/resource_handle.proto. Please update the gencode to avoid compatibility violations in the next runtime release.\n",
      "  warnings.warn(\n",
      "/home/phm1605/anaconda3/envs/python310/lib/python3.10/site-packages/google/protobuf/runtime_version.py:98: UserWarning: Protobuf gencode version 5.28.3 is exactly one major version older than the runtime version 6.31.1 at tensorflow/core/framework/tensor_shape.proto. Please update the gencode to avoid compatibility violations in the next runtime release.\n",
      "  warnings.warn(\n",
      "/home/phm1605/anaconda3/envs/python310/lib/python3.10/site-packages/google/protobuf/runtime_version.py:98: UserWarning: Protobuf gencode version 5.28.3 is exactly one major version older than the runtime version 6.31.1 at tensorflow/core/framework/types.proto. Please update the gencode to avoid compatibility violations in the next runtime release.\n",
      "  warnings.warn(\n",
      "/home/phm1605/anaconda3/envs/python310/lib/python3.10/site-packages/google/protobuf/runtime_version.py:98: UserWarning: Protobuf gencode version 5.28.3 is exactly one major version older than the runtime version 6.31.1 at tensorflow/core/framework/full_type.proto. Please update the gencode to avoid compatibility violations in the next runtime release.\n",
      "  warnings.warn(\n",
      "/home/phm1605/anaconda3/envs/python310/lib/python3.10/site-packages/google/protobuf/runtime_version.py:98: UserWarning: Protobuf gencode version 5.28.3 is exactly one major version older than the runtime version 6.31.1 at tensorflow/core/framework/function.proto. Please update the gencode to avoid compatibility violations in the next runtime release.\n",
      "  warnings.warn(\n",
      "/home/phm1605/anaconda3/envs/python310/lib/python3.10/site-packages/google/protobuf/runtime_version.py:98: UserWarning: Protobuf gencode version 5.28.3 is exactly one major version older than the runtime version 6.31.1 at tensorflow/core/framework/node_def.proto. Please update the gencode to avoid compatibility violations in the next runtime release.\n",
      "  warnings.warn(\n",
      "/home/phm1605/anaconda3/envs/python310/lib/python3.10/site-packages/google/protobuf/runtime_version.py:98: UserWarning: Protobuf gencode version 5.28.3 is exactly one major version older than the runtime version 6.31.1 at tensorflow/core/framework/op_def.proto. Please update the gencode to avoid compatibility violations in the next runtime release.\n",
      "  warnings.warn(\n",
      "/home/phm1605/anaconda3/envs/python310/lib/python3.10/site-packages/google/protobuf/runtime_version.py:98: UserWarning: Protobuf gencode version 5.28.3 is exactly one major version older than the runtime version 6.31.1 at tensorflow/core/framework/graph.proto. Please update the gencode to avoid compatibility violations in the next runtime release.\n",
      "  warnings.warn(\n",
      "/home/phm1605/anaconda3/envs/python310/lib/python3.10/site-packages/google/protobuf/runtime_version.py:98: UserWarning: Protobuf gencode version 5.28.3 is exactly one major version older than the runtime version 6.31.1 at tensorflow/core/framework/graph_debug_info.proto. Please update the gencode to avoid compatibility violations in the next runtime release.\n",
      "  warnings.warn(\n",
      "/home/phm1605/anaconda3/envs/python310/lib/python3.10/site-packages/google/protobuf/runtime_version.py:98: UserWarning: Protobuf gencode version 5.28.3 is exactly one major version older than the runtime version 6.31.1 at tensorflow/core/framework/versions.proto. Please update the gencode to avoid compatibility violations in the next runtime release.\n",
      "  warnings.warn(\n",
      "/home/phm1605/anaconda3/envs/python310/lib/python3.10/site-packages/google/protobuf/runtime_version.py:98: UserWarning: Protobuf gencode version 5.28.3 is exactly one major version older than the runtime version 6.31.1 at tensorflow/core/protobuf/config.proto. Please update the gencode to avoid compatibility violations in the next runtime release.\n",
      "  warnings.warn(\n",
      "/home/phm1605/anaconda3/envs/python310/lib/python3.10/site-packages/google/protobuf/runtime_version.py:98: UserWarning: Protobuf gencode version 5.28.3 is exactly one major version older than the runtime version 6.31.1 at xla/tsl/protobuf/coordination_config.proto. Please update the gencode to avoid compatibility violations in the next runtime release.\n",
      "  warnings.warn(\n",
      "/home/phm1605/anaconda3/envs/python310/lib/python3.10/site-packages/google/protobuf/runtime_version.py:98: UserWarning: Protobuf gencode version 5.28.3 is exactly one major version older than the runtime version 6.31.1 at tensorflow/core/framework/cost_graph.proto. Please update the gencode to avoid compatibility violations in the next runtime release.\n",
      "  warnings.warn(\n",
      "/home/phm1605/anaconda3/envs/python310/lib/python3.10/site-packages/google/protobuf/runtime_version.py:98: UserWarning: Protobuf gencode version 5.28.3 is exactly one major version older than the runtime version 6.31.1 at tensorflow/core/framework/step_stats.proto. Please update the gencode to avoid compatibility violations in the next runtime release.\n",
      "  warnings.warn(\n",
      "/home/phm1605/anaconda3/envs/python310/lib/python3.10/site-packages/google/protobuf/runtime_version.py:98: UserWarning: Protobuf gencode version 5.28.3 is exactly one major version older than the runtime version 6.31.1 at tensorflow/core/framework/allocation_description.proto. Please update the gencode to avoid compatibility violations in the next runtime release.\n",
      "  warnings.warn(\n",
      "/home/phm1605/anaconda3/envs/python310/lib/python3.10/site-packages/google/protobuf/runtime_version.py:98: UserWarning: Protobuf gencode version 5.28.3 is exactly one major version older than the runtime version 6.31.1 at tensorflow/core/framework/tensor_description.proto. Please update the gencode to avoid compatibility violations in the next runtime release.\n",
      "  warnings.warn(\n",
      "/home/phm1605/anaconda3/envs/python310/lib/python3.10/site-packages/google/protobuf/runtime_version.py:98: UserWarning: Protobuf gencode version 5.28.3 is exactly one major version older than the runtime version 6.31.1 at tensorflow/core/protobuf/cluster.proto. Please update the gencode to avoid compatibility violations in the next runtime release.\n",
      "  warnings.warn(\n",
      "/home/phm1605/anaconda3/envs/python310/lib/python3.10/site-packages/google/protobuf/runtime_version.py:98: UserWarning: Protobuf gencode version 5.28.3 is exactly one major version older than the runtime version 6.31.1 at tensorflow/core/protobuf/debug.proto. Please update the gencode to avoid compatibility violations in the next runtime release.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import torch.nn as nn\n",
    "from gpt_download import download_and_load_gpt2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "7236b412",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LayerNorm(nn.Module):\n",
    "    def __init__(self, emb_dim):\n",
    "        super().__init__()\n",
    "        self.eps = 1e-5\n",
    "        # optional trainable params\n",
    "        self.scale = nn.Parameter(torch.ones(emb_dim))\n",
    "        self.shift = nn.Parameter(torch.zeros(emb_dim))\n",
    "  \n",
    "    def forward(self, x):\n",
    "        mean = x.mean(dim=-1, keepdim=True) # (batch,1)\n",
    "        # biased variance: divided by 1/(n-1)\n",
    "        # unbiased variance: divided by 1/n\n",
    "        var = x.var(dim=-1, keepdim=True, unbiased=False) # (batch,1)\n",
    "        norm_x = (x-mean) / torch.sqrt(var+self.eps) # (batch,emb_dim)\n",
    "        return self.scale * norm_x + self.shift # (batch,emb_dim)\n",
    "        \n",
    "class GeLU(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "\n",
    "    def forward(self, x):\n",
    "        return 0.5*x*(1+torch.tanh( torch.sqrt(torch.tensor(2.0/torch.pi))*(x+0.044715*torch.pow(x,3)) ))\n",
    "\n",
    "class FeedForward(nn.Module):\n",
    "    def __init__(self, cfg):\n",
    "        super().__init__()\n",
    "        self.layers = nn.Sequential(\n",
    "          nn.Linear(cfg[\"emb_dim\"], 4*cfg[\"emb_dim\"]),\n",
    "          GeLU(),\n",
    "          nn.Linear(4*cfg[\"emb_dim\"], cfg[\"emb_dim\"])\n",
    "        )\n",
    "  \n",
    "    def forward(self, x):\n",
    "        return self.layers(x)\n",
    "\n",
    "class MultiHeadAttention(nn.Module):\n",
    "    def __init__(self, d_in, d_out, context_length, dropout, num_heads, qkv_bias=False):\n",
    "        super().__init__()\n",
    "        assert (d_out % num_heads == 0), \"d_out must be divisible by num_heads\"\n",
    "        self.d_out = d_out # 4\n",
    "        self.num_heads = num_heads # 2\n",
    "        self.head_dim = d_out // num_heads # 2\n",
    "\n",
    "        # bigger weight matrices\n",
    "        self.W_query = nn.Linear(d_in, d_out, bias=qkv_bias) # (3,4)\n",
    "        self.W_key = nn.Linear(d_in, d_out, bias=qkv_bias) # (3,4)\n",
    "        self.W_value = nn.Linear(d_in, d_out, bias=qkv_bias) # (3,4)\n",
    "\n",
    "        self.out_proj = nn.Linear(d_out, d_out)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        self.register_buffer(\n",
    "            \"mask\",\n",
    "            torch.triu(torch.ones(context_length, context_length), diagonal=1)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        b, num_tokens, d_in = x.shape\n",
    "\n",
    "        # compute big kqv matrices\n",
    "        keys = self.W_key(x) # (b,n,3)=>(b,n_token,4)\n",
    "        queries = self.W_query(x) # (b,n,3)=>(b,n_token,4)\n",
    "        values = self.W_value(x) # (b,n,3)=>(b,n_token,4)\n",
    "        # ... then splits\n",
    "        keys = keys.view(b, num_tokens, self.num_heads, self.head_dim) # (b,n_token,n_head=2,head_dim=2)\n",
    "        queries = queries.view(b, num_tokens, self.num_heads, self.head_dim) # (b,n_token,n_head,head_dim)\n",
    "        values = values.view(b, num_tokens, self.num_heads, self.head_dim) # (b,n_token,n_head,head_dim)\n",
    "        # swap <num_heads> to after-batch location\n",
    "        keys = keys.transpose(1,2) # (b,n_head=2,n_token,head_dim=2)\n",
    "        queries = queries.transpose(1,2) # (b,n_head=2,n_token,head_dim=2)\n",
    "        values = values.transpose(1,2) # (b,n_head=2,n_token,head_dim=2)\n",
    "\n",
    "        attn_scores = queries @ keys.transpose(2,3) # (b,n_head,n_token,head_dim)@(b,n_head,head_dim,n_token)=>(b,n_head,n_token,n_token)\n",
    "        mask_bool = self.mask.bool()[:num_tokens,:num_tokens]\n",
    "        attn_scores.masked_fill_(mask_bool, -torch.inf) # (n,n) with upper-right is -inf\n",
    "        attn_weights = torch.softmax(\n",
    "            attn_scores / keys.shape[-1]**0.5, dim=-1)\n",
    "        attn_weights = self.dropout(attn_weights) # (b,n_head,n_token,n_token)\n",
    "\n",
    "        context_vec = (attn_weights @ values).transpose(1,2) # (b,n_head,n_token,head_dim=2)=>transpose to (b,n_token,n_head,head_dim=2)\n",
    "        context_vec = context_vec.contiguous().view(b,num_tokens,self.d_out) # (b,n_token,n_head*head_dim)=(b,n_token,4)\n",
    "        context_vec = self.out_proj(context_vec) # (b,n_token,4)\n",
    "\n",
    "        return context_vec # (b,n_token,4)\n",
    "\n",
    "class TransformerBlock(nn.Module):\n",
    "    def __init__(self, cfg):\n",
    "        super().__init__()\n",
    "        self.att = MultiHeadAttention(\n",
    "            d_in=cfg[\"emb_dim\"],\n",
    "            d_out=cfg[\"emb_dim\"],\n",
    "            context_length=cfg[\"context_length\"],\n",
    "            num_heads=cfg[\"n_heads\"],\n",
    "            dropout=cfg[\"drop_rate\"],\n",
    "            qkv_bias=cfg[\"qkv_bias\"]\n",
    "        )\n",
    "        self.ff = FeedForward(cfg)\n",
    "        self.norm1 = LayerNorm(cfg[\"emb_dim\"])\n",
    "        self.norm2 = LayerNorm(cfg[\"emb_dim\"])\n",
    "        self.drop_shortcut = nn.Dropout(cfg[\"drop_rate\"])\n",
    "\n",
    "    def forward(self, x):\n",
    "        shortcut = x\n",
    "        x = self.norm1(x)\n",
    "        x = self.att(x)\n",
    "        x = self.drop_shortcut(x)\n",
    "        x = x + shortcut \n",
    "\n",
    "        shortcut = x\n",
    "        x = self.norm2(x)\n",
    "        x = self.ff(x)\n",
    "        x = self.drop_shortcut(x)\n",
    "        x = x + shortcut \n",
    "        return x \n",
    "\n",
    "class GPTModel(nn.Module):\n",
    "    def __init__(self, cfg):\n",
    "        super().__init__()\n",
    "        self.tok_emb = nn.Embedding(cfg[\"vocab_size\"], cfg[\"emb_dim\"])\n",
    "        self.pos_emb = nn.Embedding(cfg[\"context_length\"], cfg[\"emb_dim\"])\n",
    "        self.drop_emb = nn.Dropout(cfg[\"drop_rate\"])\n",
    "        self.trf_blocks = nn.Sequential(\n",
    "            *[TransformerBlock(cfg) for _ in range(cfg[\"n_layers\"])])\n",
    "        self.final_norm = LayerNorm(cfg[\"emb_dim\"])\n",
    "        self.out_head = nn.Linear(cfg[\"emb_dim\"], cfg[\"vocab_size\"], bias=False)\n",
    "\n",
    "    def forward(self, in_idx):\n",
    "        # in_idx: (batch,seq_len), each element is a token-index (integer shows location)\n",
    "        batch_size, seq_len = in_idx.shape\n",
    "        tok_embeds = self.tok_emb(in_idx) # (batch,seq_len)=>(batch,seq_len,emb_dim)\n",
    "        pos_embeds = self.pos_emb(torch.arange(seq_len, device=in_idx.device)) # (1,seq_len)=>(1,seq_len,emb_dim)\n",
    "        x = tok_embeds + pos_embeds # (batch,seq_len,emb_dim)\n",
    "        x = self.drop_emb(x) # (batch,seq_len,emb_dim)\n",
    "        x = self.trf_blocks(x) # (batch,seq_len,emb_dim)\n",
    "        x = self.final_norm(x) # (batch,seq_len,emb_dim)\n",
    "        logits = self.out_head(x) # (batch,seq_len,vocab_len)\n",
    "        return logits\n",
    "\n",
    "# small utils function: check if <left> and <right> has matching shape\n",
    "# if yes then return <Parameter> as the right tensor\n",
    "def assign(left, right):\n",
    "    if left.shape != right.shape:\n",
    "        raise ValueError(f\"Shape mismatch. Left: {left.shape}, Right: {right.shape}\")\n",
    "    return torch.nn.Parameter(torch.tensor(right))\n",
    "\n",
    "def load_weights_into_gpt(gpt, params):\n",
    "    # load positional encoding\n",
    "    gpt.pos_emb.weight = assign(gpt.pos_emb.weight, params['wpe'])\n",
    "    # load token embedding\n",
    "    gpt.tok_emb.weight = assign(gpt.tok_emb.weight, params['wte'])\n",
    "    # load transformers blocks\n",
    "    for b in range(len(params[\"blocks\"])):\n",
    "        # params[\"blocks\"][b][\"attn\"]: <multi-head-attn> part\n",
    "        # <multi-head-attn>[\"c_attn\"]: convolution attention (of qkv) inside\n",
    "        # split to 3 parts <query>,<key>,<value>\n",
    "        q_w, k_w, v_w = np.split( params[\"blocks\"][b][\"attn\"][\"c_attn\"][\"w\"], 3, axis=-1) # each (768,768)\n",
    "        gpt.trf_blocks[b].att.W_query.weight = assign(gpt.trf_blocks[b].att.W_query.weight, q_w.T)\n",
    "        gpt.trf_blocks[b].att.W_key.weight = assign(gpt.trf_blocks[b].att.W_key.weight, k_w.T)\n",
    "        gpt.trf_blocks[b].att.W_value.weight = assign(gpt.trf_blocks[b].att.W_value.weight, v_w.T)\n",
    "\n",
    "        # bias of <attn> in <multi-head-attention>\n",
    "        q_b, k_b, v_b = np.split( params[\"blocks\"][b][\"attn\"][\"c_attn\"][\"b\"], 3, axis=-1) # each (768,)\n",
    "        gpt.trf_blocks[b].att.W_query.bias = assign(gpt.trf_blocks[b].att.W_query.bias, q_b)\n",
    "        gpt.trf_blocks[b].att.W_key.bias = assign(gpt.trf_blocks[b].att.W_key.bias, k_b)\n",
    "        gpt.trf_blocks[b].att.W_value.bias = assign(gpt.trf_blocks[b].att.W_value.bias, v_b)\n",
    "\n",
    "        # out-projection of <attn> in <multi-head-attention>\n",
    "        gpt.trf_blocks[b].att.out_proj.weight = assign(gpt.trf_blocks[b].att.out_proj.weight, params[\"blocks\"][b][\"attn\"][\"c_proj\"][\"w\"].T)\n",
    "        gpt.trf_blocks[b].att.out_proj.bias = assign(gpt.trf_blocks[b].att.out_proj.bias, params[\"blocks\"][b][\"attn\"][\"c_proj\"][\"b\"])\n",
    "\n",
    "        # feed-forward; layer0 & layer1 (layer1 is GeLU)\n",
    "        gpt.trf_blocks[b].ff.layers[0].weight = assign(gpt.trf_blocks[b].ff.layers[0].weight, params[\"blocks\"][b][\"mlp\"][\"c_fc\"][\"w\"].T)\n",
    "        gpt.trf_blocks[b].ff.layers[0].bias = assign(gpt.trf_blocks[b].ff.layers[0].bias, params[\"blocks\"][b][\"mlp\"][\"c_fc\"][\"b\"])\n",
    "        gpt.trf_blocks[b].ff.layers[2].weight = assign(gpt.trf_blocks[b].ff.layers[2].weight, params[\"blocks\"][b][\"mlp\"][\"c_proj\"][\"w\"].T)\n",
    "        gpt.trf_blocks[b].ff.layers[2].bias = assign(gpt.trf_blocks[b].ff.layers[2].bias, params[\"blocks\"][b][\"mlp\"][\"c_proj\"][\"b\"])\n",
    "\n",
    "        # layer normalization\n",
    "        gpt.trf_blocks[b].norm1.scale = assign(gpt.trf_blocks[b].norm1.scale, params[\"blocks\"][b][\"ln_1\"][\"g\"])\n",
    "        gpt.trf_blocks[b].norm1.shift = assign(gpt.trf_blocks[b].norm1.shift, params[\"blocks\"][b][\"ln_1\"][\"b\"])\n",
    "        gpt.trf_blocks[b].norm2.scale = assign(gpt.trf_blocks[b].norm2.scale, params[\"blocks\"][b][\"ln_2\"][\"g\"])\n",
    "        gpt.trf_blocks[b].norm2.shift = assign(gpt.trf_blocks[b].norm2.shift, params[\"blocks\"][b][\"ln_2\"][\"b\"])\n",
    "\n",
    "    # Final layer normalization\n",
    "    gpt.final_norm.scale = assign(gpt.final_norm.scale, params[\"g\"])\n",
    "    gpt.final_norm.shift = assign(gpt.final_norm.shift, params[\"b\"])\n",
    "    # Out weight\n",
    "    gpt.out_head.weight = assign(gpt.out_head.weight, params[\"wte\"]) # we use the token embedding weights again (\"weight tying\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "24a9bba2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File already exists and is up-to-date: gpt2/124M/checkpoint\n",
      "File already exists and is up-to-date: gpt2/124M/encoder.json\n",
      "File already exists and is up-to-date: gpt2/124M/hparams.json\n",
      "File already exists and is up-to-date: gpt2/124M/model.ckpt.data-00000-of-00001\n",
      "File already exists and is up-to-date: gpt2/124M/model.ckpt.index\n",
      "File already exists and is up-to-date: gpt2/124M/model.ckpt.meta\n",
      "File already exists and is up-to-date: gpt2/124M/vocab.bpe\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GPTModel(\n",
       "  (tok_emb): Embedding(50257, 768)\n",
       "  (pos_emb): Embedding(1024, 768)\n",
       "  (drop_emb): Dropout(p=0.0, inplace=False)\n",
       "  (trf_blocks): Sequential(\n",
       "    (0): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GeLU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.0, inplace=False)\n",
       "    )\n",
       "    (1): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GeLU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.0, inplace=False)\n",
       "    )\n",
       "    (2): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GeLU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.0, inplace=False)\n",
       "    )\n",
       "    (3): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GeLU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.0, inplace=False)\n",
       "    )\n",
       "    (4): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GeLU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.0, inplace=False)\n",
       "    )\n",
       "    (5): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GeLU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.0, inplace=False)\n",
       "    )\n",
       "    (6): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GeLU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.0, inplace=False)\n",
       "    )\n",
       "    (7): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GeLU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.0, inplace=False)\n",
       "    )\n",
       "    (8): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GeLU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.0, inplace=False)\n",
       "    )\n",
       "    (9): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GeLU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.0, inplace=False)\n",
       "    )\n",
       "    (10): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GeLU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.0, inplace=False)\n",
       "    )\n",
       "    (11): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GeLU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.0, inplace=False)\n",
       "    )\n",
       "  )\n",
       "  (final_norm): LayerNorm()\n",
       "  (out_head): Linear(in_features=768, out_features=50257, bias=False)\n",
       ")"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_size = CHOOSE_MODEL.split(\" \")[-1].lstrip(\"(\").rstrip(\")\") # 124M\n",
    "settings, params = download_and_load_gpt2(\n",
    "    model_size=model_size, models_dir=\"gpt2\"\n",
    ")\n",
    "model = GPTModel(BASE_CONFIG)\n",
    "load_weights_into_gpt(model, params)\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "e41bfc6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check model loading is successful, by generating some meaningful text\n",
    "import tiktoken\n",
    "\n",
    "def generate_text_simple(model, idx, max_new_tokens, context_size):\n",
    "    # idx: (batch, n_tokens_long)\n",
    "    for _ in range(max_new_tokens):\n",
    "        idx_cond = idx[:,-context_size:] # take last <context_size> tokens as context => (batch,context_size)\n",
    "        with torch.no_grad():\n",
    "            logits = model(idx_cond) # (batch,context_size,vocab_len)\n",
    "        logits = logits[:,-1,:] # last tokenS - (batch,vocab_len)\n",
    "        probas = torch.softmax(logits,dim=-1) # (batch,vocab_len)\n",
    "        idx_next = torch.argmax(probas, dim=-1, keepdim=True) # (batch,1)\n",
    "        idx = torch.cat((idx, idx_next), dim=1) #(batch,n_tokens_long+1)\n",
    "    return idx\n",
    "\n",
    "def text_to_token_ids(text, tokenizer):\n",
    "    encoded = tokenizer.encode(text, allowed_special={'<|endoftext|>'}) # (n_tokens,)\n",
    "    encoded_tensor = torch.tensor(encoded).unsqueeze(0) # (1,n_tokens)\n",
    "    return encoded_tensor\n",
    "\n",
    "def token_ids_to_text(token_ids, tokenizer):\n",
    "    flat = token_ids.squeeze(0) # (n_tokens,)\n",
    "    return tokenizer.decode(flat.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "a44d9909",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Every effort moves you forward.\n",
      "\n",
      "The first step is to understand the importance of your work\n"
     ]
    }
   ],
   "source": [
    "text_1 = \"Every effort moves you\"\n",
    "token_ids = generate_text_simple(\n",
    "    model=model,\n",
    "    idx=text_to_token_ids(text_1, tokenizer),\n",
    "    max_new_tokens=15,\n",
    "    context_size=BASE_CONFIG[\"context_length\"]\n",
    ")\n",
    "# token_ids: (1,n_tokens_long+max_new_tokens)\n",
    "print(token_ids_to_text(token_ids, tokenizer))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "0fd042ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Is the following text 'spam'? Answer with 'yes' or 'no': 'You are a winner you have been specially selected to receive $1000 cash or a $2000 award.'\n",
      "\n",
      "The following text 'spam'? Answer with 'yes' or 'no': 'You are a winner\n"
     ]
    }
   ],
   "source": [
    "# Try to classify spams with prompting => not good\n",
    "text_2 = (\n",
    "    \"Is the following text 'spam'? Answer with 'yes' or 'no':\"\n",
    "    \" 'You are a winner you have been specially selected to receive $1000 cash or a $2000 award.'\"\n",
    ")\n",
    "token_ids = generate_text_simple(\n",
    "    model=model,\n",
    "    idx=text_to_token_ids(text_2, tokenizer),\n",
    "    max_new_tokens=23,\n",
    "    context_size=BASE_CONFIG[\"context_length\"]\n",
    ")\n",
    "print(token_ids_to_text(token_ids, tokenizer))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e025c34",
   "metadata": {},
   "source": [
    "## Adding a classification head"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "2986f60a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPTModel(\n",
      "  (tok_emb): Embedding(50257, 768)\n",
      "  (pos_emb): Embedding(1024, 768)\n",
      "  (drop_emb): Dropout(p=0.0, inplace=False)\n",
      "  (trf_blocks): Sequential(\n",
      "    (0): TransformerBlock(\n",
      "      (att): MultiHeadAttention(\n",
      "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (dropout): Dropout(p=0.0, inplace=False)\n",
      "      )\n",
      "      (ff): FeedForward(\n",
      "        (layers): Sequential(\n",
      "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
      "          (1): GeLU()\n",
      "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
      "        )\n",
      "      )\n",
      "      (norm1): LayerNorm()\n",
      "      (norm2): LayerNorm()\n",
      "      (drop_shortcut): Dropout(p=0.0, inplace=False)\n",
      "    )\n",
      "    (1): TransformerBlock(\n",
      "      (att): MultiHeadAttention(\n",
      "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (dropout): Dropout(p=0.0, inplace=False)\n",
      "      )\n",
      "      (ff): FeedForward(\n",
      "        (layers): Sequential(\n",
      "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
      "          (1): GeLU()\n",
      "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
      "        )\n",
      "      )\n",
      "      (norm1): LayerNorm()\n",
      "      (norm2): LayerNorm()\n",
      "      (drop_shortcut): Dropout(p=0.0, inplace=False)\n",
      "    )\n",
      "    (2): TransformerBlock(\n",
      "      (att): MultiHeadAttention(\n",
      "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (dropout): Dropout(p=0.0, inplace=False)\n",
      "      )\n",
      "      (ff): FeedForward(\n",
      "        (layers): Sequential(\n",
      "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
      "          (1): GeLU()\n",
      "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
      "        )\n",
      "      )\n",
      "      (norm1): LayerNorm()\n",
      "      (norm2): LayerNorm()\n",
      "      (drop_shortcut): Dropout(p=0.0, inplace=False)\n",
      "    )\n",
      "    (3): TransformerBlock(\n",
      "      (att): MultiHeadAttention(\n",
      "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (dropout): Dropout(p=0.0, inplace=False)\n",
      "      )\n",
      "      (ff): FeedForward(\n",
      "        (layers): Sequential(\n",
      "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
      "          (1): GeLU()\n",
      "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
      "        )\n",
      "      )\n",
      "      (norm1): LayerNorm()\n",
      "      (norm2): LayerNorm()\n",
      "      (drop_shortcut): Dropout(p=0.0, inplace=False)\n",
      "    )\n",
      "    (4): TransformerBlock(\n",
      "      (att): MultiHeadAttention(\n",
      "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (dropout): Dropout(p=0.0, inplace=False)\n",
      "      )\n",
      "      (ff): FeedForward(\n",
      "        (layers): Sequential(\n",
      "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
      "          (1): GeLU()\n",
      "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
      "        )\n",
      "      )\n",
      "      (norm1): LayerNorm()\n",
      "      (norm2): LayerNorm()\n",
      "      (drop_shortcut): Dropout(p=0.0, inplace=False)\n",
      "    )\n",
      "    (5): TransformerBlock(\n",
      "      (att): MultiHeadAttention(\n",
      "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (dropout): Dropout(p=0.0, inplace=False)\n",
      "      )\n",
      "      (ff): FeedForward(\n",
      "        (layers): Sequential(\n",
      "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
      "          (1): GeLU()\n",
      "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
      "        )\n",
      "      )\n",
      "      (norm1): LayerNorm()\n",
      "      (norm2): LayerNorm()\n",
      "      (drop_shortcut): Dropout(p=0.0, inplace=False)\n",
      "    )\n",
      "    (6): TransformerBlock(\n",
      "      (att): MultiHeadAttention(\n",
      "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (dropout): Dropout(p=0.0, inplace=False)\n",
      "      )\n",
      "      (ff): FeedForward(\n",
      "        (layers): Sequential(\n",
      "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
      "          (1): GeLU()\n",
      "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
      "        )\n",
      "      )\n",
      "      (norm1): LayerNorm()\n",
      "      (norm2): LayerNorm()\n",
      "      (drop_shortcut): Dropout(p=0.0, inplace=False)\n",
      "    )\n",
      "    (7): TransformerBlock(\n",
      "      (att): MultiHeadAttention(\n",
      "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (dropout): Dropout(p=0.0, inplace=False)\n",
      "      )\n",
      "      (ff): FeedForward(\n",
      "        (layers): Sequential(\n",
      "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
      "          (1): GeLU()\n",
      "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
      "        )\n",
      "      )\n",
      "      (norm1): LayerNorm()\n",
      "      (norm2): LayerNorm()\n",
      "      (drop_shortcut): Dropout(p=0.0, inplace=False)\n",
      "    )\n",
      "    (8): TransformerBlock(\n",
      "      (att): MultiHeadAttention(\n",
      "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (dropout): Dropout(p=0.0, inplace=False)\n",
      "      )\n",
      "      (ff): FeedForward(\n",
      "        (layers): Sequential(\n",
      "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
      "          (1): GeLU()\n",
      "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
      "        )\n",
      "      )\n",
      "      (norm1): LayerNorm()\n",
      "      (norm2): LayerNorm()\n",
      "      (drop_shortcut): Dropout(p=0.0, inplace=False)\n",
      "    )\n",
      "    (9): TransformerBlock(\n",
      "      (att): MultiHeadAttention(\n",
      "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (dropout): Dropout(p=0.0, inplace=False)\n",
      "      )\n",
      "      (ff): FeedForward(\n",
      "        (layers): Sequential(\n",
      "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
      "          (1): GeLU()\n",
      "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
      "        )\n",
      "      )\n",
      "      (norm1): LayerNorm()\n",
      "      (norm2): LayerNorm()\n",
      "      (drop_shortcut): Dropout(p=0.0, inplace=False)\n",
      "    )\n",
      "    (10): TransformerBlock(\n",
      "      (att): MultiHeadAttention(\n",
      "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (dropout): Dropout(p=0.0, inplace=False)\n",
      "      )\n",
      "      (ff): FeedForward(\n",
      "        (layers): Sequential(\n",
      "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
      "          (1): GeLU()\n",
      "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
      "        )\n",
      "      )\n",
      "      (norm1): LayerNorm()\n",
      "      (norm2): LayerNorm()\n",
      "      (drop_shortcut): Dropout(p=0.0, inplace=False)\n",
      "    )\n",
      "    (11): TransformerBlock(\n",
      "      (att): MultiHeadAttention(\n",
      "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (dropout): Dropout(p=0.0, inplace=False)\n",
      "      )\n",
      "      (ff): FeedForward(\n",
      "        (layers): Sequential(\n",
      "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
      "          (1): GeLU()\n",
      "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
      "        )\n",
      "      )\n",
      "      (norm1): LayerNorm()\n",
      "      (norm2): LayerNorm()\n",
      "      (drop_shortcut): Dropout(p=0.0, inplace=False)\n",
      "    )\n",
      "  )\n",
      "  (final_norm): LayerNorm()\n",
      "  (out_head): Linear(in_features=768, out_features=50257, bias=False)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "a764675b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# First freeze every layers\n",
    "for param in model.parameters():\n",
    "    param.requires_grad = False\n",
    "# Replace last layer\n",
    "torch.manual_seed(123)\n",
    "num_classes = 2\n",
    "model.out_head = torch.nn.Linear(\n",
    "    in_features=BASE_CONFIG[\"emb_dim\"],\n",
    "    out_features=num_classes\n",
    ")\n",
    "# Make the last <transformer> block AND final <LayerNorm> trainable\n",
    "for param in model.trf_blocks[-1].parameters():\n",
    "    param.requires_grad = True\n",
    "for param in model.final_norm.parameters():\n",
    "    param.requires_grad = True "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "da58776b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Inputs: tensor([[5211,  345,  423,  640]])\n",
      "Inputs dimensions: torch.Size([1, 4])\n"
     ]
    }
   ],
   "source": [
    "# Try feeding an example text\n",
    "inputs = tokenizer.encode(\"Do you have time\") # list of 4 ints\n",
    "inputs = torch.tensor(inputs).unsqueeze(0) # (batch,n_token)=(1,4)\n",
    "print(\"Inputs:\", inputs)\n",
    "print(\"Inputs dimensions:\", inputs.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "f5b96657",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Outputs:\n",
      " tensor([[[-1.5854,  0.9904],\n",
      "         [-3.7235,  7.4548],\n",
      "         [-2.2661,  6.6049],\n",
      "         [-3.5983,  3.9902]]])\n",
      "Outputs dimensions: torch.Size([1, 4, 2])\n",
      "Last output token: tensor([[-3.5983,  3.9902]])\n"
     ]
    }
   ],
   "source": [
    "# Prediction output => take last token\n",
    "with torch.no_grad():\n",
    "    outputs = model(inputs)\n",
    "print(\"Outputs:\\n\", outputs) # (batch,n_token,out_dim)=(1,4,2)\n",
    "print(\"Outputs dimensions:\", outputs.shape)\n",
    "print(\"Last output token:\", outputs[:,-1,:])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "603eee66",
   "metadata": {},
   "source": [
    "## Calculating the classification loss and accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "60a1798e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Last output token: tensor([[-3.5983,  3.9902]])\n",
      "Class label: 1\n"
     ]
    }
   ],
   "source": [
    "# Current class prediction: not correct\n",
    "print(\"Last output token:\", outputs[:,-1,:]) # (1,2)\n",
    "probas = torch.softmax(outputs[:,-1,:], dim=-1) # (1,2)\n",
    "label = torch.argmax(probas)\n",
    "print(\"Class label:\", label.item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "9f68a380",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculating classification accuracy\n",
    "def calc_accuracy_loader(data_loader, model, device, num_batches=None):\n",
    "    model.eval()\n",
    "    correct_predictions, num_examples = 0, 0\n",
    "    if num_batches is None:\n",
    "        num_batches = len(data_loader)\n",
    "    else:\n",
    "        num_batches = min(num_batches, len(data_loader))\n",
    "    \n",
    "    # <input_batch>: (batch,n_words)=(8,103)\n",
    "    # <target_batch>: (batch,)=(8,)\n",
    "    for i, (input_batch, target_batch) in enumerate(data_loader):\n",
    "        if i < num_batches:\n",
    "            input_batch = input_batch.to(device)\n",
    "            target_batch = target_batch.to(device)\n",
    "            with torch.no_grad():\n",
    "                logits = model(input_batch)[:,-1,:] # last of (batch,n_words,n_class)=>(batch,2)\n",
    "            predicted_labels = torch.argmax(logits, dim=-1) # (batch,)\n",
    "            \n",
    "            num_examples += predicted_labels.shape[0]\n",
    "            correct_predictions += (predicted_labels==target_batch).sum().item()\n",
    "        else:\n",
    "            break\n",
    "    return correct_predictions / num_examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "2cce05a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/phm1605/anaconda3/envs/python310/lib/python3.10/site-packages/torch/cuda/__init__.py:283: UserWarning: \n",
      "    Found GPU1 NVIDIA GeForce GT 1030 which is of cuda capability 6.1.\n",
      "    Minimum and Maximum cuda capability supported by this version of PyTorch is\n",
      "    (7.0) - (12.0)\n",
      "    \n",
      "  warnings.warn(\n",
      "/home/phm1605/anaconda3/envs/python310/lib/python3.10/site-packages/torch/cuda/__init__.py:304: UserWarning: \n",
      "    Please install PyTorch with a following CUDA\n",
      "    configurations:  12.6 following instructions at\n",
      "    https://pytorch.org/get-started/locally/\n",
      "    \n",
      "  warnings.warn(matched_cuda_warn.format(matched_arches))\n",
      "/home/phm1605/anaconda3/envs/python310/lib/python3.10/site-packages/torch/cuda/__init__.py:326: UserWarning: \n",
      "NVIDIA GeForce GT 1030 with CUDA capability sm_61 is not compatible with the current PyTorch installation.\n",
      "The current PyTorch install supports CUDA capabilities sm_70 sm_75 sm_80 sm_86 sm_90 sm_100 sm_120.\n",
      "If you want to use the NVIDIA GeForce GT 1030 GPU with PyTorch, please check the instructions at https://pytorch.org/get-started/locally/\n",
      "\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training accuracy: 53.75%\n",
      "Validation accuracy: 45.00%\n",
      "Test accuracy: 48.75%\n"
     ]
    }
   ],
   "source": [
    "# evaluate accuracy over 10 batches\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model.to(device)\n",
    "train_accuracy = calc_accuracy_loader(\n",
    "    train_loader, model, device, num_batches=10\n",
    ")\n",
    "val_accuracy = calc_accuracy_loader(\n",
    "    val_loader, model, device, num_batches=10\n",
    ")\n",
    "test_accuracy = calc_accuracy_loader(\n",
    "    test_loader, model, device, num_batches=10\n",
    ")\n",
    "print(f\"Training accuracy: {train_accuracy*100:.2f}%\")\n",
    "print(f\"Validation accuracy: {val_accuracy*100:.2f}%\")\n",
    "print(f\"Test accuracy: {test_accuracy*100:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "dc6166ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for classification: we use <cross-entropy> loss of the last token row\n",
    "def calc_loss_batch(input_batch, target_batch, model, device):\n",
    "    input_batch = input_batch.to(device) # (batch,n_words)\n",
    "    target_batch = target_batch.to(device) # (batch,)\n",
    "    logits = model(input_batch)[:,-1,:] # (batch,n_word,n_class)=>(batch,n_class)\n",
    "    loss = torch.nn.functional.cross_entropy(logits, target_batch)\n",
    "    return loss\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "eb9b05bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_loss_loader(data_loader, model, device, num_batches=None):\n",
    "    total_loss = 0.\n",
    "    if len(data_loader) == 0:\n",
    "        return float(\"nan\")\n",
    "    elif num_batches is None:\n",
    "        num_batches = len(data_loader)\n",
    "    else:\n",
    "        num_batches = min(num_batches, len(data_loader))\n",
    "    for i, (input_batch, target_batch) in enumerate(data_loader):\n",
    "        if i<num_batches:\n",
    "            loss = calc_loss_batch(\n",
    "                input_batch, target_batch, model, device\n",
    "            )\n",
    "            total_loss += loss.item()\n",
    "        else:\n",
    "            break\n",
    "    return total_loss / num_batches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "ab09e8d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 2.322\n",
      "Validation loss: 2.558\n",
      "Test loss: 2.316\n"
     ]
    }
   ],
   "source": [
    "# Calculate loss for train/val/test dataset\n",
    "with torch.no_grad():\n",
    "    train_loss = calc_loss_loader(\n",
    "        train_loader, model, device, num_batches=5\n",
    "    )\n",
    "    val_loss = calc_loss_loader(\n",
    "        val_loader, model, device, num_batches=5\n",
    "    )\n",
    "    test_loss = calc_loss_loader(\n",
    "        test_loader, model, device, num_batches=5\n",
    "    )\n",
    "print(f\"Training loss: {train_loss:.3f}\")\n",
    "print(f\"Validation loss: {val_loss:.3f}\")\n",
    "print(f\"Test loss: {test_loss:.3f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5809826",
   "metadata": {},
   "source": [
    "## Fine-tuning model on supervised data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "523e85a8-c69b-4372-babc-5378fa5e1e9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# eval_iter: num_batches to evaluate accuracy (of train/val)\n",
    "def evaluate_model(model, train_loader, val_loader, device, eval_iter):\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        train_loss = calc_loss_loader(train_loader, model, device, num_batches=eval_iter)\n",
    "        val_loss = calc_loss_loader(train_loader, model, device, num_batches=eval_iter)\n",
    "    model.train()\n",
    "    return train_loss, val_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "8e9abca3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_classifier_simple(model, train_loader, val_loader, optimizer, device, num_epochs, eval_freq, eval_iter):\n",
    "    # eval_iter: num_batches to evaluate accuracy (of train/val)\n",
    "    train_losses, val_losses, train_accs, val_accs = [], [], [], []\n",
    "    # examples_seen: add up #samples-per-batch when each batch passing\n",
    "    # global_step: add up 1 after each batch passing\n",
    "    examples_seen, global_step = 0, -1\n",
    "    for epoch in range(num_epochs):\n",
    "        model.train()\n",
    "        for input_batch, target_batch in train_loader:\n",
    "            optimizer.zero_grad()\n",
    "            loss = calc_loss_batch(input_batch, target_batch, model, device)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            examples_seen += input_batch.shape[0]\n",
    "            global_step += 1\n",
    "            if global_step % eval_freq == 0:\n",
    "                train_loss, val_loss = evaluate_model(model, train_loader, val_loader, device, eval_iter)\n",
    "                train_losses.append(train_loss)\n",
    "                val_losses.append(val_loss)\n",
    "                print(f\"Ep {epoch+1} (Step {global_step:06d}): Train loss {train_loss:.3f}, Val loss {val_loss:.3f}\")\n",
    "        train_accuracy = calc_accuracy_loader(train_loader, model, device, num_batches=eval_iter)\n",
    "        val_accuracy = calc_accuracy_loader(val_loader, model, device, num_batches=eval_iter)\n",
    "        print(f\"Training accuracy: {train_accuracy*100:.2f}% | \", end=\"\")\n",
    "        print(f\"Validation accuracy: {val_accuracy*100:.2f}%\")\n",
    "        train_accs.append(train_accuracy)\n",
    "        val_accs.append(val_accuracy)\n",
    "    \n",
    "    return train_losses, val_losses, train_accs, val_accs, examples_seen    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "507413f7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep 1 (Step 000000): Train loss 2.015, Val loss 2.988\n",
      "Ep 1 (Step 000050): Train loss 0.645, Val loss 0.594\n",
      "Ep 1 (Step 000100): Train loss 0.485, Val loss 0.495\n",
      "Training accuracy: 82.50% | Validation accuracy: 95.00%\n",
      "Ep 2 (Step 000150): Train loss 0.413, Val loss 0.444\n",
      "Ep 2 (Step 000200): Train loss 0.394, Val loss 0.407\n",
      "Ep 2 (Step 000250): Train loss 0.297, Val loss 0.283\n",
      "Training accuracy: 87.50% | Validation accuracy: 97.50%\n",
      "Ep 3 (Step 000300): Train loss 0.417, Val loss 0.486\n",
      "Ep 3 (Step 000350): Train loss 0.253, Val loss 0.463\n",
      "Training accuracy: 90.00% | Validation accuracy: 90.00%\n",
      "Ep 4 (Step 000400): Train loss 0.351, Val loss 0.367\n",
      "Ep 4 (Step 000450): Train loss 0.468, Val loss 0.355\n",
      "Ep 4 (Step 000500): Train loss 0.246, Val loss 0.283\n",
      "Training accuracy: 90.00% | Validation accuracy: 92.50%\n",
      "Ep 5 (Step 000550): Train loss 0.198, Val loss 0.308\n",
      "Ep 5 (Step 000600): Train loss 0.203, Val loss 0.135\n",
      "Training accuracy: 95.00% | Validation accuracy: 97.50%\n",
      "Ep 6 (Step 000650): Train loss 0.234, Val loss 0.104\n",
      "Ep 6 (Step 000700): Train loss 0.056, Val loss 0.244\n",
      "Ep 6 (Step 000750): Train loss 0.055, Val loss 0.049\n",
      "Training accuracy: 100.00% | Validation accuracy: 100.00%\n",
      "Ep 7 (Step 000800): Train loss 0.145, Val loss 0.017\n",
      "Ep 7 (Step 000850): Train loss 0.124, Val loss 0.111\n",
      "Ep 7 (Step 000900): Train loss 0.032, Val loss 0.123\n",
      "Training accuracy: 97.50% | Validation accuracy: 100.00%\n",
      "Ep 8 (Step 000950): Train loss 0.004, Val loss 0.063\n",
      "Ep 8 (Step 001000): Train loss 0.066, Val loss 0.021\n",
      "Training accuracy: 97.50% | Validation accuracy: 100.00%\n",
      "Ep 9 (Step 001050): Train loss 0.051, Val loss 0.016\n",
      "Ep 9 (Step 001100): Train loss 0.151, Val loss 0.066\n",
      "Ep 9 (Step 001150): Train loss 0.064, Val loss 0.152\n",
      "Training accuracy: 97.50% | Validation accuracy: 100.00%\n",
      "Ep 10 (Step 001200): Train loss 0.015, Val loss 0.092\n",
      "Ep 10 (Step 001250): Train loss 0.035, Val loss 0.024\n",
      "Training accuracy: 97.50% | Validation accuracy: 100.00%\n",
      "Training completed in 1.09 minutes.\n"
     ]
    }
   ],
   "source": [
    "# Training\n",
    "import time\n",
    "\n",
    "start_time = time.time()\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=5e-5, weight_decay=0.1)\n",
    "num_epochs = 10\n",
    "train_losses, val_losses, train_accs, val_accs, examples_seen = train_classifier_simple(\n",
    "    model, train_loader, val_loader, optimizer, device, num_epochs=num_epochs, eval_freq=50, eval_iter=5\n",
    ")\n",
    "end_time = time.time()\n",
    "execution_time_minutes = (end_time-start_time)/60\n",
    "print(f\"Training completed in {execution_time_minutes:.2f} minutes.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "2e87475f-666d-48d3-80da-1c8fe9022116",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 500x300 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plot losses\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def plot_values(epochs_seen, examples_seen, train_values, val_values, label=\"loss\"):\n",
    "    fig, ax1 = plt.subplots(figsize=(5,3))\n",
    "    ax1.plot(epochs_seen, train_values, label=f\"Training {label}\")\n",
    "    ax1.plot(epochs_seen, val_values, linestyle=\"-.\", label=f\"Validation {label}\")\n",
    "    ax1.set_xlabel(\"Epochs\")\n",
    "    ax1.set_ylabel(label.capitalize())\n",
    "    ax1.legend()\n",
    "\n",
    "    # Invisible plot for aligning ticks\n",
    "    ax2 = ax1.twiny()\n",
    "    ax2.plot(examples_seen, train_values, alpha=0)\n",
    "    ax2.set_xlabel(\"Examples seen\")\n",
    "\n",
    "    fig.tight_layout()\n",
    "    plt.savefig(f\"{label}-plt.pdf\")\n",
    "    plt.show()\n",
    "\n",
    "epochs_tensor = torch.linspace(0, num_epochs, len(train_losses))\n",
    "examples_seen_tensor = torch.linspace(0, examples_seen, len(train_losses)) # examples_seen: 5200, len(train_losses): 13\n",
    "plot_values(epochs_tensor, examples_seen_tensor, train_losses, val_losses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "0a1a3091-a1bd-4cc2-8f3d-cf2f3a44680a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 500x300 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# plot accuracy \n",
    "epochs_tensor = torch.linspace(0, num_epochs, len(train_accs))\n",
    "examples_seen_tensor = torch.linspace(0, examples_seen, len(train_accs))\n",
    "plot_values(epochs_tensor, examples_seen_tensor, train_accs, val_accs, label=\"accuracy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "7d8ecf93-eb35-4601-aeef-c335f0e6a5ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training accuracy: 98.94%\n",
      "Validation accuracy: 97.99%\n",
      "Test accuracy: 96.33%\n"
     ]
    }
   ],
   "source": [
    "# Print dataset accuracies\n",
    "train_accuracy = calc_accuracy_loader(train_loader, model, device)\n",
    "val_accuracy = calc_accuracy_loader(val_loader, model, device)\n",
    "test_accuracy = calc_accuracy_loader(test_loader, model, device)\n",
    "print(f\"Training accuracy: {train_accuracy*100:.2f}%\")\n",
    "print(f\"Validation accuracy: {val_accuracy*100:.2f}%\")\n",
    "print(f\"Test accuracy: {test_accuracy*100:.2f}%\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6bcacd4f-2e13-49e4-be80-efc50a68e18d",
   "metadata": {},
   "source": [
    "## Using LLM as a spam classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "82117073-29a5-4f7b-b6d9-1cdd615ceb4e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "spam\n"
     ]
    }
   ],
   "source": [
    "def classify_review(text, model, tokenizer, device, max_length=None, pad_token_id=50256):\n",
    "    model.eval()\n",
    "    input_ids = tokenizer.encode(text) # list of ints\n",
    "    # pos_emb: (context_length,embed_dim)=(1024,768)\n",
    "    supported_context_length = model.pos_emb.weight.shape[0] # 1024\n",
    "    input_ids = input_ids[:min(max_length, supported_context_length)]\n",
    "    # pad input to reach 103 tokens length\n",
    "    input_ids += [pad_token_id] * (max_length-len(input_ids))\n",
    "    input_tensor = torch.tensor(\n",
    "        input_ids, device=device\n",
    "    ).unsqueeze(0) # (1,103)\n",
    "    with torch.no_grad():\n",
    "        logits = model(input_tensor)[:,-1,:] # (1,103,2)=>(1,2)\n",
    "    predicted_label = torch.argmax(logits, dim=-1).item()\n",
    "\n",
    "    return \"spam\" if predicted_label == 1 else \"not spam\"\n",
    "\n",
    "text_1 = \"You are a winner you have been specially selected to receive $1000 cash or $2000 award.\"\n",
    "print(classify_review(text_1, model, tokenizer, device, max_length=train_dataset.max_length)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "d182e691-98f9-432f-8443-41821cc15787",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "not spam\n"
     ]
    }
   ],
   "source": [
    "text_2 = \"Hey, just wanted to check if we're still on for dinner tonight? Let me know!\"\n",
    "print(classify_review(text_2, model, tokenizer, device, max_length=train_dataset.max_length))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "5d45757b-d0bf-4128-95a5-0376ea527524",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save model for latter use\n",
    "torch.save(model.state_dict(), \"review_classifier.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "e5d1d8c7-9668-4ab4-bb8a-e41a912425be",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load saved model\n",
    "model_state_dict = torch.load(\"review_classifier.pth\", map_location=device)\n",
    "model.load_state_dict(model_state_dict)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
