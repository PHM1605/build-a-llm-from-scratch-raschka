{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "829eb91c-8c19-4d34-8a62-300f561b6bac",
   "metadata": {},
   "source": [
    "## Preparing the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "8194434d-d64b-4912-92e4-3da2c154292f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Label</th>\n",
       "      <th>Text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ham</td>\n",
       "      <td>Go until jurong point, crazy.. Available only ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ham</td>\n",
       "      <td>Ok lar... Joking wif u oni...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>spam</td>\n",
       "      <td>Free entry in 2 a wkly comp to win FA Cup fina...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ham</td>\n",
       "      <td>U dun say so early hor... U c already then say...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ham</td>\n",
       "      <td>Nah I don't think he goes to usf, he lives aro...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5567</th>\n",
       "      <td>spam</td>\n",
       "      <td>This is the 2nd time we have tried 2 contact u...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5568</th>\n",
       "      <td>ham</td>\n",
       "      <td>Will Ì_ b going to esplanade fr home?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5569</th>\n",
       "      <td>ham</td>\n",
       "      <td>Pity, * was in mood for that. So...any other s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5570</th>\n",
       "      <td>ham</td>\n",
       "      <td>The guy did some bitching but I acted like i'd...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5571</th>\n",
       "      <td>ham</td>\n",
       "      <td>Rofl. Its true to its name</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5572 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Label                                               Text\n",
       "0      ham  Go until jurong point, crazy.. Available only ...\n",
       "1      ham                      Ok lar... Joking wif u oni...\n",
       "2     spam  Free entry in 2 a wkly comp to win FA Cup fina...\n",
       "3      ham  U dun say so early hor... U c already then say...\n",
       "4      ham  Nah I don't think he goes to usf, he lives aro...\n",
       "...    ...                                                ...\n",
       "5567  spam  This is the 2nd time we have tried 2 contact u...\n",
       "5568   ham              Will Ì_ b going to esplanade fr home?\n",
       "5569   ham  Pity, * was in mood for that. So...any other s...\n",
       "5570   ham  The guy did some bitching but I acted like i'd...\n",
       "5571   ham                         Rofl. Its true to its name\n",
       "\n",
       "[5572 rows x 2 columns]"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "import pandas as pd \n",
    "data_file_path = \"spam.csv\"\n",
    "df = pd.read_csv(data_file_path, encoding=\"latin-1\")\n",
    "df = df.iloc[:,:2]\n",
    "df.columns = [\"Label\", \"Text\"]\n",
    "df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "43680a4c-fbf5-4f83-82a9-4dcaeb662f3d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Label\n",
      "ham     4825\n",
      "spam     747\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Number of each class <ham> or <spam>\n",
    "print(df[\"Label\"].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "e9e61d12-144f-4c35-ab96-7505c5d4ec62",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Label\n",
      "ham     747\n",
      "spam    747\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Under-sampling to balance dataset\n",
    "def create_balanced_dataset(df):\n",
    "    num_spam = df[df[\"Label\"]==\"spam\"].shape[0]\n",
    "    ham_subset = df[df[\"Label\"]==\"ham\"].sample(\n",
    "        num_spam, random_state=123\n",
    "    )\n",
    "    balanced_df = pd.concat([\n",
    "        ham_subset, df[df[\"Label\"] == \"spam\"]\n",
    "    ])\n",
    "    return balanced_df \n",
    "balanced_df = create_balanced_dataset(df)\n",
    "print(balanced_df[\"Label\"].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "d5e02691-9d96-4673-83ad-f28f52b2eb24",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert classes to 0 and 1\n",
    "balanced_df[\"Label\"] = balanced_df[\"Label\"].map({\"ham\":0, \"spam\":1})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "56f716b4-f075-4bbd-9575-6d5aa6df0e95",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train/val/test split to 0.7/0.1/0.2\n",
    "def random_split(df, train_frac, validation_frac):\n",
    "    # shuffle DataFrame\n",
    "    df = df.sample(frac=1, random_state=123).reset_index(drop=True)\n",
    "    train_end = int(len(df) * train_frac)\n",
    "    validation_end = train_end + int(len(df) * validation_frac)\n",
    "    \n",
    "    train_df = df[:train_end]\n",
    "    validation_df = df[train_end:validation_end]\n",
    "    test_df = df[validation_end:]\n",
    "    \n",
    "    return train_df, validation_df, test_df \n",
    "\n",
    "train_df, validation_df, test_df = random_split(balanced_df, 0.7, 0.1)\n",
    "\n",
    "train_df.to_csv(\"train.csv\", index=None)\n",
    "validation_df.to_csv(\"validation.csv\", index=None)\n",
    "test_df.to_csv(\"test.csv\", index=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "576d1dd7-c21b-4f1e-8f68-e3b2c0dfcd0d",
   "metadata": {},
   "source": [
    "## Creating data loaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "09e6c669-f4e3-43d8-a8e6-c20b54325edf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[50256]\n"
     ]
    }
   ],
   "source": [
    "import tiktoken\n",
    "tokenizer = tiktoken.get_encoding(\"gpt2\")\n",
    "print(tokenizer.encode(\"<|endoftext|>\", allowed_special={\"<|endoftext|>\"}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "4501e58a-8f61-4815-bbbd-c2f550c38f56",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset max length:  103\n"
     ]
    }
   ],
   "source": [
    "# Setting up Dataset\n",
    "import torch\n",
    "from torch.utils.data import Dataset \n",
    "\n",
    "class SpamDataset(Dataset):\n",
    "    # csv_file: 2 columns of \"Label\" (0 or 1) and \"Text\" (string)\n",
    "    def __init__(self, csv_file, tokenizer, max_length=None, pad_token_id=50256):\n",
    "        self.data = pd.read_csv(csv_file)\n",
    "        # [[3,643,2], [7,1],...]\n",
    "        self.encoded_texts = [\n",
    "            tokenizer.encode(text) for text in self.data[\"Text\"]\n",
    "        ]\n",
    "        \n",
    "        if max_length is None:\n",
    "            self.max_length = self._longest_encoded_length()\n",
    "        else: # truncate sentence if too long\n",
    "            self.max_length = max_length\n",
    "            self.encoded_texts = [\n",
    "                encoded_text[:self.max_length]\n",
    "                for encoded_text in self.encoded_texts\n",
    "            ]\n",
    "        # pad sequence with <50256> to the length of longest sequence\n",
    "        self.encoded_texts = [\n",
    "            encoded_text + [pad_token_id]*(self.max_length-len(encoded_text))\n",
    "            for encoded_text in self.encoded_texts\n",
    "        ]\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        encoded = self.encoded_texts[index] # will have same length <max_length>\n",
    "        label = self.data.iloc[index][\"Label\"]\n",
    "        return (\n",
    "            torch.tensor(encoded, dtype=torch.long), # (max_length,)\n",
    "            torch.tensor(label, dtype=torch.long) # (1,)\n",
    "        )\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def _longest_encoded_length(self):\n",
    "        max_length = 0\n",
    "        for encoded_text in self.encoded_texts:\n",
    "            encoded_length = len(encoded_text)\n",
    "            if encoded_length > max_length:\n",
    "                max_length = encoded_length\n",
    "        return max_length\n",
    "\n",
    "train_dataset = SpamDataset(\n",
    "    csv_file=\"train.csv\",\n",
    "    max_length=None,\n",
    "    tokenizer=tokenizer\n",
    ")\n",
    "print(\"Dataset max length: \", train_dataset.max_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "b54e2f67-aff9-44d4-b31f-8b071f650f7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pad & truncate val/test dataset to <max-length> OF TRAIN\n",
    "val_dataset = SpamDataset(\n",
    "    csv_file=\"validation.csv\",\n",
    "    max_length=train_dataset.max_length,\n",
    "    tokenizer=tokenizer\n",
    ")\n",
    "test_dataset = SpamDataset(\n",
    "    csv_file=\"test.csv\",\n",
    "    max_length=train_dataset.max_length,\n",
    "    tokenizer=tokenizer\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "4e40a4d5-74a5-4ae3-a99b-e5d1c4a0380a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create DataLoaders\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "num_workers = 0\n",
    "batch_size = 8\n",
    "torch.manual_seed(123)\n",
    "\n",
    "# each batch: X: <batch,max-length>=<8,103>; y: <batch,>=<8,>\n",
    "train_loader = DataLoader(\n",
    "    dataset=train_dataset,\n",
    "    batch_size=batch_size,\n",
    "    shuffle=True,\n",
    "    num_workers=num_workers,\n",
    "    drop_last=True\n",
    ")\n",
    "val_loader = DataLoader(\n",
    "    dataset=val_dataset,\n",
    "    batch_size=batch_size,\n",
    "    num_workers=num_workers,\n",
    "    drop_last=False\n",
    ")\n",
    "test_loader = DataLoader(\n",
    "    dataset=test_dataset,\n",
    "    batch_size=batch_size,\n",
    "    num_workers=num_workers,\n",
    "    drop_last=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "c77f1c1e-474c-4198-8535-d484c7804390",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input batch dimensions: torch.Size([8, 103])\n",
      "Label batch dimensions: torch.Size([8])\n"
     ]
    }
   ],
   "source": [
    "# Print batch shape\n",
    "for input_batch, target_batch in train_loader:\n",
    "    pass\n",
    "print(\"Input batch dimensions:\", input_batch.shape)\n",
    "print(\"Label batch dimensions:\", target_batch.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "907e3d8a-1ede-435d-9937-426e39c53572",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "130 training batches\n",
      "19 validation batches\n",
      "38 test batches\n"
     ]
    }
   ],
   "source": [
    "# How many batches in each dataset\n",
    "print(f\"{len(train_loader)} training batches\")\n",
    "print(f\"{len(val_loader)} validation batches\")\n",
    "print(f\"{len(test_loader)} test batches\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f617a20e-f8ae-42bc-ae56-996b1d19342c",
   "metadata": {},
   "source": [
    "## Initialize model with pre-trained weights (prepare for fine-tuning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "0ac7cd83-ffdf-42a1-8746-8865116bb737",
   "metadata": {},
   "outputs": [],
   "source": [
    "CHOOSE_MODEL = \"gpt2-small (124M)\"\n",
    "INPUT_PROMPT = \"Every effort moves\"\n",
    "BASE_CONFIG = {\n",
    "    \"vocab_size\": 50257,\n",
    "    \"context_length\": 1024,\n",
    "    \"drop_rate\": 0.0,\n",
    "    \"qkv_bias\": True\n",
    "}\n",
    "model_configs = {\n",
    "    \"gpt2-small (124M)\": {\"emb_dim\":768, \"n_layers\":12, \"n_heads\":12},\n",
    "    \"gpt2-medium (355M)\": {\"emb_dim\":1024, \"n_layers\":24, \"n_heads\":16},\n",
    "    \"gpt2-large (774M)\": {\"emb_dim\":1280, \"n_layers\":36, \"n_heads\":20},\n",
    "    \"gpt2-xl (1558M)\": {\"emb_dim\":1600, \"n_layers\":48, \"n_heads\":25}\n",
    "}\n",
    "BASE_CONFIG.update(model_configs[CHOOSE_MODEL])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "3651505e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "from gpt_download import download_and_load_gpt2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "7236b412",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LayerNorm(nn.Module):\n",
    "    def __init__(self, emb_dim):\n",
    "        super().__init__()\n",
    "        self.eps = 1e-5\n",
    "        # optional trainable params\n",
    "        self.scale = nn.Parameter(torch.ones(emb_dim))\n",
    "        self.shift = nn.Parameter(torch.zeros(emb_dim))\n",
    "  \n",
    "    def forward(self, x):\n",
    "        mean = x.mean(dim=-1, keepdim=True) # (batch,1)\n",
    "        # biased variance: divided by 1/(n-1)\n",
    "        # unbiased variance: divided by 1/n\n",
    "        var = x.var(dim=-1, keepdim=True, unbiased=False) # (batch,1)\n",
    "        norm_x = (x-mean) / torch.sqrt(var+self.eps) # (batch,emb_dim)\n",
    "        return self.scale * norm_x + self.shift # (batch,emb_dim)\n",
    "        \n",
    "class GeLU(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "\n",
    "    def forward(self, x):\n",
    "        return 0.5*x*(1+torch.tanh( torch.sqrt(torch.tensor(2.0/torch.pi))*(x+0.044715*torch.pow(x,3)) ))\n",
    "\n",
    "class FeedForward(nn.Module):\n",
    "    def __init__(self, cfg):\n",
    "        super().__init__()\n",
    "        self.layers = nn.Sequential(\n",
    "          nn.Linear(cfg[\"emb_dim\"], 4*cfg[\"emb_dim\"]),\n",
    "          GeLU(),\n",
    "          nn.Linear(4*cfg[\"emb_dim\"], cfg[\"emb_dim\"])\n",
    "        )\n",
    "  \n",
    "    def forward(self, x):\n",
    "        return self.layers(x)\n",
    "\n",
    "class MultiHeadAttention(nn.Module):\n",
    "    def __init__(self, d_in, d_out, context_length, dropout, num_heads, qkv_bias=False):\n",
    "        super().__init__()\n",
    "        assert (d_out % num_heads == 0), \"d_out must be divisible by num_heads\"\n",
    "        self.d_out = d_out # 4\n",
    "        self.num_heads = num_heads # 2\n",
    "        self.head_dim = d_out // num_heads # 2\n",
    "\n",
    "        # bigger weight matrices\n",
    "        self.W_query = nn.Linear(d_in, d_out, bias=qkv_bias) # (3,4)\n",
    "        self.W_key = nn.Linear(d_in, d_out, bias=qkv_bias) # (3,4)\n",
    "        self.W_value = nn.Linear(d_in, d_out, bias=qkv_bias) # (3,4)\n",
    "\n",
    "        self.out_proj = nn.Linear(d_out, d_out)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        self.register_buffer(\n",
    "            \"mask\",\n",
    "            torch.triu(torch.ones(context_length, context_length), diagonal=1)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        b, num_tokens, d_in = x.shape\n",
    "\n",
    "        # compute big kqv matrices\n",
    "        keys = self.W_key(x) # (b,n,3)=>(b,n_token,4)\n",
    "        queries = self.W_query(x) # (b,n,3)=>(b,n_token,4)\n",
    "        values = self.W_value(x) # (b,n,3)=>(b,n_token,4)\n",
    "        # ... then splits\n",
    "        keys = keys.view(b, num_tokens, self.num_heads, self.head_dim) # (b,n_token,n_head=2,head_dim=2)\n",
    "        queries = queries.view(b, num_tokens, self.num_heads, self.head_dim) # (b,n_token,n_head,head_dim)\n",
    "        values = values.view(b, num_tokens, self.num_heads, self.head_dim) # (b,n_token,n_head,head_dim)\n",
    "        # swap <num_heads> to after-batch location\n",
    "        keys = keys.transpose(1,2) # (b,n_head=2,n_token,head_dim=2)\n",
    "        queries = queries.transpose(1,2) # (b,n_head=2,n_token,head_dim=2)\n",
    "        values = values.transpose(1,2) # (b,n_head=2,n_token,head_dim=2)\n",
    "\n",
    "        attn_scores = queries @ keys.transpose(2,3) # (b,n_head,n_token,head_dim)@(b,n_head,head_dim,n_token)=>(b,n_head,n_token,n_token)\n",
    "        mask_bool = self.mask.bool()[:num_tokens,:num_tokens]\n",
    "        attn_scores.masked_fill_(mask_bool, -torch.inf) # (n,n) with upper-right is -inf\n",
    "        attn_weights = torch.softmax(\n",
    "            attn_scores / keys.shape[-1]**0.5, dim=-1)\n",
    "        attn_weights = self.dropout(attn_weights) # (b,n_head,n_token,n_token)\n",
    "\n",
    "        context_vec = (attn_weights @ values).transpose(1,2) # (b,n_head,n_token,head_dim=2)=>transpose to (b,n_token,n_head,head_dim=2)\n",
    "        context_vec = context_vec.contiguous().view(b,num_tokens,self.d_out) # (b,n_token,n_head*head_dim)=(b,n_token,4)\n",
    "        context_vec = self.out_proj(context_vec) # (b,n_token,4)\n",
    "\n",
    "        return context_vec # (b,n_token,4)\n",
    "\n",
    "class TransformerBlock(nn.Module):\n",
    "    def __init__(self, cfg):\n",
    "        super().__init__()\n",
    "        self.att = MultiHeadAttention(\n",
    "            d_in=cfg[\"emb_dim\"],\n",
    "            d_out=cfg[\"emb_dim\"],\n",
    "            context_length=cfg[\"context_length\"],\n",
    "            num_heads=cfg[\"n_heads\"],\n",
    "            dropout=cfg[\"drop_rate\"],\n",
    "            qkv_bias=cfg[\"qkv_bias\"]\n",
    "        )\n",
    "        self.ff = FeedForward(cfg)\n",
    "        self.norm1 = LayerNorm(cfg[\"emb_dim\"])\n",
    "        self.norm2 = LayerNorm(cfg[\"emb_dim\"])\n",
    "        self.drop_shortcut = nn.Dropout(cfg[\"drop_rate\"])\n",
    "\n",
    "    def forward(self, x):\n",
    "        shortcut = x\n",
    "        x = self.norm1(x)\n",
    "        x = self.att(x)\n",
    "        x = self.drop_shortcut(x)\n",
    "        x = x + shortcut \n",
    "\n",
    "        shortcut = x\n",
    "        x = self.norm2(x)\n",
    "        x = self.ff(x)\n",
    "        x = self.drop_shortcut(x)\n",
    "        x = x + shortcut \n",
    "        return x \n",
    "\n",
    "class GPTModel(nn.Module):\n",
    "    def __init__(self, cfg):\n",
    "        super().__init__()\n",
    "        self.tok_emb = nn.Embedding(cfg[\"vocab_size\"], cfg[\"emb_dim\"])\n",
    "        self.pos_emb = nn.Embedding(cfg[\"context_length\"], cfg[\"emb_dim\"])\n",
    "        self.drop_emb = nn.Dropout(cfg[\"drop_rate\"])\n",
    "        self.trf_blocks = nn.Sequential(\n",
    "            *[TransformerBlock(cfg) for _ in range(cfg[\"n_layers\"])])\n",
    "        self.final_norm = LayerNorm(cfg[\"emb_dim\"])\n",
    "        self.out_head = nn.Linear(cfg[\"emb_dim\"], cfg[\"vocab_size\"], bias=False)\n",
    "\n",
    "    def forward(self, in_idx):\n",
    "        # in_idx: (batch,seq_len), each element is a token-index (integer shows location)\n",
    "        batch_size, seq_len = in_idx.shape\n",
    "        tok_embeds = self.tok_emb(in_idx) # (batch,seq_len)=>(batch,seq_len,emb_dim)\n",
    "        pos_embeds = self.pos_emb(torch.arange(seq_len, device=in_idx.device)) # (1,seq_len)=>(1,seq_len,emb_dim)\n",
    "        x = tok_embeds + pos_embeds # (batch,seq_len,emb_dim)\n",
    "        x = self.drop_emb(x) # (batch,seq_len,emb_dim)\n",
    "        x = self.trf_blocks(x) # (batch,seq_len,emb_dim)\n",
    "        x = self.final_norm(x) # (batch,seq_len,emb_dim)\n",
    "        logits = self.out_head(x) # (batch,seq_len,vocab_len)\n",
    "        return logits\n",
    "\n",
    "# small utils function: check if <left> and <right> has matching shape\n",
    "# if yes then return <Parameter> as the right tensor\n",
    "def assign(left, right):\n",
    "    if left.shape != right.shape:\n",
    "        raise ValueError(f\"Shape mismatch. Left: {left.shape}, Right: {right.shape}\")\n",
    "    return torch.nn.Parameter(torch.tensor(right))\n",
    "\n",
    "def load_weights_into_gpt(gpt, params):\n",
    "    # load positional encoding\n",
    "    gpt.pos_emb.weight = assign(gpt.pos_emb.weight, params['wpe'])\n",
    "    # load token embedding\n",
    "    gpt.tok_emb.weight = assign(gpt.tok_emb.weight, params['wte'])\n",
    "    # load transformers blocks\n",
    "    for b in range(len(params[\"blocks\"])):\n",
    "        # params[\"blocks\"][b][\"attn\"]: <multi-head-attn> part\n",
    "        # <multi-head-attn>[\"c_attn\"]: convolution attention (of qkv) inside\n",
    "        # split to 3 parts <query>,<key>,<value>\n",
    "        q_w, k_w, v_w = np.split( params[\"blocks\"][b][\"attn\"][\"c_attn\"][\"w\"], 3, axis=-1) # each (768,768)\n",
    "        gpt.trf_blocks[b].att.W_query.weight = assign(gpt.trf_blocks[b].att.W_query.weight, q_w.T)\n",
    "        gpt.trf_blocks[b].att.W_key.weight = assign(gpt.trf_blocks[b].att.W_key.weight, k_w.T)\n",
    "        gpt.trf_blocks[b].att.W_value.weight = assign(gpt.trf_blocks[b].att.W_value.weight, v_w.T)\n",
    "\n",
    "        # bias of <attn> in <multi-head-attention>\n",
    "        q_b, k_b, v_b = np.split( params[\"blocks\"][b][\"attn\"][\"c_attn\"][\"b\"], 3, axis=-1) # each (768,)\n",
    "        gpt.trf_blocks[b].att.W_query.bias = assign(gpt.trf_blocks[b].att.W_query.bias, q_b)\n",
    "        gpt.trf_blocks[b].att.W_key.bias = assign(gpt.trf_blocks[b].att.W_key.bias, k_b)\n",
    "        gpt.trf_blocks[b].att.W_value.bias = assign(gpt.trf_blocks[b].att.W_value.bias, v_b)\n",
    "\n",
    "        # out-projection of <attn> in <multi-head-attention>\n",
    "        gpt.trf_blocks[b].att.out_proj.weight = assign(gpt.trf_blocks[b].att.out_proj.weight, params[\"blocks\"][b][\"attn\"][\"c_proj\"][\"w\"].T)\n",
    "        gpt.trf_blocks[b].att.out_proj.bias = assign(gpt.trf_blocks[b].att.out_proj.bias, params[\"blocks\"][b][\"attn\"][\"c_proj\"][\"b\"])\n",
    "\n",
    "        # feed-forward; layer0 & layer1 (layer1 is GeLU)\n",
    "        gpt.trf_blocks[b].ff.layers[0].weight = assign(gpt.trf_blocks[b].ff.layers[0].weight, params[\"blocks\"][b][\"mlp\"][\"c_fc\"][\"w\"].T)\n",
    "        gpt.trf_blocks[b].ff.layers[0].bias = assign(gpt.trf_blocks[b].ff.layers[0].bias, params[\"blocks\"][b][\"mlp\"][\"c_fc\"][\"b\"])\n",
    "        gpt.trf_blocks[b].ff.layers[2].weight = assign(gpt.trf_blocks[b].ff.layers[2].weight, params[\"blocks\"][b][\"mlp\"][\"c_proj\"][\"w\"].T)\n",
    "        gpt.trf_blocks[b].ff.layers[2].bias = assign(gpt.trf_blocks[b].ff.layers[2].bias, params[\"blocks\"][b][\"mlp\"][\"c_proj\"][\"b\"])\n",
    "\n",
    "        # layer normalization\n",
    "        gpt.trf_blocks[b].norm1.scale = assign(gpt.trf_blocks[b].norm1.scale, params[\"blocks\"][b][\"ln_1\"][\"g\"])\n",
    "        gpt.trf_blocks[b].norm1.shift = assign(gpt.trf_blocks[b].norm1.shift, params[\"blocks\"][b][\"ln_1\"][\"b\"])\n",
    "        gpt.trf_blocks[b].norm2.scale = assign(gpt.trf_blocks[b].norm2.scale, params[\"blocks\"][b][\"ln_2\"][\"g\"])\n",
    "        gpt.trf_blocks[b].norm2.shift = assign(gpt.trf_blocks[b].norm2.shift, params[\"blocks\"][b][\"ln_2\"][\"b\"])\n",
    "\n",
    "    # Final layer normalization\n",
    "    gpt.final_norm.scale = assign(gpt.final_norm.scale, params[\"g\"])\n",
    "    gpt.final_norm.shift = assign(gpt.final_norm.shift, params[\"b\"])\n",
    "    # Out weight\n",
    "    gpt.out_head.weight = assign(gpt.out_head.weight, params[\"wte\"]) # we use the token embedding weights again (\"weight tying\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "24a9bba2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File already exists and is up-to-date: gpt2/124M/checkpoint\n",
      "File already exists and is up-to-date: gpt2/124M/encoder.json\n",
      "File already exists and is up-to-date: gpt2/124M/hparams.json\n",
      "File already exists and is up-to-date: gpt2/124M/model.ckpt.data-00000-of-00001\n",
      "File already exists and is up-to-date: gpt2/124M/model.ckpt.index\n",
      "File already exists and is up-to-date: gpt2/124M/model.ckpt.meta\n",
      "File already exists and is up-to-date: gpt2/124M/vocab.bpe\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GPTModel(\n",
       "  (tok_emb): Embedding(50257, 768)\n",
       "  (pos_emb): Embedding(1024, 768)\n",
       "  (drop_emb): Dropout(p=0.0, inplace=False)\n",
       "  (trf_blocks): Sequential(\n",
       "    (0): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GeLU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.0, inplace=False)\n",
       "    )\n",
       "    (1): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GeLU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.0, inplace=False)\n",
       "    )\n",
       "    (2): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GeLU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.0, inplace=False)\n",
       "    )\n",
       "    (3): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GeLU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.0, inplace=False)\n",
       "    )\n",
       "    (4): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GeLU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.0, inplace=False)\n",
       "    )\n",
       "    (5): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GeLU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.0, inplace=False)\n",
       "    )\n",
       "    (6): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GeLU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.0, inplace=False)\n",
       "    )\n",
       "    (7): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GeLU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.0, inplace=False)\n",
       "    )\n",
       "    (8): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GeLU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.0, inplace=False)\n",
       "    )\n",
       "    (9): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GeLU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.0, inplace=False)\n",
       "    )\n",
       "    (10): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GeLU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.0, inplace=False)\n",
       "    )\n",
       "    (11): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GeLU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.0, inplace=False)\n",
       "    )\n",
       "  )\n",
       "  (final_norm): LayerNorm()\n",
       "  (out_head): Linear(in_features=768, out_features=50257, bias=False)\n",
       ")"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_size = CHOOSE_MODEL.split(\" \")[-1].lstrip(\"(\").rstrip(\")\") # 124M\n",
    "settings, params = download_and_load_gpt2(\n",
    "    model_size=model_size, models_dir=\"gpt2\"\n",
    ")\n",
    "model = GPTModel(BASE_CONFIG)\n",
    "load_weights_into_gpt(model, params)\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "e41bfc6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check model loading is successful, by generating some meaningful text\n",
    "import tiktoken\n",
    "\n",
    "def generate_text_simple(model, idx, max_new_tokens, context_size):\n",
    "    # idx: (batch, n_tokens_long)\n",
    "    for _ in range(max_new_tokens):\n",
    "        idx_cond = idx[:,-context_size:] # take last <context_size> tokens as context => (batch,context_size)\n",
    "        with torch.no_grad():\n",
    "            logits = model(idx_cond) # (batch,context_size,vocab_len)\n",
    "        logits = logits[:,-1,:] # last tokenS - (batch,vocab_len)\n",
    "        probas = torch.softmax(logits,dim=-1) # (batch,vocab_len)\n",
    "        idx_next = torch.argmax(probas, dim=-1, keepdim=True) # (batch,1)\n",
    "        idx = torch.cat((idx, idx_next), dim=1) #(batch,n_tokens_long+1)\n",
    "    return idx\n",
    "\n",
    "def text_to_token_ids(text, tokenizer):\n",
    "    encoded = tokenizer.encode(text, allowed_special={'<|endoftext|>'}) # (n_tokens,)\n",
    "    encoded_tensor = torch.tensor(encoded).unsqueeze(0) # (1,n_tokens)\n",
    "    return encoded_tensor\n",
    "\n",
    "def token_ids_to_text(token_ids, tokenizer):\n",
    "    flat = token_ids.squeeze(0) # (n_tokens,)\n",
    "    return tokenizer.decode(flat.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "a44d9909",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Every effort moves you forward.\n",
      "\n",
      "The first step is to understand the importance of your work\n"
     ]
    }
   ],
   "source": [
    "text_1 = \"Every effort moves you\"\n",
    "token_ids = generate_text_simple(\n",
    "    model=model,\n",
    "    idx=text_to_token_ids(text_1, tokenizer),\n",
    "    max_new_tokens=15,\n",
    "    context_size=BASE_CONFIG[\"context_length\"]\n",
    ")\n",
    "# token_ids: (1,n_tokens_long+max_new_tokens)\n",
    "print(token_ids_to_text(token_ids, tokenizer))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "0fd042ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Is the following text 'spam'? Answer with 'yes' or 'no': 'You are a winner you have been specially selected to receive $1000 cash or a $2000 award.'\n",
      "\n",
      "The following text 'spam'? Answer with 'yes' or 'no': 'You are a winner\n"
     ]
    }
   ],
   "source": [
    "# Try to classify spams with prompting => not good\n",
    "text_2 = (\n",
    "    \"Is the following text 'spam'? Answer with 'yes' or 'no':\"\n",
    "    \" 'You are a winner you have been specially selected to receive $1000 cash or a $2000 award.'\"\n",
    ")\n",
    "token_ids = generate_text_simple(\n",
    "    model=model,\n",
    "    idx=text_to_token_ids(text_2, tokenizer),\n",
    "    max_new_tokens=23,\n",
    "    context_size=BASE_CONFIG[\"context_length\"]\n",
    ")\n",
    "print(token_ids_to_text(token_ids, tokenizer))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e025c34",
   "metadata": {},
   "source": [
    "## Adding a classification head"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "2986f60a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPTModel(\n",
      "  (tok_emb): Embedding(50257, 768)\n",
      "  (pos_emb): Embedding(1024, 768)\n",
      "  (drop_emb): Dropout(p=0.0, inplace=False)\n",
      "  (trf_blocks): Sequential(\n",
      "    (0): TransformerBlock(\n",
      "      (att): MultiHeadAttention(\n",
      "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (dropout): Dropout(p=0.0, inplace=False)\n",
      "      )\n",
      "      (ff): FeedForward(\n",
      "        (layers): Sequential(\n",
      "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
      "          (1): GeLU()\n",
      "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
      "        )\n",
      "      )\n",
      "      (norm1): LayerNorm()\n",
      "      (norm2): LayerNorm()\n",
      "      (drop_shortcut): Dropout(p=0.0, inplace=False)\n",
      "    )\n",
      "    (1): TransformerBlock(\n",
      "      (att): MultiHeadAttention(\n",
      "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (dropout): Dropout(p=0.0, inplace=False)\n",
      "      )\n",
      "      (ff): FeedForward(\n",
      "        (layers): Sequential(\n",
      "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
      "          (1): GeLU()\n",
      "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
      "        )\n",
      "      )\n",
      "      (norm1): LayerNorm()\n",
      "      (norm2): LayerNorm()\n",
      "      (drop_shortcut): Dropout(p=0.0, inplace=False)\n",
      "    )\n",
      "    (2): TransformerBlock(\n",
      "      (att): MultiHeadAttention(\n",
      "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (dropout): Dropout(p=0.0, inplace=False)\n",
      "      )\n",
      "      (ff): FeedForward(\n",
      "        (layers): Sequential(\n",
      "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
      "          (1): GeLU()\n",
      "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
      "        )\n",
      "      )\n",
      "      (norm1): LayerNorm()\n",
      "      (norm2): LayerNorm()\n",
      "      (drop_shortcut): Dropout(p=0.0, inplace=False)\n",
      "    )\n",
      "    (3): TransformerBlock(\n",
      "      (att): MultiHeadAttention(\n",
      "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (dropout): Dropout(p=0.0, inplace=False)\n",
      "      )\n",
      "      (ff): FeedForward(\n",
      "        (layers): Sequential(\n",
      "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
      "          (1): GeLU()\n",
      "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
      "        )\n",
      "      )\n",
      "      (norm1): LayerNorm()\n",
      "      (norm2): LayerNorm()\n",
      "      (drop_shortcut): Dropout(p=0.0, inplace=False)\n",
      "    )\n",
      "    (4): TransformerBlock(\n",
      "      (att): MultiHeadAttention(\n",
      "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (dropout): Dropout(p=0.0, inplace=False)\n",
      "      )\n",
      "      (ff): FeedForward(\n",
      "        (layers): Sequential(\n",
      "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
      "          (1): GeLU()\n",
      "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
      "        )\n",
      "      )\n",
      "      (norm1): LayerNorm()\n",
      "      (norm2): LayerNorm()\n",
      "      (drop_shortcut): Dropout(p=0.0, inplace=False)\n",
      "    )\n",
      "    (5): TransformerBlock(\n",
      "      (att): MultiHeadAttention(\n",
      "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (dropout): Dropout(p=0.0, inplace=False)\n",
      "      )\n",
      "      (ff): FeedForward(\n",
      "        (layers): Sequential(\n",
      "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
      "          (1): GeLU()\n",
      "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
      "        )\n",
      "      )\n",
      "      (norm1): LayerNorm()\n",
      "      (norm2): LayerNorm()\n",
      "      (drop_shortcut): Dropout(p=0.0, inplace=False)\n",
      "    )\n",
      "    (6): TransformerBlock(\n",
      "      (att): MultiHeadAttention(\n",
      "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (dropout): Dropout(p=0.0, inplace=False)\n",
      "      )\n",
      "      (ff): FeedForward(\n",
      "        (layers): Sequential(\n",
      "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
      "          (1): GeLU()\n",
      "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
      "        )\n",
      "      )\n",
      "      (norm1): LayerNorm()\n",
      "      (norm2): LayerNorm()\n",
      "      (drop_shortcut): Dropout(p=0.0, inplace=False)\n",
      "    )\n",
      "    (7): TransformerBlock(\n",
      "      (att): MultiHeadAttention(\n",
      "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (dropout): Dropout(p=0.0, inplace=False)\n",
      "      )\n",
      "      (ff): FeedForward(\n",
      "        (layers): Sequential(\n",
      "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
      "          (1): GeLU()\n",
      "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
      "        )\n",
      "      )\n",
      "      (norm1): LayerNorm()\n",
      "      (norm2): LayerNorm()\n",
      "      (drop_shortcut): Dropout(p=0.0, inplace=False)\n",
      "    )\n",
      "    (8): TransformerBlock(\n",
      "      (att): MultiHeadAttention(\n",
      "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (dropout): Dropout(p=0.0, inplace=False)\n",
      "      )\n",
      "      (ff): FeedForward(\n",
      "        (layers): Sequential(\n",
      "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
      "          (1): GeLU()\n",
      "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
      "        )\n",
      "      )\n",
      "      (norm1): LayerNorm()\n",
      "      (norm2): LayerNorm()\n",
      "      (drop_shortcut): Dropout(p=0.0, inplace=False)\n",
      "    )\n",
      "    (9): TransformerBlock(\n",
      "      (att): MultiHeadAttention(\n",
      "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (dropout): Dropout(p=0.0, inplace=False)\n",
      "      )\n",
      "      (ff): FeedForward(\n",
      "        (layers): Sequential(\n",
      "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
      "          (1): GeLU()\n",
      "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
      "        )\n",
      "      )\n",
      "      (norm1): LayerNorm()\n",
      "      (norm2): LayerNorm()\n",
      "      (drop_shortcut): Dropout(p=0.0, inplace=False)\n",
      "    )\n",
      "    (10): TransformerBlock(\n",
      "      (att): MultiHeadAttention(\n",
      "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (dropout): Dropout(p=0.0, inplace=False)\n",
      "      )\n",
      "      (ff): FeedForward(\n",
      "        (layers): Sequential(\n",
      "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
      "          (1): GeLU()\n",
      "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
      "        )\n",
      "      )\n",
      "      (norm1): LayerNorm()\n",
      "      (norm2): LayerNorm()\n",
      "      (drop_shortcut): Dropout(p=0.0, inplace=False)\n",
      "    )\n",
      "    (11): TransformerBlock(\n",
      "      (att): MultiHeadAttention(\n",
      "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (dropout): Dropout(p=0.0, inplace=False)\n",
      "      )\n",
      "      (ff): FeedForward(\n",
      "        (layers): Sequential(\n",
      "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
      "          (1): GeLU()\n",
      "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
      "        )\n",
      "      )\n",
      "      (norm1): LayerNorm()\n",
      "      (norm2): LayerNorm()\n",
      "      (drop_shortcut): Dropout(p=0.0, inplace=False)\n",
      "    )\n",
      "  )\n",
      "  (final_norm): LayerNorm()\n",
      "  (out_head): Linear(in_features=768, out_features=50257, bias=False)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "a764675b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# First freeze every layers\n",
    "for param in model.parameters():\n",
    "    param.requires_grad = False\n",
    "# Replace last layer\n",
    "torch.manual_seed(123)\n",
    "num_classes = 2\n",
    "model.out_head = torch.nn.Linear(\n",
    "    in_features=BASE_CONFIG[\"emb_dim\"],\n",
    "    out_features=num_classes\n",
    ")\n",
    "# Make the last <transformer> block AND final <LayerNorm> trainable\n",
    "for param in model.trf_blocks[-1].parameters():\n",
    "    param.requires_grad = True\n",
    "for param in model.final_norm.parameters():\n",
    "    param.requires_grad = True "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "da58776b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Inputs: tensor([[5211,  345,  423,  640]])\n",
      "Inputs dimensions: torch.Size([1, 4])\n"
     ]
    }
   ],
   "source": [
    "# Try feeding an example text\n",
    "inputs = tokenizer.encode(\"Do you have time\") # list of 4 ints\n",
    "inputs = torch.tensor(inputs).unsqueeze(0) # (batch,n_token)=(1,4)\n",
    "print(\"Inputs:\", inputs)\n",
    "print(\"Inputs dimensions:\", inputs.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "f5b96657",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Outputs:\n",
      " tensor([[[-1.5854,  0.9904],\n",
      "         [-3.7235,  7.4548],\n",
      "         [-2.2661,  6.6049],\n",
      "         [-3.5983,  3.9902]]])\n",
      "Outputs dimensions: torch.Size([1, 4, 2])\n",
      "Last output token: tensor([[-3.5983,  3.9902]])\n"
     ]
    }
   ],
   "source": [
    "# Prediction output => take last token\n",
    "with torch.no_grad():\n",
    "    outputs = model(inputs)\n",
    "print(\"Outputs:\\n\", outputs) # (batch,n_token,out_dim)=(1,4,2)\n",
    "print(\"Outputs dimensions:\", outputs.shape)\n",
    "print(\"Last output token:\", outputs[:,-1,:])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "603eee66",
   "metadata": {},
   "source": [
    "## Calculating the classification loss and accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "60a1798e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Last output token: tensor([[-3.5983,  3.9902]])\n",
      "Class label: 1\n"
     ]
    }
   ],
   "source": [
    "# Current class prediction: not correct\n",
    "print(\"Last output token:\", outputs[:,-1,:]) # (1,2)\n",
    "probas = torch.softmax(outputs[:,-1,:], dim=-1) # (1,2)\n",
    "label = torch.argmax(probas)\n",
    "print(\"Class label:\", label.item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "9f68a380",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculating classification accuracy\n",
    "def calc_accuracy_loader(data_loader, model, device, num_batches=None):\n",
    "    model.eval()\n",
    "    correct_predictions, num_examples = 0, 0\n",
    "    if num_batches is None:\n",
    "        num_batches = len(data_loader)\n",
    "    else:\n",
    "        num_batches = min(num_batches, len(data_loader))\n",
    "    \n",
    "    # <input_batch>: (batch,n_words)=(8,103)\n",
    "    # <target_batch>: (batch,)=(8,)\n",
    "    for i, (input_batch, target_batch) in enumerate(data_loader):\n",
    "        if i < num_batches:\n",
    "            input_batch = input_batch.to(device)\n",
    "            target_batch = target_batch.to(device)\n",
    "            with torch.no_grad():\n",
    "                logits = model(input_batch)[:,-1,:] # last of (batch,n_words,n_class)=>(batch,2)\n",
    "            predicted_labels = torch.argmax(logits, dim=-1) # (batch,)\n",
    "            \n",
    "            num_examples += predicted_labels.shape[0]\n",
    "            correct_predictions += (predicted_labels==target_batch).sum().item()\n",
    "        else:\n",
    "            break\n",
    "    return correct_predictions / num_examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "2cce05a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training accuracy: 53.75%\n",
      "Validation accuracy: 45.00%\n",
      "Test accuracy: 48.75%\n"
     ]
    }
   ],
   "source": [
    "# evaluate accuracy over 10 batches\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model.to(device)\n",
    "train_accuracy = calc_accuracy_loader(\n",
    "    train_loader, model, device, num_batches=10\n",
    ")\n",
    "val_accuracy = calc_accuracy_loader(\n",
    "    val_loader, model, device, num_batches=10\n",
    ")\n",
    "test_accuracy = calc_accuracy_loader(\n",
    "    test_loader, model, device, num_batches=10\n",
    ")\n",
    "print(f\"Training accuracy: {train_accuracy*100:.2f}%\")\n",
    "print(f\"Validation accuracy: {val_accuracy*100:.2f}%\")\n",
    "print(f\"Test accuracy: {test_accuracy*100:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "dc6166ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for classification: we use <cross-entropy> loss of the last token row\n",
    "def calc_loss_batch(input_batch, target_batch, model, device):\n",
    "    input_batch = input_batch.to(device) # (batch,n_words)\n",
    "    target_batch = target_batch.to(device) # (batch,)\n",
    "    logits = model(input_batch)[:,-1,:] # (batch,n_word,n_class)=>(batch,n_class)\n",
    "    loss = torch.nn.functional.cross_entropy(logits, target_batch)\n",
    "    return loss\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "eb9b05bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_loss_loader(data_loader, model, device, num_batches=None):\n",
    "    total_loss = 0.\n",
    "    if len(data_loader) == 0:\n",
    "        return float(\"nan\")\n",
    "    elif num_batches is None:\n",
    "        num_batches = len(data_loader)\n",
    "    else:\n",
    "        num_batches = min(num_batches, len(data_loader))\n",
    "    for i, (input_batch, target_batch) in enumerate(data_loader):\n",
    "        if i<num_batches:\n",
    "            loss = calc_loss_batch(\n",
    "                input_batch, target_batch, model, device\n",
    "            )\n",
    "            total_loss += loss.item()\n",
    "        else:\n",
    "            break\n",
    "    return total_loss / num_batches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "ab09e8d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 2.322\n",
      "Validation loss: 2.558\n",
      "Test loss: 2.316\n"
     ]
    }
   ],
   "source": [
    "# Calculate loss for train/val/test dataset\n",
    "with torch.no_grad():\n",
    "    train_loss = calc_loss_loader(\n",
    "        train_loader, model, device, num_batches=5\n",
    "    )\n",
    "    val_loss = calc_loss_loader(\n",
    "        val_loader, model, device, num_batches=5\n",
    "    )\n",
    "    test_loss = calc_loss_loader(\n",
    "        test_loader, model, device, num_batches=5\n",
    "    )\n",
    "print(f\"Training loss: {train_loss:.3f}\")\n",
    "print(f\"Validation loss: {val_loss:.3f}\")\n",
    "print(f\"Test loss: {test_loss:.3f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5809826",
   "metadata": {},
   "source": [
    "## Fine-tuning model on supervised data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "523e85a8-c69b-4372-babc-5378fa5e1e9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# eval_iter: num_batches to evaluate accuracy (of train/val)\n",
    "def evaluate_model(model, train_loader, val_loader, device, eval_iter):\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        train_loss = calc_loss_loader(train_loader, model, device, num_batches=eval_iter)\n",
    "        val_loss = calc_loss_loader(train_loader, model, device, num_batches=eval_iter)\n",
    "    model.train()\n",
    "    return train_loss, val_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "8e9abca3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_classifier_simple(model, train_loader, val_loader, optimizer, device, num_epochs, eval_freq, eval_iter):\n",
    "    # eval_iter: num_batches to evaluate accuracy (of train/val)\n",
    "    train_losses, val_losses, train_accs, val_accs = [], [], [], []\n",
    "    # examples_seen: add up #samples-per-batch when each batch passing\n",
    "    # global_step: add up 1 after each batch passing\n",
    "    examples_seen, global_step = 0, -1\n",
    "    for epoch in range(num_epochs):\n",
    "        model.train()\n",
    "        for input_batch, target_batch in train_loader:\n",
    "            optimizer.zero_grad()\n",
    "            loss = calc_loss_batch(input_batch, target_batch, model, device)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            examples_seen += input_batch.shape[0]\n",
    "            global_step += 1\n",
    "            if global_step % eval_freq == 0:\n",
    "                train_loss, val_loss = evaluate_model(model, train_loader, val_loader, device, eval_iter)\n",
    "                train_losses.append(train_loss)\n",
    "                val_losses.append(val_loss)\n",
    "                print(f\"Ep {epoch+1} (Step {global_step:06d}): Train loss {train_loss:.3f}, Val loss {val_loss:.3f}\")\n",
    "        train_accuracy = calc_accuracy_loader(train_loader, model, device, num_batches=eval_iter)\n",
    "        val_accuracy = calc_accuracy_loader(val_loader, model, device, num_batches=eval_iter)\n",
    "        print(f\"Training accuracy: {train_accuracy*100:.2f}% | \", end=\"\")\n",
    "        print(f\"Validation accuracy: {val_accuracy*100:.2f}%\")\n",
    "        train_accs.append(train_accuracy)\n",
    "        val_accs.append(val_accuracy)\n",
    "    \n",
    "    return train_losses, val_losses, train_accs, val_accs, examples_seen    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "507413f7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep 1 (Step 000000): Train loss 2.015, Val loss 2.988\n",
      "Ep 1 (Step 000050): Train loss 0.645, Val loss 0.594\n",
      "Ep 1 (Step 000100): Train loss 0.485, Val loss 0.495\n",
      "Training accuracy: 82.50% | Validation accuracy: 95.00%\n",
      "Ep 2 (Step 000150): Train loss 0.413, Val loss 0.444\n",
      "Ep 2 (Step 000200): Train loss 0.394, Val loss 0.407\n",
      "Ep 2 (Step 000250): Train loss 0.297, Val loss 0.283\n",
      "Training accuracy: 87.50% | Validation accuracy: 97.50%\n",
      "Ep 3 (Step 000300): Train loss 0.417, Val loss 0.486\n",
      "Ep 3 (Step 000350): Train loss 0.253, Val loss 0.463\n",
      "Training accuracy: 90.00% | Validation accuracy: 90.00%\n",
      "Ep 4 (Step 000400): Train loss 0.351, Val loss 0.367\n",
      "Ep 4 (Step 000450): Train loss 0.468, Val loss 0.355\n",
      "Ep 4 (Step 000500): Train loss 0.246, Val loss 0.283\n",
      "Training accuracy: 90.00% | Validation accuracy: 92.50%\n",
      "Ep 5 (Step 000550): Train loss 0.198, Val loss 0.308\n",
      "Ep 5 (Step 000600): Train loss 0.203, Val loss 0.135\n",
      "Training accuracy: 95.00% | Validation accuracy: 97.50%\n",
      "Ep 6 (Step 000650): Train loss 0.234, Val loss 0.104\n",
      "Ep 6 (Step 000700): Train loss 0.056, Val loss 0.244\n",
      "Ep 6 (Step 000750): Train loss 0.055, Val loss 0.049\n",
      "Training accuracy: 100.00% | Validation accuracy: 100.00%\n",
      "Ep 7 (Step 000800): Train loss 0.145, Val loss 0.017\n",
      "Ep 7 (Step 000850): Train loss 0.124, Val loss 0.111\n",
      "Ep 7 (Step 000900): Train loss 0.032, Val loss 0.123\n",
      "Training accuracy: 97.50% | Validation accuracy: 100.00%\n",
      "Ep 8 (Step 000950): Train loss 0.004, Val loss 0.063\n",
      "Ep 8 (Step 001000): Train loss 0.066, Val loss 0.021\n",
      "Training accuracy: 97.50% | Validation accuracy: 100.00%\n",
      "Ep 9 (Step 001050): Train loss 0.051, Val loss 0.016\n",
      "Ep 9 (Step 001100): Train loss 0.151, Val loss 0.066\n",
      "Ep 9 (Step 001150): Train loss 0.064, Val loss 0.152\n",
      "Training accuracy: 97.50% | Validation accuracy: 100.00%\n",
      "Ep 10 (Step 001200): Train loss 0.015, Val loss 0.092\n",
      "Ep 10 (Step 001250): Train loss 0.035, Val loss 0.024\n",
      "Training accuracy: 97.50% | Validation accuracy: 100.00%\n",
      "Ep 11 (Step 001300): Train loss 0.011, Val loss 0.037\n",
      "Ep 11 (Step 001350): Train loss 0.006, Val loss 0.049\n",
      "Ep 11 (Step 001400): Train loss 0.019, Val loss 0.015\n",
      "Training accuracy: 97.50% | Validation accuracy: 100.00%\n",
      "Ep 12 (Step 001450): Train loss 0.013, Val loss 0.010\n",
      "Ep 12 (Step 001500): Train loss 0.010, Val loss 0.009\n",
      "Ep 12 (Step 001550): Train loss 0.035, Val loss 0.041\n",
      "Training accuracy: 100.00% | Validation accuracy: 100.00%\n",
      "Ep 13 (Step 001600): Train loss 0.057, Val loss 0.018\n",
      "Ep 13 (Step 001650): Train loss 0.009, Val loss 0.003\n",
      "Training accuracy: 97.50% | Validation accuracy: 100.00%\n",
      "Ep 14 (Step 001700): Train loss 0.017, Val loss 0.023\n",
      "Ep 14 (Step 001750): Train loss 0.003, Val loss 0.002\n",
      "Ep 14 (Step 001800): Train loss 0.003, Val loss 0.033\n",
      "Training accuracy: 100.00% | Validation accuracy: 100.00%\n",
      "Ep 15 (Step 001850): Train loss 0.027, Val loss 0.006\n",
      "Ep 15 (Step 001900): Train loss 0.008, Val loss 0.002\n",
      "Training accuracy: 97.50% | Validation accuracy: 100.00%\n",
      "Ep 16 (Step 001950): Train loss 0.001, Val loss 0.003\n",
      "Ep 16 (Step 002000): Train loss 0.012, Val loss 0.001\n",
      "Ep 16 (Step 002050): Train loss 0.001, Val loss 0.007\n",
      "Training accuracy: 100.00% | Validation accuracy: 100.00%\n",
      "Ep 17 (Step 002100): Train loss 0.002, Val loss 0.003\n",
      "Ep 17 (Step 002150): Train loss 0.026, Val loss 0.012\n",
      "Ep 17 (Step 002200): Train loss 0.000, Val loss 0.011\n",
      "Training accuracy: 100.00% | Validation accuracy: 100.00%\n",
      "Ep 18 (Step 002250): Train loss 0.003, Val loss 0.013\n",
      "Ep 18 (Step 002300): Train loss 0.005, Val loss 0.003\n",
      "Training accuracy: 100.00% | Validation accuracy: 100.00%\n",
      "Ep 19 (Step 002350): Train loss 0.004, Val loss 0.023\n",
      "Ep 19 (Step 002400): Train loss 0.010, Val loss 0.002\n",
      "Ep 19 (Step 002450): Train loss 0.001, Val loss 0.005\n",
      "Training accuracy: 100.00% | Validation accuracy: 100.00%\n",
      "Ep 20 (Step 002500): Train loss 0.001, Val loss 0.018\n",
      "Ep 20 (Step 002550): Train loss 0.000, Val loss 0.004\n",
      "Training accuracy: 100.00% | Validation accuracy: 100.00%\n",
      "Ep 21 (Step 002600): Train loss 0.001, Val loss 0.000\n",
      "Ep 21 (Step 002650): Train loss 0.011, Val loss 0.005\n",
      "Ep 21 (Step 002700): Train loss 0.005, Val loss 0.002\n",
      "Training accuracy: 100.00% | Validation accuracy: 100.00%\n",
      "Ep 22 (Step 002750): Train loss 0.002, Val loss 0.007\n",
      "Ep 22 (Step 002800): Train loss 0.000, Val loss 0.023\n",
      "Ep 22 (Step 002850): Train loss 0.001, Val loss 0.001\n",
      "Training accuracy: 100.00% | Validation accuracy: 100.00%\n",
      "Ep 23 (Step 002900): Train loss 0.003, Val loss 0.001\n",
      "Ep 23 (Step 002950): Train loss 0.002, Val loss 0.002\n",
      "Training accuracy: 100.00% | Validation accuracy: 100.00%\n",
      "Ep 24 (Step 003000): Train loss 0.015, Val loss 0.001\n",
      "Ep 24 (Step 003050): Train loss 0.001, Val loss 0.002\n",
      "Ep 24 (Step 003100): Train loss 0.002, Val loss 0.001\n",
      "Training accuracy: 100.00% | Validation accuracy: 100.00%\n",
      "Ep 25 (Step 003150): Train loss 0.002, Val loss 0.000\n",
      "Ep 25 (Step 003200): Train loss 0.000, Val loss 0.000\n",
      "Training accuracy: 100.00% | Validation accuracy: 100.00%\n",
      "Ep 26 (Step 003250): Train loss 0.001, Val loss 0.001\n",
      "Ep 26 (Step 003300): Train loss 0.000, Val loss 0.002\n",
      "Ep 26 (Step 003350): Train loss 0.000, Val loss 0.000\n",
      "Training accuracy: 100.00% | Validation accuracy: 100.00%\n",
      "Ep 27 (Step 003400): Train loss 0.000, Val loss 0.000\n",
      "Ep 27 (Step 003450): Train loss 0.005, Val loss 0.000\n",
      "Ep 27 (Step 003500): Train loss 0.000, Val loss 0.000\n",
      "Training accuracy: 100.00% | Validation accuracy: 100.00%\n",
      "Ep 28 (Step 003550): Train loss 0.000, Val loss 0.000\n",
      "Ep 28 (Step 003600): Train loss 0.000, Val loss 0.000\n",
      "Training accuracy: 100.00% | Validation accuracy: 100.00%\n",
      "Ep 29 (Step 003650): Train loss 0.000, Val loss 0.000\n",
      "Ep 29 (Step 003700): Train loss 0.001, Val loss 0.000\n",
      "Ep 29 (Step 003750): Train loss 0.001, Val loss 0.000\n",
      "Training accuracy: 100.00% | Validation accuracy: 100.00%\n",
      "Ep 30 (Step 003800): Train loss 0.000, Val loss 0.001\n",
      "Ep 30 (Step 003850): Train loss 0.000, Val loss 0.000\n",
      "Training accuracy: 100.00% | Validation accuracy: 100.00%\n",
      "Ep 31 (Step 003900): Train loss 0.000, Val loss 0.000\n",
      "Ep 31 (Step 003950): Train loss 0.000, Val loss 0.000\n",
      "Ep 31 (Step 004000): Train loss 0.000, Val loss 0.000\n",
      "Training accuracy: 100.00% | Validation accuracy: 100.00%\n",
      "Ep 32 (Step 004050): Train loss 0.000, Val loss 0.000\n",
      "Ep 32 (Step 004100): Train loss 0.000, Val loss 0.000\n",
      "Ep 32 (Step 004150): Train loss 0.000, Val loss 0.001\n",
      "Training accuracy: 100.00% | Validation accuracy: 100.00%\n",
      "Ep 33 (Step 004200): Train loss 0.000, Val loss 0.000\n",
      "Ep 33 (Step 004250): Train loss 0.000, Val loss 0.000\n",
      "Training accuracy: 100.00% | Validation accuracy: 100.00%\n",
      "Ep 34 (Step 004300): Train loss 0.000, Val loss 0.000\n",
      "Ep 34 (Step 004350): Train loss 0.000, Val loss 0.000\n",
      "Ep 34 (Step 004400): Train loss 0.000, Val loss 0.000\n",
      "Training accuracy: 100.00% | Validation accuracy: 100.00%\n",
      "Ep 35 (Step 004450): Train loss 0.000, Val loss 0.000\n",
      "Ep 35 (Step 004500): Train loss 0.000, Val loss 0.000\n",
      "Training accuracy: 100.00% | Validation accuracy: 100.00%\n",
      "Ep 36 (Step 004550): Train loss 0.000, Val loss 0.000\n",
      "Ep 36 (Step 004600): Train loss 0.000, Val loss 0.000\n",
      "Ep 36 (Step 004650): Train loss 0.000, Val loss 0.000\n",
      "Training accuracy: 100.00% | Validation accuracy: 100.00%\n",
      "Ep 37 (Step 004700): Train loss 0.000, Val loss 0.000\n",
      "Ep 37 (Step 004750): Train loss 0.000, Val loss 0.000\n",
      "Ep 37 (Step 004800): Train loss 0.000, Val loss 0.000\n",
      "Training accuracy: 100.00% | Validation accuracy: 100.00%\n",
      "Ep 38 (Step 004850): Train loss 0.000, Val loss 0.000\n",
      "Ep 38 (Step 004900): Train loss 0.000, Val loss 0.000\n",
      "Training accuracy: 100.00% | Validation accuracy: 100.00%\n",
      "Ep 39 (Step 004950): Train loss 0.000, Val loss 0.000\n",
      "Ep 39 (Step 005000): Train loss 0.000, Val loss 0.000\n",
      "Ep 39 (Step 005050): Train loss 0.000, Val loss 0.000\n",
      "Training accuracy: 100.00% | Validation accuracy: 100.00%\n",
      "Ep 40 (Step 005100): Train loss 0.000, Val loss 0.000\n",
      "Ep 40 (Step 005150): Train loss 0.000, Val loss 0.000\n",
      "Training accuracy: 100.00% | Validation accuracy: 100.00%\n",
      "Ep 41 (Step 005200): Train loss 0.000, Val loss 0.000\n",
      "Ep 41 (Step 005250): Train loss 0.000, Val loss 0.000\n",
      "Ep 41 (Step 005300): Train loss 0.000, Val loss 0.000\n",
      "Training accuracy: 100.00% | Validation accuracy: 100.00%\n",
      "Ep 42 (Step 005350): Train loss 0.000, Val loss 0.000\n",
      "Ep 42 (Step 005400): Train loss 0.000, Val loss 0.000\n",
      "Ep 42 (Step 005450): Train loss 0.000, Val loss 0.000\n",
      "Training accuracy: 100.00% | Validation accuracy: 100.00%\n",
      "Ep 43 (Step 005500): Train loss 0.000, Val loss 0.000\n",
      "Ep 43 (Step 005550): Train loss 0.000, Val loss 0.000\n",
      "Training accuracy: 100.00% | Validation accuracy: 100.00%\n",
      "Ep 44 (Step 005600): Train loss 0.000, Val loss 0.000\n",
      "Ep 44 (Step 005650): Train loss 0.000, Val loss 0.000\n",
      "Ep 44 (Step 005700): Train loss 0.000, Val loss 0.000\n",
      "Training accuracy: 100.00% | Validation accuracy: 100.00%\n",
      "Ep 45 (Step 005750): Train loss 0.000, Val loss 0.000\n",
      "Ep 45 (Step 005800): Train loss 0.000, Val loss 0.000\n",
      "Training accuracy: 100.00% | Validation accuracy: 100.00%\n",
      "Ep 46 (Step 005850): Train loss 0.000, Val loss 0.000\n",
      "Ep 46 (Step 005900): Train loss 0.000, Val loss 0.000\n",
      "Ep 46 (Step 005950): Train loss 0.000, Val loss 0.000\n",
      "Training accuracy: 100.00% | Validation accuracy: 100.00%\n",
      "Ep 47 (Step 006000): Train loss 0.000, Val loss 0.000\n",
      "Ep 47 (Step 006050): Train loss 0.000, Val loss 0.000\n",
      "Ep 47 (Step 006100): Train loss 0.000, Val loss 0.000\n",
      "Training accuracy: 100.00% | Validation accuracy: 100.00%\n",
      "Ep 48 (Step 006150): Train loss 0.000, Val loss 0.000\n",
      "Ep 48 (Step 006200): Train loss 0.000, Val loss 0.000\n",
      "Training accuracy: 100.00% | Validation accuracy: 100.00%\n",
      "Ep 49 (Step 006250): Train loss 0.000, Val loss 0.000\n",
      "Ep 49 (Step 006300): Train loss 0.000, Val loss 0.000\n",
      "Ep 49 (Step 006350): Train loss 0.000, Val loss 0.000\n",
      "Training accuracy: 100.00% | Validation accuracy: 100.00%\n",
      "Ep 50 (Step 006400): Train loss 0.000, Val loss 0.000\n",
      "Ep 50 (Step 006450): Train loss 0.000, Val loss 0.000\n",
      "Training accuracy: 100.00% | Validation accuracy: 100.00%\n",
      "Training completed in 5.39 minutes.\n"
     ]
    }
   ],
   "source": [
    "# Training\n",
    "import time\n",
    "\n",
    "start_time = time.time()\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=5e-5, weight_decay=0.1)\n",
    "num_epochs = 50\n",
    "train_losses, val_losses, train_accs, val_accs, examples_seen = train_classifier_simple(\n",
    "    model, train_loader, val_loader, optimizer, device, num_epochs=num_epochs, eval_freq=50, eval_iter=5\n",
    ")\n",
    "end_time = time.time()\n",
    "execution_time_minutes = (end_time-start_time)/60\n",
    "print(f\"Training completed in {execution_time_minutes:.2f} minutes.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "2e87475f-666d-48d3-80da-1c8fe9022116",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 500x300 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plot losses\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def plot_values(epochs_seen, examples_seen, train_values, val_values, label=\"loss\"):\n",
    "    fig, ax1 = plt.subplots(figsize=(5,3))\n",
    "    ax1.plot(epochs_seen, train_values, label=f\"Training {label}\")\n",
    "    ax1.plot(epochs_seen, val_values, linestyle=\"-.\", label=f\"Validation {label}\")\n",
    "    ax1.set_xlabel(\"Epochs\")\n",
    "    ax1.set_ylabel(label.capitalize())\n",
    "    ax1.legend()\n",
    "\n",
    "    # Invisible plot for aligning ticks\n",
    "    ax2 = ax1.twiny()\n",
    "    ax2.plot(examples_seen, train_values, alpha=0)\n",
    "    ax2.set_xlabel(\"Examples seen\")\n",
    "\n",
    "    fig.tight_layout()\n",
    "    plt.savefig(f\"{label}-plt.pdf\")\n",
    "    plt.show()\n",
    "\n",
    "epochs_tensor = torch.linspace(0, num_epochs, len(train_losses))\n",
    "examples_seen_tensor = torch.linspace(0, examples_seen, len(train_losses)) # examples_seen: 5200, len(train_losses): 13\n",
    "plot_values(epochs_tensor, examples_seen_tensor, train_losses, val_losses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "0a1a3091-a1bd-4cc2-8f3d-cf2f3a44680a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAeEAAAEiCAYAAADONmoUAAAAOnRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjEwLjAsIGh0dHBzOi8vbWF0cGxvdGxpYi5vcmcvlHJYcgAAAAlwSFlzAAAPYQAAD2EBqD+naQAAWZ5JREFUeJzt3Xl8TFf/B/DPTJKZZLLvG9kkQkgiQtKoXUjQFA+tqhJLKRWleGxF0KeNKmqp8pSHdBW0aH+NLUIssZPEkggSxJIVWWWdOb8/JrkyMlmGJDfL9/16zSsz95575twzw3fOPeeeI2CMMRBCCCGk0Qn5LgAhhBDSWlEQJoQQQnhCQZgQQgjhCQVhQgghhCcUhAkhhBCeUBAmhBBCeEJBmBBCCOEJBWFCCCGEJxSECSGEEJ5QECaE1Enfvn0xe/ZsvotBSItCQZiQRjJhwgQIBIIqD39/f76LRgjhiTrfBSCkNfH398fOnTsVtonFYp5KQwjhG7WECWlEYrEYFhYWCg9DQ0MAQFRUFEQiEU6fPs2lX716NczMzJCeng4AOHz4MHr27AkDAwMYGxvjnXfeQVJSEpf+/v37EAgE2LNnD3r16gUtLS10794dt2/fxqVLl9CtWzfo6Ohg8ODByMzM5I6bMGEChg8fjhUrVsDU1BR6enqYNm0aSkpKqj2X4uJizJs3D9bW1tDW1oa3tzeioqK4/Q8ePEBAQAAMDQ2hra2NTp064eDBg9Xm98MPP8DJyQmampowNzfHqFGjuH0ymQwhISGwt7eHlpYW3N3d8ccffygcf+PGDQwePBg6OjowNzfHuHHjkJWVxe3v27cvPvvsM8yfPx9GRkawsLDA8uXLqy0PIY2BgjAhTURFn+u4ceOQk5ODmJgYLF26FNu3b4e5uTkAoKCgAHPmzMHly5cRGRkJoVCIESNGQCaTKeQVHByMJUuW4OrVq1BXV8eHH36I+fPnY8OGDTh9+jTu3r2LZcuWKRwTGRmJhIQEREVFYdeuXdi3bx9WrFhRbXmDgoJw7tw5hIWF4dq1a3jvvffg7++PO3fuAABmzJiB4uJinDp1CtevX8c333wDHR0dpXldvnwZn332GVauXInExEQcPnwYvXv35vaHhITg559/xtatW3Hz5k18/vnn+Oijj3Dy5EkAQHZ2Nvr37w8PDw9cvnwZhw8fRnp6Ot5//32F9/npp5+gra2NCxcuYPXq1Vi5ciUiIiLq+AkR0gAYIaRRBAYGMjU1Naatra3w+Oqrr7g0xcXFrEuXLuz9999nLi4ubMqUKTXmmZmZyQCw69evM8YYu3fvHgPAtm/fzqXZtWsXA8AiIyO5bSEhIczZ2VmhbEZGRqygoIDbtmXLFqajo8OkUiljjLE+ffqwWbNmMcYYe/DgAVNTU2OPHz9WKM+AAQPYokWLGGOMubq6suXLl9epbv7880+mp6fHcnNzq+wrKipiEomEnT17VmH75MmT2ZgxYxhjjH355Zds0KBBCvsfPnzIALDExESu/D179lRI0717d7ZgwYI6lZGQhkB9woQ0on79+mHLli0K24yMjLjnIpEIv/32G9zc3GBra4vvvvtOIe2dO3ewbNkyXLhwAVlZWVwLOCUlBZ07d+bSubm5cc8rWtGurq4K2zIyMhTydnd3h0Qi4V77+PggPz8fDx8+hK2trULa69evQyqVon379grbi4uLYWxsDAD47LPPMH36dBw9ehS+vr4YOXKkQrkqGzhwIGxtbeHg4AB/f3/4+/tjxIgRkEgkuHv3Ll68eIGBAwcqHFNSUgIPDw8AQFxcHE6cOKG0pZ2UlMSV89X3t7S0rFIPhDQmCsKENCJtbW04OjrWmObs2bMAgGfPnuHZs2fQ1tbm9gUEBMDW1hbbtm2DlZUVZDIZOnfuXKXvVkNDg3suEAiUbnv1ErYq8vPzoaamhitXrkBNTU1hX0Ug/Pjjj+Hn54fw8HAcPXoUISEhWLt2LWbOnFklP11dXVy9ehVRUVE4evQoli1bhuXLl+PSpUvIz88HAISHh8Pa2lrhuIpBbfn5+QgICMA333xTJW9LS0vueeU6AN68Hgh5UxSECWlCkpKS8Pnnn2Pbtm3YvXs3AgMDcezYMQiFQjx9+hSJiYnYtm0bevXqBQA4c+ZMvb13XFwcCgsLoaWlBQA4f/48dHR00LZt2yppPTw8IJVKkZGRwZVFmbZt22LatGmYNm0aFi1ahG3btikNwgCgrq4OX19f+Pr6Ijg4GAYGBjh+/DgGDhwIsViMlJQU9OnTR+mxXbt2xZ9//gk7Ozuoq9N/a6T5oG8rIY2ouLgYaWlpCtvU1dVhYmICqVSKjz76CH5+fpg4cSL8/f3h6uqKtWvX4t///jcMDQ1hbGyMH3/8EZaWlkhJScHChQvrrWwlJSWYPHkylixZgvv37yM4OBhBQUEQCquO32zfvj3Gjh2L8ePHY+3atfDw8EBmZiYiIyPh5uaGoUOHYvbs2Rg8eDDat2+P58+f48SJE+jYsaPS9/7nn3+QnJyM3r17w9DQEAcPHoRMJoOzszN0dXUxb948fP7555DJZOjZsydycnIQHR0NPT09BAYGYsaMGdi2bRvGjBnDjX6+e/cuwsLCsH379iqtdUKaCgrChDSiw4cPK1weBQBnZ2fcunULX331FR48eIB//vkHgPwy6o8//ogxY8Zg0KBBcHd3R1hYGD777DN07twZzs7O2LhxI/r27VsvZRswYACcnJzQu3dvFBcXY8yYMTXewrNz50785z//wdy5c/H48WOYmJjgrbfewjvvvAMAkEqlmDFjBh49egQ9PT34+/tX6eOuYGBggH379mH58uUoKiqCk5MTdu3ahU6dOgEAvvzyS5iamiIkJATJyckwMDBA165dsXjxYgCAlZUVoqOjsWDBAgwaNAjFxcWwtbWFv7+/0h8RhDQVAsYY47sQhBB+TZgwAdnZ2Thw4ADfRSGkVaGfiIQQQghPKAgTQgghPKHL0YQQQghPqCVMCCGE8ISCMCGEEMITCsKEEEIITygIN6DNmzfDzs4Ompqa8Pb2xsWLF/ku0ms7deoUAgICYGVlBYFAUOVWFsYYli1bBktLS2hpacHX15dbTafCs2fPMHbsWOjp6cHAwACTJ0/mpiSscO3aNfTq1Quamppo27YtVq9eXaUse/fuRYcOHaCpqQlXV9cal8draCEhIejevTt0dXVhZmaG4cOHIzExUSFNUVERZsyYAWNjY+jo6GDkyJHc0oQVUlJSMHToUEgkEpiZmeHf//43ysrKFNJERUWha9euEIvFcHR0RGhoaJXyNJXv3JYtW+Dm5gY9PT3o6enBx8cHhw4d4va3xjpRZtWqVRAIBJg9eza3rTXWzfLlyyEQCBQeHTp04Pa36DrhdfmIFiwsLIyJRCK2Y8cOdvPmTTZlyhRmYGDA0tPT+S7aazl48CD74osv2L59+xgAtn//foX9q1atYvr6+uzAgQMsLi6Ovfvuu8ze3p4VFhZyafz9/Zm7uzs7f/48O336NHN0dORWwWGMsZycHGZubs7Gjh3Lbty4wXbt2sW0tLTYf//7Xy5NdHQ0U1NTY6tXr2bx8fFsyZIlTENDg1tFqLH5+fmxnTt3shs3brDY2Fg2ZMgQZmNjw/Lz87k006ZNY23btmWRkZHs8uXL7K233mI9evTg9peVlbHOnTszX19fFhMTww4ePMhMTEy41YgYYyw5OZlJJBI2Z84cFh8fzzZt2sTU1NTY4cOHuTRN6Tv3999/s/DwcHb79m2WmJjIFi9ezDQ0NNiNGzcYY62zTl518eJFZmdnx9zc3LjVqRhrnXUTHBzMOnXqxFJTU7lHZmYmt78l1wkF4Qbi5eXFZsyYwb2WSqXMysqKhYSE8Fiq+vFqEJbJZMzCwoJ9++233Lbs7GwmFovZrl27GGOMxcfHMwDs0qVLXJpDhw4xgUDALYf3ww8/MENDQ1ZcXMylWbBggcKSe++//z4bOnSoQnm8vb3ZJ598Uq/n+LoyMjIYAHby5EnGmLweNDQ02N69e7k0CQkJDAA7d+4cY0z+A0coFLK0tDQuzZYtW5ienh5XF/Pnz2edOnVSeK/Ro0czPz8/7nVT/84ZGhqy7du3U50wxvLy8piTkxOLiIhQWCKytdZNcHAwc3d3V7qvpdcJXY5uACUlJbhy5Qp8fX25bUKhEL6+vjh37hyPJWsY9+7dQ1pamsL56uvrw9vbmzvfc+fOwcDAAN26dePS+Pr6QigU4sKFC1ya3r17QyQScWn8/PyQmJiI58+fc2kqv09FmqZSrzk5OQBeLk945coVlJaWKpS5Q4cOsLGxUagbV1dXbslBQH5Oubm5uHnzJpempvNuyt85qVSKsLAwFBQUwMfHh+oEwIwZMzB06NAq5W/NdXPnzh1YWVnBwcEBY8eORUpKCoCWXycUhBtAVlYWpFKpwhcCkK/h+urk/S1BxTnVdL5paWkwMzNT2K+urg4jIyOFNMryqPwe1aVpCvUqk8kwe/ZsvP3229zavmlpaRCJRDAwMFBI+2rdvO555+bmorCwsEl+565fvw4dHR2IxWJMmzYN+/fvh4uLS6uuEwAICwvD1atXERISUmVfa60bb29vhIaG4vDhw9iyZQvu3buHXr16IS8vr8XXCS3gQEg9mTFjBm7cuFGvyws2Z87OzoiNjUVOTg7++OMPBAYG4uTJk3wXi1cPHz7ErFmzEBERAU1NTb6L02QMHjyYe+7m5gZvb2/Y2tpiz5493NKaLRW1hBuAiYkJ1NTUqozeS09Ph4WFBU+lajgV51TT+VpYWCAjI0Nhf1lZGZ49e6aQRlkeld+jujR812tQUBD++ecfnDhxAm3atOG2W1hYoKSkBNnZ2QrpX62b1z1vPT09aGlpNcnvnEgkgqOjIzw9PRESEgJ3d3ds2LChVdfJlStXkJGRga5du0JdXR3q6uo4efIkNm7cCHV1dZibm7fauqnMwMAA7du3x927d1v894WCcAMQiUTw9PREZGQkt00mkyEyMhI+Pj48lqxh2Nvbw8LCQuF8c3NzceHCBe58fXx8kJ2djStXrnBpjh8/DplMBm9vby7NqVOnUFpayqWJiIiAs7MzDA0NuTSV36ciDV/1yhhDUFAQ9u/fj+PHj8Pe3l5hv6enJzQ0NBTKnJiYiJSUFIW6uX79usKPlIiICOjp6cHFxYVLU9N5N4fvnEwmQ3FxcauukwEDBuD69euIjY3lHt26dcPYsWO55621birLz89HUlISLC0tW/73pcGGfLVyYWFhTCwWs9DQUBYfH8+mTp3KDAwMFEbvNSd5eXksJiaGxcTEMABs3bp1LCYmhj148IAxJr9FycDAgP3111/s2rVrbNiwYUpvUfLw8GAXLlxgZ86cYU5OTgq3KGVnZzNzc3M2btw4duPGDRYWFsYkEkmVW5TU1dXZmjVrWEJCAgsODub1FqXp06czfX19FhUVpXB7xYsXL7g006ZNYzY2Nuz48ePs8uXLzMfHh/n4+HD7K26vGDRoEIuNjWWHDx9mpqamSm+v+Pe//80SEhLY5s2bld5e0VS+cwsXLmQnT55k9+7dY9euXWMLFy5kAoGAHT16lDHWOuukOpVHRzPWOutm7ty5LCoqit27d49FR0czX19fZmJiwjIyMhhjLbtOKAg3oE2bNjEbGxsmEomYl5cXO3/+PN9Fem0nTpxgAKo8AgMDGWPy25SWLl3KzM3NmVgsZgMGDGCJiYkKeTx9+pSNGTOG6ejoMD09PTZx4kSWl5enkCYuLo717NmTicViZm1tzVatWlWlLHv27GHt27dnIpGIderUiYWHhzfYeddGWZ0AYDt37uTSFBYWsk8//ZQZGhoyiUTCRowYwVJTUxXyuX//Phs8eDDT0tJiJiYmbO7cuay0tFQhzYkTJ1iXLl2YSCRiDg4OCu9Roal85yZNmsRsbW2ZSCRipqambMCAAVwAZqx11kl1Xg3CrbFuRo8ezSwtLZlIJGLW1tZs9OjR7O7du9z+llwntIoSIYQQwhPqEyaEEEJ4QkGYEEII4QkFYUIIIYQnFIQJIYQQnlAQJoQQQnhCQZgQQgjhCQXhBlRcXIzly5ejuLiY76I0KVQv1aO6UY7qRTmqF+WaU73QfcINKDc3F/r6+sjJyYGenh7fxWkyqF6qR3WjHNWLclQvyjWneqGWMCGEEMITCsKEEEIIT2g9YSXKysoQExMDc3NzCIWv/zslLy8PAPD48WPk5ubWV/GaPaqX6lHdKEf1ohzVi3J814tMJkN6ejo8PDygrl5zmKU+YSUuXboELy8vvotBCCGkGbt48SK6d+9eYxpqCSthbm4OQF6BlpaWPJeGEEJIc5KamgovLy8ultSEgrASFZegLS0t0aZNG55LQwghpDmqS3cmDcwihBBCeMJrED516hQCAgJgZWUFgUCAAwcO1HpMVFQUunbtCrFYDEdHR4SGhlZJs3nzZtjZ2UFTUxPe3t64ePFi/ReeEEIIeUO8BuGCggK4u7tj8+bNdUp/7949DB06FP369UNsbCxmz56Njz/+GEeOHOHS7N69G3PmzEFwcDCuXr0Kd3d3+Pn5ISMjo6FOgxBCCHktTWZ0tEAgwP79+zF8+PBq0yxYsADh4eG4ceMGt+2DDz5AdnY2Dh8+DADw9vZG9+7d8f333wOQDxVv27YtZs6ciYULF9apLI8ePULbtm3x8OFD6hMmhBCiElViSLMamHXu3Dn4+voqbPPz88Ps2bMBACUlJbhy5QoWLVrE7RcKhfD19cW5c+cas6hNVplUhtvp+ehYFg9BkYr3zxnYAGYd5M9LC4F7pwGBEHCq9Jk8vgoUZKmWr64FYOkmfy6TAncj5c/b9QPUNPC8oARFj67BUvBMtXwlxsjQ6wQpY7DU15LnK5MCdm8DIm15mszbwPP7Sg9Pyy1Cem5Rle1SDR3kmHbjXhukX4BQWohcEw+UifQBAJr5DyHJTVKpuDI1MbLNfbjXellXoV6SizyjzijVNAEAiF6kQSf7lkr5QiDEM8ve3EvdZ9ehUfQUBfrOKNaWj/7XKHoK3WfXVcsXwHOLt8GEGgAA7exbEL9IwwtdexTp2gIA1EryoJ91ReV8s828IFOXAAAkuUnQzH+IIm1rvNB3AgAIy4pgkHFe5XyVfUYlWmbIN3SRJ5BJYZR2WuV8lX1GpWJD5Bm7c2kMU09DwKQq5avsM6ru+6cKZZ9Rdd8/VSj9jKr5/qmius9I2fdPFco+o+cWPdGzvSk01BrnQnGzCsJpaWlVhnybm5sjNzcXhYWFeP78OaRSqdI0t25V/x9XcXGxwkTfFTd6t0ShZ+/jP+EJuGi+CmY511Q7+K0ZgP/X8ucvngK/vweoiYClmS/TnFwN3D6kWr5uo4F//Sh/LiuT5wsACx+CCdUxdvsFTHq6BqOEUSplK3Xoh4BHQSgqleHUv/tBf08gUJIHfBYDGDnIE8X9Dpz5TunxFuWPV92Q2WFiydfc65OiObAVZuBfxctxlbUHAExWC8dSjd9UKu8TZoQRxd9zr/eJlsFdeBcfl8zFMZknAGCE8DS+E21RKd9ipg7n4p+519s01mCg2lXML52CPdJ+AIDewjj8LPpGpXwBoHPRduRDHiy/Uf8Ro9WjsLp0NH6QDgMAdBLcQ7j4C5Xz7V38HVKY/N/xfPUwfKr+N7aXDcZ/ysYBACzxFOc0Z6qcr7LPaJ+0J+aUfgoAEKEUtzWnqJyvss/olNQVE0tfNgiui2dAV6BasFT2GVX3/VOFss+ouu+fKpR9RtV9/1RR3Wek7PunCmWfkXvxNsQt96cg3JhCQkKwYsUKvovRKC7ck7cmYwvNMMjKQ7WD9a1fPlcTAVYeQPmvUI6Rg3y7KgxsK70QvDxeIERieh7iU3PxQM0EGfouMNMV1znbVLU2SM+V/7g6kZiB4ZbuQGkBoFYpD10rpeV9WlCCR88LoSYUQKyu+I8xS80abmb6L98n1wElMn20MTBBmbp8u6TIEneKnOpcVgDIFujDzfRlvs/y7HFHKoCpvhncNOTbDUrMceeFavmWQU0h34J8G9wpy4O+rjncxPLt5qWmuFOgWr4A4GJtgCKBlvx9XrTBnRIniHQs4aYpz9e6zBh38lXPt52hEQzU5HmoFVrhTrEToG0NN63yepDJcCdX9XyVfUYlWm3gpi3fps5KcSdH9XyVfUa5mrZw03lZ7/ezHaGJqldWaqLsM6ru+6cKZZ9Rdd8/lSj5jKr7/qmius9I2fdPFco+IzcTPQgFKp73G2hWfcK9e/dG165dsX79em7bzp07MXv2bOTk5KCkpAQSiQR//PGHQj6BgYHIzs7GX3/9pTTfV1vCjx8/houLS8vrE5ZJ0f+700jOLAAARC/sD2sDLZ4LVbNNkXewNuI2AKCrjQH2ffp2nY9dtO86dl1MAQAMdbXE5rFd63zsxJ0XcSIxE//2c8aMfo6qFZoQ0qqp0ifcrO4T9vHxQWRkpMK2iIgI+PjI+zFEIhE8PT0V0shkMkRGRnJplBGLxdDT0+Meurq6DXMCPJOe/R4/5n6K99SiAACRCem8lqcujlUqY8zDbGTm1W19UJmMKZzfyduZKC6rW39cQXEZopPkfVYDXWqf8YYQQl4Xr0E4Pz8fsbGxiI2NBSC/BSk2NhYpKfLWy6JFizB+/Hgu/bRp05CcnIz58+fj1q1b+OGHH7Bnzx58/vnnXJo5c+Zg27Zt+Omnn5CQkIDp06ejoKAAEydObNRza4pK4g/BUfAYWpAHsoj4ph2E03OLEPcoBwIBYGcsAWN1/+Fw7XEOMvKKoS1Sg6muGPnFZTifXLeBXaduZ6KkTAZbYwmczHTe5BQIIaRGvAbhy5cvw8PDAx4e8j65OXPmwMPDA8uWLQMgn3+zIiADgL29PcLDwxEREQF3d3esXbsW27dvh5+fH5dm9OjRWLNmDZYtW4YuXbogNjYWhw8frtMcni3dea/vMbMkCOfFPeWvk58it6iU51JVr+JHQpe2BhjZVX5J51gdg3BEvHyUZF9nM/h2NFfYVuux5e8xsKM5BI3YN0QIaX14HZjVt29f1NQlrWw2rL59+yImJqbGfIOCghAUFPSmxWtxbucI8H+yHnjH0RLS1FwkZRbgZGImAtyt+C6aUhUBd6CLOfo5m2FtxG2cvpOFFyVlkIhq/uoei8/gjtXX0sCuiyk4Fp+BL4exGgNrmVSG47deHksIIQ2pWfUJkzeTlJkPAGhnqgNfl4rWYdO8JJ1fXIazd8v7ZTuao4OFLtoYaqG4TIbTd2q+Dznl6QskpudBTShAX2dT+LQzhkSkhrTcItx4XPN9j5cfPEf2i1IYSDTgaWtYb+dDCCHKUBBuDUoLgZ1D0OX+/yBCKRxMtTGoPAifSMxAqVTGcwGrOnU7EyVSGeyMJXA004FAIOBapsdq+eFwtPyys5edEQwkImhqqKG3kymA2i9JV+Tdv4MZ1BvpPkFCSOtF/8u0BslRwINo9MsPRwnU0c5UB13aGsJER4S8ojJcvKfiTFSNoCIYDnR52S87sLxv9/itDEhl1XdjRFQ6tkLF86M1BHDGGNcfPIguRRNCGgEF4dYg8SAA4GiZBwAB7E20oSYUoH8HMwBN75J0mVSG44nyftmKQVUA0N3eCHqa6nhaUIKrKc+VHvu8oASXH8j3VQ7C/TqYQSgAbqXl4eGzF0qPvZORjwdPX0CkLkSv8pYzIYQ0JArCLZ1MBiTKF7eIkHWDpb4mtMXyQU0DXeSTMkbEp9c4QK6xXbov75c1fKVfVkNNyP1wqO6S9IlEeSu5g4Uu2hpJuO1G2iJ0szOSH1vNCOuKHyNvtzPm6ogQQhoSBeGW7vFloCADJeo6uCDrCAdTbW5XT0cTaGoI8Ti7EPGpKi7m0IAiuH5Z8yr9srUNKFN2KbrCoDofq2zGaEIIqX8UhFu68kvRd/XeQml5f3AFLZEaejrKL7tW3NLDN3m/rHzw1EAXsyr7+7Q3hYaaAMlZBbibka+wr6hUipO35YtJVL6MXaFi24V7z5DzQvH+6IzcIsQ+zC5PV/V9CSGkIVAQbuluyYNwtLo3AMDBRFthN9c6TFBtCbCGcjs9Hw+fFVbbL6urqQGfdvIl4169rHwu+SlelEhhrieGq3XVCe3tTLThZKYDqYwh6rbij47I8nuD3dsawExPs75OhxBCakRBuCV7mgRkJQJCdfzfC/lanO1emYaxf0czCATAjce5eJKt2jJrDaHiFqKejibV9ssO7Kh8QFnFa9+O5hAKlU/IUd0o6YpjaVQ0IaQxURBuycovRctseyL+mfyjdjBVDMImOmJ42sgHPzWFBR0iEmqfraqiX/hqynNuQYfKCzbUdGzFvpOJ8vmhAfmCDWfuZtV6LCGE1DcKwi1Z+aXoZ20GoEzGoKkhhKWSS62+dbiHtjGk5xYhrrxfdkCH6vtlLfW14GqtD8aAE+WXka8/zkF6rnzBBp92xtUe697GoNKCDvIZuU7fyUJJmQw2RrRgAyGkcVEQbqkKngIPzwMAbunJF2xwMNFRepm2ovXH94IOFX28XerQL1sxyKrih0PF5eQ+zqYQq6tVe5xQKOAGXkW8cmzliUEIIaQxUBBuqe4cAZgMsHDFzRfyQUqVb0+qrJ2pDhxMtVEqZTiZmNmYpVRQ0+1Fr6pIc+ZuJgpLpK917LGE9PIFG+p+LCGE1CcKwi1V0gn5X+ehSM4sAFC1P7iyiikh67pUYH0rqLxgQx2CYUdLXVgbaKGoVIbfL6ZwCzb0c6799qIe7UygpaGG1Jwi/HzuAZ6XL9jQjRZsIIQ0MgrCLdXwLcCEg4DHWCRnVayepLwlDLwMfCdu8bOgQ8WCDbbGdeuXrbygw3cRtwEA3e0MYSAR1XqspoYaereX3+a0rvzY/s60YAMhpPHR/zotlZo6YPc2YGCDpPKWcLsaWsIeNoYw1hYhl6cFHbjLyR3r3i9bEYTzi8vKX9d9pquKtC+PpUvRhJDGRxPk8okxoIEHAmW/KMGzghIAgL1J9S1hNaEAAzqaYc/lRzh4PRUulnoNWq7KZIxxCzaoEgy97I2gq6mOvKLyQKpklqzq9C9f0EHGAJGaEL3b04INhJDGR0GYL5mJwA4/wOsToN+i+suXMWD7AMCqK9BvMZIy5UG+8sIN1fHtaI49lx/htwsp+O1CSv2VqY4MXlmwoTYaakL0czbD33FP4GyuCxtjSe0HlTPSFqGbrREu3n+GHo60YAMhhB90OZov+6YAhc+Bk6vqN9/8dODxFeDy/wANCZIy5f3B1Y2Mrqx3e1N0sNCt3/LUkVAATOxhr3K/7IS37WCqK8bU3g4qv+eU3g4w0RFhck97lY8lhJD6QD//+cAYkBrXMHmLdID3QoH8DEBD8+XIaJPaBztpaqjh0Kxe4GtVw+qmmqxJVxtDXPrC97Xeb6CLOQa6DHytYwkhpD5QEOZDXqri67ISQL32Ub11ItYBOo3gXiZn1j4yujKBQNDQ3dSEEELK0eVoPuhZAYufvHyd33D35r68HE3TMRJCSFNDQZgvIm1Av638eV49LiN48wCQeAgofI4yqQwpz14AqFufMCGEkMZFQbixySpNhKFrKf/76uXpNxGxFNj1AZB+Ew+fF6JUKl+4wUpfq/7egxBCSL2gINzYYn4GNr8FXN4B6JZPLlFfQbi0EMh+KH9u0h5JGfJL0fbVLNxACCGEXxSEG1viYSAzAXjxtP5bws+SATBArA9om9ZpukpCCCH8odHRjW3EFuDOMaBNN+Dmfvm2+uoTzroj/2viBAgEdVq4gRBCCH8oCDc2LUPA7T35cz0r+d/ivPrJu3IQxsuR0dQSJoSQpomCMJ9chsvv6VUX109+T8uDsLEjAHAt4ZoWbiCEEMIf6hNuLDIp8OtI4PQ6oEQeHKGhWX8BGKjUEm6P7BcleFqHhRsIIYTwh4JwY3l4Abh7DIjeAKjVY+CtwJjC5eiK5Qst9GpfuIEQQgg/KAg3lsSD8r/t/eRr/Vb453Pg52FA9huuWpSfDpTkAQIhYOTwcrpKM2oFE0JIU0VBuDEwBtwqD8LOgxX3JZ8EkqNe3t/7uipawQa2gLoYyVl1X7iBEEIIP+g6ZWPIug08SwLURIDjKyv+9F0EMCk3mOqN3gN4OTI6o+5LGBJCCOEHBeHGcCtc/te+NyB+Zb3eituV3tTTu/K/Ju0BgGsJ08hoQghpuuhydGNIPCT/++ql6PqkoQXoWQMmTiiTyvDgacVEHdQSJoSQpopawg0tPwN4dEn+3HmIkv2ZQGqs/FYl+96v/z4DlskfjOHh0xe0cAMhhDQD1BJuaImHADDAyuPlDFmV3T8N/DYKiFpVP+8nEHAjo2nhBkIIadp4D8KbN2+GnZ0dNDU14e3tjYsXL1abtrS0FCtXrkS7du2gqakJd3d3HD58WCHN8uXLIRAIFB4dOnRo6NOoHncpeqjy/RWLOOQ+ef33YEzh5cs5o+lSNCGENGW8BuHdu3djzpw5CA4OxtWrV+Hu7g4/Pz9kZGQoTb9kyRL897//xaZNmxAfH49p06ZhxIgRiImJUUjXqVMnpKamco8zZ840xulUVVIAJJ+QP6+uP5hbzjCtSjCts4S/gTXOQPg8AJXmjKaZsgghpEnjNQivW7cOU6ZMwcSJE+Hi4oKtW7dCIpFgx44dStP/8ssvWLx4MYYMGQIHBwdMnz4dQ4YMwdq1axXSqaurw8LCgnuYmJg0xulUlXQCKCsCDGwA807K01QE4bJCoCjn9d4n6zaQnwaUyIMvN2e0GY2MJoSQpoy3IFxSUoIrV67A1/flfbNCoRC+vr44d+6c0mOKi4uhqampsE1LS6tKS/fOnTuwsrKCg4MDxo4di5SUmmejKi4uRm5uLvfIy6unVY2SIuV/nYcCgmr6ZjW0AE0D+fPXXdLQ6xPg40igx0wA4NYRpok6CCGkaeMtCGdlZUEqlcLc3Fxhu7m5OdLSlAcjPz8/rFu3Dnfu3IFMJkNERAT27duH1NRULo23tzdCQ0Nx+PBhbNmyBffu3UOvXr1qDKwhISHQ19fnHi4uLvVzkoNXA4H/AN0n15yuYsBW3mv2C2vqydcnNu+EnBelyMovX7iB+oQJIaRJ431glio2bNgAJycndOjQASKRCEFBQZg4cSKEwpenMXjwYLz33ntwc3ODn58fDh48iOzsbOzZs6fafBctWoScnBzuER8fXz8FVtMA7Htxs1hVq3K/8BtKKm8FW+hpQocWbiCEkCaNtyBsYmICNTU1pKenK2xPT0+HhYWF0mNMTU1x4MABFBQU4MGDB7h16xZ0dHTg4OBQ7fsYGBigffv2uHv3brVpxGIx9PT0uIeurm61aRtExQjpvNSa0ylT8BQ4+G/g0v8A0MhoQghpTngLwiKRCJ6enoiMjOS2yWQyREZGwsfHp8ZjNTU1YW1tjbKyMvz5558YNmxYtWnz8/ORlJQES0vLeit7vXuTlnBmAnDxR+DsRgCVRkbTdJWEENLk8Xo5es6cOdi2bRt++uknJCQkYPr06SgoKMDEiRMBAOPHj8eiRYu49BcuXMC+ffuQnJyM06dPw9/fHzKZDPPnz+fSzJs3DydPnsT9+/dx9uxZjBgxAmpqahgzZkyjn1+dvUlLmFu4oXzO6ExauIEQQpoLXjsNR48ejczMTCxbtgxpaWno0qULDh8+zA3WSklJUejvLSoqwpIlS5CcnAwdHR0MGTIEv/zyCwwMDLg0jx49wpgxY/D06VOYmpqiZ8+eOH/+PExNTRv79OqOm7DjdYJw+WV2Y3m/88vL0dQSJoSQpo73kTtBQUEICgpSui8qKkrhdZ8+fWodNBUWFlZfRWs8XEv4NS5HPy1fR9jEEWVSGe4/rVg9iVrChBDS1Kl8OdrOzg4rV66s9d5booKKPmEmVX3WrEqXox89L6SFGwghpBlROQjPnj0b+/btg4ODAwYOHIiwsDAUFxc3RNlaDz0rYEkmMPdW9ZN6KFNaBGSX/xgyduIGZdkZa9PCDYQQ0gy8VhCOjY3FxYsX0bFjR8ycOROWlpYICgrC1atXG6KMLZ9AAKiLVD/uWTLAZIBYH9Axo+kqCSGkmXnt0dFdu3bFxo0b8eTJEwQHB2P79u3o3r07unTpgh07doC97mIEpO4q9QdDIOCmq6SFGwghpHl47SBcWlqKPXv24N1338XcuXPRrVs3bN++HSNHjsTixYsxduzY+ixny3duM/BTAHDzQN2PySoPwuUjo5MyaGQ0IYQ0JyqPjr569Sp27tyJXbt2QSgUYvz48fjuu+8U1uwdMWIEunfvXq8FbfGybgP3TgE2PYBOw+t4TEVLuPz2pCyaqIMQQpoTlYNw9+7dMXDgQGzZsgXDhw+HhoZGlTT29vb44IMP6qWArYb7GHkAtupS92OevgzCtHADIYQ0PyoH4eTkZNja2taYRltbGzt37nztQrVKNm/JH3XFmMLlaFq4gRBCmh+V+4QzMjJw4cKFKtsvXLiAy5cv10uhSB2UFQMu7wJt3wKMHGjhBkIIaYZUDsIzZszAw4cPq2x//PgxZsyYUS+FapVKC4HbR4DYXXVLr6EJDNsMTD4CaGjSnNGEENIMqXzdMj4+Hl27dq2y3cPDo/7W4W2NivOB39+XP3cdJV+LWAW0ehIhhDQ/KreExWJxlTWAASA1NRXq6tQX+dokxoCwPPDmV63fKvIz5DNmlaOFGwghpPlROQgPGjQIixYtQk5ODrctOzsbixcvxsCBA+u1cK2KUPhyDum6rKZ04FPga0sgbjfKpDI8ePoCAOBAE3UQQkizoXLTdc2aNejduzdsbW3h4eEBAIiNjYW5uTl++eWXei9gq6JrAeQ8rNu6wnlp8ikr9a3x6HkhSqQyiNWFsDaghRsIIaS5UDkIW1tb49q1a/jtt98QFxcHLS0tTJw4EWPGjFF6zzBRQUVLuC5LGk47Lb8kramP5CT5VQl7E1q4gRBCmpPX6sTV1tbG1KlT67ssRNdK/rcuLWGBANA1BwAkZz4BQIOyCCGkuXntkVTx8fFISUlBSUmJwvZ33333jQvVanEt4ToE4Upejoym/mBCCGlOXmvGrBEjRuD69esQCATcakmC8nVwpVJp/ZawNdG1lP+tLQif3QQ8OAu4jQY6DUcSjYwmhJBmSeXR0bNmzYK9vT0yMjIgkUhw8+ZNnDp1Ct26dUNUVFQDFLEVqWuf8NVfgMSDgKwMAGi2LEIIaaZUbgmfO3cOx48fh4mJCYRCIYRCIXr27ImQkBB89tlniImJaYhytg51aQk/TQKyEgGhOuDoi5zCUmTlFwOgljAhhDQ3KreEpVIpdHV1AQAmJiZ48kQ+KMjW1haJiYn1W7rWRq88CBflACUvlKe5FS7/a9cT0DLgpqs01xPTwg2EENLMqPy/dufOnREXFwd7e3t4e3tj9erVEIlE+PHHH+Hg4NAQZWw9xHqAhgQofSFvDRu3q5om8ZD8r/MQAOD6g2lkNCGEND8qB+ElS5agoED+H//KlSvxzjvvoFevXjA2Nsbu3bvrvYCtikAA6FkBRblAcW7V/QVPgYfn5c+dBwMALdxACCHNmMpB2M/Pj3vu6OiIW7du4dmzZzA0NORGSJM3MOMiIFRTvu/2YfksWRaugIENgEqDskyoJUwIIc2NSn3CpaWlUFdXx40bNxS2GxkZUQCuL9UFYEA+IhrgLkUDle4RNqMgTAghzY1KQVhDQwM2NjZ0LzAfSguBpOPy5+VBWCpjtHADIYQ0YyqPjv7iiy+wePFiPHv2rCHKQ+5EAKHvAEe+UNyefFI+YEvPGrB0BwA8ev6CFm4ghJBmTOU+4e+//x53796FlZUVbG1toa2t2AK7evVqvRWuVSrKAe6flvf9VsZdih4sH8CFl5eiaeEGQghpnlQOwsOHD2+AYhCOzVvAv7YDRvYvt8lk8kFZgEJ/cDLdnkQIIc2aykE4ODi4IcpBKui3AdzeU9z2LAkozAZEuoBdL25zEk1XSQghzRpNsdQcmDgB85OBzFuAuojb/HL1JGoJE0JIc6RyEBYKhTXejkQjp+vB3Ugg+wHQ4R1Ax0y+TawDtOmmkIwWbiCEkOZN5SC8f/9+hdelpaWIiYnBTz/9hBUrVtRbwVq1I4vlrV5De0DblBuIVVnlhRvs6fYkQghpllQOwsOGDauybdSoUejUqRN2796NyZMn10vBWjVdC3kQzksDzm0GroUBPjMB99FcksoLN+hqavBVUkIIIW9A5fuEq/PWW28hMjKyvrJr3XSt5H/zUuULNqRdB4qyFZLQdJWEENL81cvArMLCQmzcuBHW1tb1kR3RtZD/zUsF3v8JuH0EaNdPIUlyVsV0lXQpmhBCmiuVg/CrCzUwxpCXlweJRIJff/21XgvXaumWryuclwpomwAeY6skScqgljAhhDR3Kl+O/u677xQeGzduxD///IMHDx7g3XffVbkAmzdvhp2dHTQ1NeHt7Y2LFy9Wm7a0tBQrV65Eu3btoKmpCXd3dxw+fPiN8myS9CqCcFq1SSpawjQymhBCmi+VW8ITJkyotzffvXs35syZg61bt8Lb2xvr16+Hn58fEhMTYWZmViX9kiVL8Ouvv2Lbtm3o0KEDjhw5ghEjRuDs2bPw8PB4rTybpIqW8KNLwNlNgNcnCvcHS2UM97PkCzfQPcKEENJ8qdwS3rlzJ/bu3Vtl+969e/HTTz+plNe6deswZcoUTJw4ES4uLti6dSskEgl27NihNP0vv/yCxYsXY8iQIXBwcMD06dMxZMgQrF279rXzbJIq+oQB4NwPgJri6GdauIEQQloGlYNwSEgITExMqmw3MzPD119/Xed8SkpKcOXKFfj6+r4sjFAIX19fnDt3TukxxcXF0NTUVNimpaWFM2fOvHaeTZKOOff0nlYn7Ii+jx1n7nGP/525B4AWbiCEkOZO5cvRKSkpsLe3r7Ld1tYWKSkpdc4nKysLUqkU5ubmCtvNzc1x69Ytpcf4+flh3bp16N27N9q1a4fIyEjs27ePm6XrdfIE5MG9uLiYe52Xl1fn82gIMoE69+vou0ft8XdKvNJ0jmZ0KZoQQpozlYOwmZkZrl27Bjs7O4XtcXFxMDY2rq9yKbVhwwZMmTIFHTp0gEAgQLt27TBx4sQ3vtQcEhLSpGb7inuUjfUlC9BR/QnQeRTeVTJjlkhdiKm9HXgoHSGEkPqichAeM2YMPvvsM+jq6qJ3794AgJMnT2LWrFn44IMP6pyPiYkJ1NTUkJ6errA9PT0dFhYWSo8xNTXFgQMHUFRUhKdPn8LKygoLFy6Eg4PDa+cJAIsWLcKcOXO4148fP4aLi0udz6W+RcSn46TMHTod/LH5w668lYMQQkjDUrlP+Msvv4S3tzcGDBgALS0taGlpYdCgQejfv79KfcIikQienp4Ks2zJZDJERkbCx8enxmM1NTVhbW2NsrIy/Pnnn9xUmq+bp1gshp6eHvfQ1dWt83k0hIh4+Y+IQS7mtaQkhBDSnKncEhaJRNi9ezf+85//IDY2FlpaWnB1dYWtra3Kbz5nzhwEBgaiW7du8PLywvr161FQUICJEycCAMaPHw9ra2uEhIQAAC5cuIDHjx+jS5cuePz4MZYvXw6ZTIb58+fXOc+m7n5WAe5k5ENdKEDf9s3klipCCCGv5bWnrXRycoKTk9Mbvfno0aORmZmJZcuWIS0tDV26dMHhw4e5gVUpKSkQCl821ouKirBkyRIkJydDR0cHQ4YMwS+//AIDA4M659nUHUuQt4K97I2gL6GFGQghpCUTMMaYKgeMHDkSXl5eWLBggcL21atX49KlS0rvIW5uHj16hLZt2+Lhw4do06ZNo773+/89h4v3niE4wAUT3646Cp0QQkjTpkoMUblP+NSpUxgyZEiV7YMHD8apU6dUzY5U8rygBJfvPwMA+HZsHi13Qgghr0/lIJyfnw+RSFRlu4aGBnJzc+ulUK3V8VsZkDGgg4Uu2hpJ+C4OIYSQBqZyEHZ1dcXu3burbA8LC+P1tp6WgEZFE0JI66LywKylS5fiX//6F5KSktC/f38AQGRkJH7//Xf88ccf9V7A1qKoVIpTdzIBAANdqr+nmRBCSMuhchAOCAjAgQMH8PXXX+OPP/6AlpYW3N3dcfz4cRgZGTVEGVuFc0lP8aJECgs9TXS21uO7OIQQQhrBa92iNHToUAwdOhQAkJubi127dmHevHm4cuUKN48zUc3R8kvRvi5mECiZppIQQkjLo3KfcIVTp04hMDAQVlZWWLt2Lfr374/z58/XZ9laDZmMIbL8/mC6FE0IIa2HSi3htLQ0hIaG4n//+x9yc3Px/vvvo7i4GAcOHKBBWW/g2uMcZOQVQ0esjrcc6JI+IYS0FnVuCQcEBMDZ2RnXrl3D+vXr8eTJE2zatKkhy9ZqRMSnAQD6tDeFWF2N59IQQghpLHVuCR86dAifffYZpk+f/sbTVRJFx+IzAAAD6dYkQghpVercEj5z5gzy8vLg6ekJb29vfP/998jKymrIsrUKKU9fIDE9D2pCAfo504INhBDSmtQ5CL/11lvYtm0bUlNT8cknnyAsLAxWVlaQyWSIiIhAXl5eQ5azxTpafinay44WbCCEkNZG5dHR2tramDRpEs6cOYPr169j7ty5WLVqFczMzPDuu+82RBlbtGPcqGi6FE0IIa3Na9+iBADOzs5YvXo1Hj16hF27dtVXmVqN7BcluHT/OQAKwoQQ0hq9URCuoKamhuHDh+Pvv/+uj+xajeO3MiCVMVqwgRBCWql6CcLk9dClaEIIad0oCPOkuEyKk4kVCzZQECaEkNaIgjBPLt57hoISKcz1xOhspc93cQghhPCAgjBPElJzAQDd7IwgFNKCDYQQ0hpREOZJcmYBAKCdqQ7PJSGEEMIXCsI8ScrMBwC0M9XmuSSEEEL48lrrCZM3Ry1h0hpIpVKUlpbyXQxC6p1IJIJQ+ObtWArCPMh+UYKnBSUAAHsTagmTlocxhrS0NGRnZ/NdFEIahFAohL29PUQi0RvlQ0GYB0nlrWALPU1oi+kjIC1PRQA2MzODRCKBQECDD0nLIZPJ8OTJE6SmpsLGxuaNvt8UAXiQXNEfbEatYNLySKVSLgAbGxvzXRxCGoSpqSmePHmCsrIyaGi8/uI7NDCLB8lZ8pawgwn1B5OWp6IPWCKhqVhJy1VxGVoqlb5RPhSEeZCUIW8JO9DIaNKC0SVo0pLV1/ebgjAPKlrCNDKakJbPzs4O69evr3P6qKgoCAQCGtTWSlAQbmRlUhkePC2/HE0tYUKaDIFAUONj+fLlr5XvpUuXMHXq1Dqn79GjB1JTU6GvT9PZtgY0MKuRPXxeiFIpg6aGEFb6WnwXhxBSLjU1lXu+e/duLFu2DImJidw2HZ2XV64YY5BKpVBXr/2/UFNTU5XKIRKJYGFhodIxLUVJSckb3/LT3FBLuJFVjIy2N9GhOaMJaUIsLCy4h76+PgQCAff61q1b0NXVxaFDh+Dp6QmxWIwzZ84gKSkJw4YNg7m5OXR0dNC9e3ccO3ZMId9XL0cLBAJs374dI0aMgEQigZOTk8Ja7K9ejg4NDYWBgQGOHDmCjh07QkdHB/7+/go/GsrKyvDZZ5/BwMAAxsbGWLBgAQIDAzF8+PBqz/fp06cYM2YMrK2tIZFI4Orqil27dimkkclkWL16NRwdHSEWi2FjY4OvvvqK2//o0SOMGTMGRkZG0NbWRrdu3XDhwgUAwIQJE6q8/+zZs9G3b1/udd++fREUFITZs2fDxMQEfn5+AIB169bB1dUV2traaNu2LT799FPk5+cr5BUdHY2+fftCIpHA0NAQfn5+eP78OX7++WcYGxujuLhYIf3w4cMxbty4auuDLxSEG1nFTFl0KZq0JowxvCgp4+XBGKu381i4cCFWrVqFhIQEuLm5IT8/H0OGDEFkZCRiYmLg7++PgIAApKSk1JjPihUr8P777+PatWsYMmQIxo4di2fPnlWb/sWLF1izZg1++eUXnDp1CikpKZg3bx63/5tvvsFvv/2GnTt3Ijo6Grm5uThw4ECNZSgqKoKnpyfCw8Nx48YNTJ06FePGjcPFixe5NIsWLcKqVauwdOlSxMfH4/fff4e5uXzp1fz8fPTp0wePHz/G33//jbi4OMyfPx8ymawONfnSTz/9BJFIhOjoaGzduhWAfCKMjRs34ubNm/jpp59w/PhxzJ8/nzsmNjYWAwYMgIuLC86dO4czZ84gICAAUqkU7733HqRSqcIPm4yMDISHh2PSpEkqla0x0OXoRvZyzmgalEVaj8JSKVyWHeHlveNX+kEiqp//6lauXImBAwdyr42MjODu7s69/vLLL7F//378/fffCAoKqjafCRMmYMyYMQCAr7/+Ghs3bsTFixfh7++vNH1paSm2bt2Kdu3aAQCCgoKwcuVKbv+mTZuwaNEijBgxAgDw/fff4+DBgzWei7W1tUIgnzlzJo4cOYI9e/bAy8sLeXl52LBhA77//nsEBgYCANq1a4eePXsCAH7//XdkZmbi0qVLMDIyAgA4OjrW+J7KODk5YfXq1QrbZs+ezT23s7PDf/7zH0ybNg0//PADAGD16tXo1q0b9xoAOnXqxD3/8MMPsXPnTrz33nsAgF9//RU2NjYKrfCmgoJwI3s5ZzS1hAlpbrp166bwOj8/H8uXL0d4eDhSU1NRVlaGwsLCWlvCbm5u3HNtbW3o6ekhIyOj2vQSiYQLwABgaWnJpc/JyUF6ejq8vLy4/WpqavD09KyxVSqVSvH1119jz549ePz4MUpKSlBcXMzd352QkIDi4mIMGDBA6fGxsbHw8PDgAvDr8vT0rLLt2LFjCAkJwa1bt5Cbm4uysjIUFRXhxYsXkEgkiI2N5QKsMlOmTEH37t3x+PFjWFtbIzQ0FBMmTGiSt81REG5kyVnl9wjTRB2kFdHSUEP8Sj/e3ru+aGsr/nieN28eIiIisGbNGjg6OkJLSwujRo1CSUlJjfm8OsOSQCCoMWAqS/+ml9m//fZbbNiwAevXr+f6X2fPns2VXUur5oGjte0XCoVVyqhsMY9X6/T+/ft45513MH36dHz11VcwMjLCmTNnMHnyZJSUlEAikdT63h4eHnB3d8fPP/+MQYMG4ebNmwgPD6/xGL5Qn3AjynlRiqx8+Rec+oRJayIQCCARqfPyaMjWT3R0NCZMmIARI0bA1dUVFhYWuH//foO9nzL6+vowNzfHpUuXuG1SqRRXr16t8bjo6GgMGzYMH330Edzd3eHg4IDbt29z+52cnKClpYXIyEilx7u5uSE2NrbavmxTU1OFwWOAvPVcmytXrkAmk2Ht2rV466230L59ezx58qTKe1dXrgoff/wxQkNDsXPnTvj6+qJt27a1vjcfKAg3oqTyVjAt3EBIy+Dk5IR9+/YhNjYWcXFx+PDDD1UemFQfZs6ciZCQEPz1119ITEzErFmz8Pz58xp/gDg5OSEiIgJnz55FQkICPvnkE6Snp3P7NTU1sWDBAsyfPx8///wzkpKScP78efzvf/8DAIwZMwYWFhYYPnw4oqOjkZycjD///BPnzp0DAPTv3x+XL1/Gzz//jDt37iA4OBg3btyo9VwcHR1RWlqKTZs2ITk5Gb/88gs3YKvCokWLcOnSJXz66ae4du0abt26hS1btiArK4tL8+GHH+LRo0fYtm1bkxyQVYGCcCOikdGEtCzr1q2DoaEhevTogYCAAPj5+aFr166NXo4FCxZgzJgxGD9+PHx8fKCjowM/Pz9oampWe8ySJUvQtWtX+Pn5oW/fvlxArWzp0qWYO3culi1bho4dO2L06NFcX7RIJMLRo0dhZmaGIUOGwNXVFatWrYKamvzyv5+fH5YuXYr58+eje/fuyMvLw/jx42s9F3d3d6xbtw7ffPMNOnfujN9++w0hISEKadq3b4+jR48iLi4OXl5e8PHxwV9//aVw37a+vj5GjhwJHR2dGm/V4h3j2ffff89sbW2ZWCxmXl5e7MKFCzWm/+6771j79u2ZpqYma9OmDZs9ezYrLCzk9gcHBzMACg9nZ2eVyvTw4UMGgD18+PC1zqk6qw4lMNsF/7Al+6/Xa76ENCWFhYUsPj5e4d8laVxSqZS1b9+eLVmyhO+i8Kp///5s5syZDZJ3Td9zVWIIr9dEd+/ejTlz5mDr1q3w9vbG+vXr4efnh8TERJiZmVVJ//vvv2PhwoXYsWMHevTogdu3b3Mj3tatW8el69Spk8IN83WZ1aYxVEzUQS1hQkh9evDgAY4ePYo+ffqguLgY33//Pe7du4cPP/yQ76Lx4vnz54iKikJUVJTCbUxNEa/Rad26dZgyZQomTpwIANi6dSvCw8OxY8cOLFy4sEr6s2fP4u233+a+WHZ2dhgzZgw3Q0sFdXX1JjntWxJ3OZpGRhNC6o9QKERoaCjmzZsHxhg6d+6MY8eOoWPHjnwXjRceHh54/vw5vvnmGzg7O/NdnBrxFoRLSkpw5coVLFq0iNsmFArh6+vLdey/qkePHvj1119x8eJFeHl5ITk5GQcPHqwyFdmdO3dgZWUFTU1N+Pj4ICQkBDY2NtWWpbi4WGGKs7y8vDc8u6oqL9xA9wgTQupT27ZtER0dzXcxmozGHqH+JngLwllZWZBKpdwUaBXMzc1x69Ytpcd8+OGHyMrKQs+ePcEYQ1lZGaZNm4bFixdzaby9vREaGgpnZ2ekpqZixYoV6NWrF27cuAFdXV2l+YaEhGDFihX1d3JKPKKFGwghhLyiWY2OjoqKwtdff40ffvgBV69exb59+xAeHo4vv/ySSzN48GC89957cHNzg5+fHw4ePIjs7Gzs2bOn2nwXLVqEnJwc7hEfH1/vZa+YrtLOWJsWbiCEEAKAx5awiYkJ1NTUFO5LA4D09PRq+3OXLl2KcePG4eOPPwYAuLq6oqCgAFOnTsUXX3wBobDqbwoDAwO0b98ed+/erbYsYrEYYrGYe52bm/s6p1QjbrpKM+oPJoQQIsdbS1gkEsHT01Nh1hOZTIbIyEj4+PgoPebFixdVAm3FPWmsminc8vPzkZSUBEtLy3oq+eupmK6ynQn1BxNCCJHjdXT0nDlzEBgYiG7dusHLywvr169HQUEBN1p6/PjxsLa25m7UDggIwLp16+Dh4QFvb2/cvXsXS5cuRUBAABeM582bh4CAANja2uLJkycIDg6Gmpoat2IJX5IyaGQ0IYQQRbwG4dGjRyMzMxPLli1DWloaunTpgsOHD3ODtVJSUhRavkuWLIFAIMCSJUvw+PFjmJqaIiAgQOki00+fPoWpqSl69uyJ8+fPw9TUtNHPrzKuJUxBmBBCSDkBq+46biv26NEjtG3bFg8fPkSbNm3eOL+cF6VwX3kUAHBjhR90aN5o0oIVFRXh3r17sLe3r3HaxJaqb9++6NKlC9avXw9APp/B7NmzFdbIfZVAIMD+/fvfeHrF+sqH1K6m77kqMaRZjY5uriov3EABmJCmKSAgAP7+/kr3nT59GgKBANeuXVM530uXLmHq1KlvWjwFy5cvR5cuXapsT01NxeDBg+v1vUjDoiDcCGjhBkKavsmTJyMiIgKPHj2qsm/nzp3o1q0b3NzcVM7X1NQUEomkPopYKwsLC4U7PVqL2tZvbsooCDcCmjOakKbvnXfegampKUJDQxW25+fnY+/evZg8eTKePn2KMWPGwNraGhKJBK6urti1a1eN+drZ2XGXpgH5jH69e/eGpqYmXFxcEBERUeWYBQsWoH379pBIJHBwcMDSpUtRWloKAAgNDcWKFSsQFxcHgUAAgUDAlVkgEODAgQNcPtevX0f//v2hpaUFY2NjTJ06Ffn5+dz+CRMmYPjw4VizZg0sLS1hbGyMGTNmcO+lTFJSEoYNGwZzc3Po6Oige/fuCnP1A/JZCBcsWIC2bdtCLBbD0dGRWwIRAG7evIl33nkHenp60NXVRa9evZCUlARAfjn/1Uv3w4cPx4QJExTq9Msvv8T48eOhp6fHXWmoqd4q/N///R+6d+8OTU1NmJiYYMSIEQCAlStXonPnzlXOt0uXLli6dGm19fGmKAg3goqJOmhQFmn1SgpUf0jLXh4vLZNvKy2sW74qUFdXx/jx4xEaGqpwy+PevXshlUoxZswYFBUVwdPTE+Hh4bhx4wamTp2KcePG4eLFi3V6D5lMhn/9618QiUS4cOECtm7digULFlRJp6uri9DQUMTHx2PDhg3Ytm0bvvvuOwDyAa1z585Fp06dkJqaitTUVIwePbpKHgUFBfDz84OhoSEuXbqEvXv34tixYwgKClJId+LECSQlJeHEiRP46aefEBoaWuWHSGX5+fkYMmQIIiMjERMTA39/fwQEBCAlJYVLM378eOzatQsbN25EQkIC/vvf/0JHR/7/3+PHj9G7d2+IxWIcP34cV65cwaRJk1BWVlbdWyq1Zs0auLu7IyYmhguSNdUbAISHh2PEiBEYMmQIYmJiEBkZCS8vLwDApEmTkJCQgEuXLnHpY2JicO3aNe6OnQZRv4s7tQz1vZSh79ooZrvgHxaVmFEv+RHSlNW4lGGwnuqPG/teHn9jn3zbjiGK+X5jr/xYFSUkJDAA7MSJE9y2Xr16sY8++qjaY4YOHcrmzp3Lve7Tpw+bNWsW99rW1pZ99913jDHGjhw5wtTV1dnjx4+5/YcOHWIA2P79+6t9j2+//ZZ5enpyr4ODg5m7u3uVdJXz+fHHH5mhoSHLz8/n9oeHhzOhUMjS0tIYY4wFBgYyW1tbVlZWxqV577332OjRo6stizKdOnVimzZtYowxlpiYyACwiIgIpWkXLVrE7O3tWUlJidL9r9YfY4wNGzaMBQYGcq9tbW3Z8OHDay3Xq/Xm4+PDxo4dW236wYMHs+nTp3OvZ86cyfr27as0bX0tZUgt4QYmX7jhBQDAgSbqIKRJ69ChA3r06IEdO3YAAO7evYvTp09j8uTJAACpVIovv/wSrq6uMDIygo6ODo4cOaLQCqxJQkIC2rZtCysrK26bssmJdu/ejbfffhsWFhbQ0dHBkiVL6vweld/L3d0d2tov/995++23IZPJkJiYyG3r1KkTN88CAFhaWiIjI6PafPPz8zFv3jx07NgRBgYG0NHRQUJCAle+2NhYqKmpoU+fPkqPj42NRa9evaChoaHS+byqW7duVbbVVm+xsbEYMGBAtXlOmTIFu3btQlFREUpKSvD7779j0qRJb1TO2tBQ3Qb26HkhSqQyiNWFsDaghRtIK7f4ierHqFUaaNQhQJ6H4JX2w+zrb1auSiZPnoyZM2di8+bN2LlzJ9q1a8cFlG+//RYbNmzA+vXr4erqCm1tbcyePbteBwadO3cOY8eOxYoVK+Dn5wd9fX2EhYVh7dq19fYelb0aDAUCAWQyWbXp582bh4iICKxZswaOjo7Q0tLCqFGjuDrQ0qr5/7na9guFwiozICrro6784wKoW73V9t4BAQEQi8XYv38/RCIRSktLMWrUqBqPeVPUEm5gFZN02JvQwg2EQKSt+kOtUltBTV2+TUOrbvm+hvfffx9CoRC///47fv75Z0yaNAkCgfzfbnR0NIYNG4aPPvoI7u7ucHBwwO3bt+ucd8eOHfHw4UOkpqZy286fP6+Q5uzZs7C1tcUXX3yBbt26wcnJCQ8ePFA8XZEIUqm01veKi4tDQcHLvvHo6GgIhcI3WmM3OjoaEyZMwIgRI+Dq6goLCwuFpQNdXV0hk8lw8uRJpce7ubnh9OnT1Q7+MjU1VagfqVSKGzdu1FquutSbm5ubwlTJr1JXV0dgYCB27tyJnTt34oMPPqg1cL8pCsINjFu4gQZlEdIs6OjoYPTo0Vi0aBFSU1MVRuU6OTkhIiICZ8+eRUJCAj755JMqi9DUxNfXF+3bt0dgYCDi4uJw+vRpfPHFFwppnJyckJKSgrCwMCQlJWHjxo3Yv3+/Qho7Ozvcu3cPsbGxyMrKUlgPvcLYsWOhqamJwMBA3LhxAydOnMDMmTMxbty4KkvIqsLJyQn79u1DbGws4uLi8OGHHyq0nO3s7BAYGIhJkybhwIEDuHfvHqKioriV7IKCgpCbm4sPPvgAly9fxp07d/DLL79wl8j79++P8PBwhIeH49atW5g+fTqys7PrVK7a6i04OBi7du1CcHAwEhIScP36dXzzzTcKaT7++GMcP34chw8fbvBL0QAF4Qb3cmQ09QcT0lxMnjwZz58/h5+fn0L/7ZIlS9C1a1f4+fmhb9++sLCwUGl2KqFQiP3796OwsBBeXl74+OOPFabdBYB3330Xn3/+OYKCgtClSxecPXu2yi0yI0eOhL+/P/r16wdTU1Olt0lJJBIcOXIEz549Q/fu3TFq1CgMGDAA33//vWqV8Yp169bB0NAQPXr0QEBAAPz8/NC1a1eFNFu2bMGoUaPw6aefokOHDpgyZQrXIjc2Nsbx48eRn5+PPn36wNPTE9u2beMui0+aNAmBgYEYP348+vTpAwcHB/Tr16/WctWl3vr27Yu9e/fi77//RpcuXdC/f/8qI9udnJzQo0cPdOjQAd7e3m9SVXVC01YqUZ/TVr7/33O4eO8Z1o/uguEe1vVUQkKartY+bSVp3hhjcHJywqeffoo5c+ZUm66+pq2kgVkNjGbLIoSQ5iEzMxNhYWFIS0tr2HuDK6Eg3IByCkuRlS/vq6ElDAkhpGkzMzODiYkJfvzxRxgaGjbKe1IQbkAV01Wa64lp4QZCCGni+OidpYFZDYi7FG1CrWBCCCFVURBuQNzIaDPqDyaEEFIVBeEGRC1h0prRjRekJauv7zcF4QaUREsYklao4n7PFy9e8FwSQhpOxTSdlefdfh00WqgBbfrQA3cz8uHexoDvohDSaNTU1GBgYMAtAiCRSLhpHwlpCWQyGTIzMyGRSKCu/mZhlIJwA+pgoYcOFnp8F4OQRmdhYQEANa7GQ0hzJhQKYWNj88Y/MCkIE0LqnUAggKWlJczMzKqdqJ+Q5kwkEkEofPMeXQrChJAGo6am9sZ9ZoS0ZDQwixBCCOEJBWFCCCGEJxSECSGEEJ5Qn7ASFQtUp6am8lwSQgghzU1F7KiIJTWhIKxEeno6AMDLy4vnkhBCCGmu0tPTYWNjU2MaAaO55aooKytDTEwMzM3N32gIel5eHlxcXBAfHw9dXd16LGHLQXVUO6qj2lEd1Y7qqHb1VUcymQzp6enw8PCodTIPCsINKDc3F/r6+sjJyYGeHk3aoQzVUe2ojmpHdVQ7qqPa8VFHNDCLEEII4QkFYUIIIYQnFIQbkFgsRnBwMMRiMd9FabKojmpHdVQ7qqPaUR3Vjo86oj5hQgghhCfUEiaEEEJ4QkGYEEII4QkFYUIIIYQnFIQb0ObNm2FnZwdNTU14e3vj4sWLfBeJN6dOnUJAQACsrKwgEAhw4MABhf2MMSxbtgyWlpbQ0tKCr68v7ty5w09heRASEoLu3btDV1cXZmZmGD58OBITExXSFBUVYcaMGTA2NoaOjg5GjhzJze7WGmzZsgVubm7Q09ODnp4efHx8cOjQIW5/a68fZVatWgWBQIDZs2dz21p7PS1fvhwCgUDh0aFDB25/Y9cPBeEGsnv3bsyZMwfBwcG4evUq3N3d4efnh4yMDL6LxouCggK4u7tj8+bNSvevXr0aGzduxNatW3HhwgVoa2vDz88PRUVFjVxSfpw8eRIzZszA+fPnERERgdLSUgwaNAgFBQVcms8//xz/93//h7179+LkyZN48uQJ/vWvf/FY6sbVpk0brFq1CleuXMHly5fRv39/DBs2DDdv3gRA9fOqS5cu4b///S/c3NwUtlM9AZ06dUJqair3OHPmDLev0euHkQbh5eXFZsyYwb2WSqXMysqKhYSE8FiqpgEA279/P/daJpMxCwsL9u2333LbsrOzmVgsZrt27eKhhPzLyMhgANjJkycZY/L60NDQYHv37uXSJCQkMADs3LlzfBWTd4aGhmz79u1UP6/Iy8tjTk5OLCIigvXp04fNmjWLMUbfI8YYCw4OZu7u7kr38VE/1BJuACUlJbhy5Qp8fX25bUKhEL6+vjh37hyPJWua7t27h7S0NIX60tfXh7e3d6utr5ycHACAkZERAODKlSsoLS1VqKMOHTrAxsamVdaRVCpFWFgYCgoK4OPjQ/XzihkzZmDo0KEK9QHQ96jCnTt3YGVlBQcHB4wdOxYpKSkA+KkfWkWpAWRlZUEqlcLc3Fxhu7m5OW7dusVTqZqutLQ0AFBaXxX7WhOZTIbZs2fj7bffRufOnQHI60gkEsHAwEAhbWuro+vXr8PHxwdFRUXQ0dHB/v374eLigtjYWKqfcmFhYbh69SouXbpUZR99jwBvb2+EhobC2dkZqampWLFiBXr16oUbN27wUj8UhAlpYmbMmIEbN24o9FMROWdnZ8TGxiInJwd//PEHAgMDcfLkSb6L1WQ8fPgQs2bNQkREBDQ1NfkuTpM0ePBg7rmbmxu8vb1ha2uLPXv2QEtLq9HLQ5ejG4CJiQnU1NSqjKhLT0+HhYUFT6VquirqhOoLCAoKwj///IMTJ06gTZs23HYLCwuUlJQgOztbIX1rqyORSARHR0d4enoiJCQE7u7u2LBhA9VPuStXriAjIwNdu3aFuro61NXVcfLkSWzcuBHq6uowNzenenqFgYEB2rdvj7t37/LyPaIg3ABEIhE8PT0RGRnJbZPJZIiMjISPjw+PJWua7O3tYWFhoVBfubm5uHDhQqupL8YYgoKCsH//fhw/fhz29vYK+z09PaGhoaFQR4mJiUhJSWk1daSMTCZDcXEx1U+5AQMG4Pr164iNjeUe3bp1w9ixY7nnVE+K8vPzkZSUBEtLS36+Rw0y3IuwsLAwJhaLWWhoKIuPj2dTp05lBgYGLC0tje+i8SIvL4/FxMSwmJgYBoCtW7eOxcTEsAcPHjDGGFu1ahUzMDBgf/31F7t27RobNmwYs7e3Z4WFhTyXvHFMnz6d6evrs6ioKJaamso9Xrx4waWZNm0as7GxYcePH2eXL19mPj4+zMfHh8dSN66FCxeykydPsnv37rFr166xhQsXMoFAwI4ePcoYo/qpTuXR0YxRPc2dO5dFRUWxe/fusejoaObr68tMTExYRkYGY6zx64eCcAPatGkTs7GxYSKRiHl5ebHz58/zXSTenDhxggGo8ggMDGSMyW9TWrp0KTM3N2disZgNGDCAJSYm8lvoRqSsbgCwnTt3cmkKCwvZp59+ygwNDZlEImEjRoxgqamp/BW6kU2aNInZ2toykUjETE1N2YABA7gAzBjVT3VeDcKtvZ5Gjx7NLC0tmUgkYtbW1mz06NHs7t273P7Grh9aRYkQQgjhCfUJE0IIITyhIEwIIYTwhIIwIYQQwhMKwoQQQghPKAgTQgghPKEgTAghhPCEgjAhhBDCEwrChBBCCE8oCBNCGoxAIMCBAwf4LgYhTRYFYUJaqAkTJkAgEFR5+Pv78100Qkg5Wk+YkBbM398fO3fuVNgmFot5Kg0h5FXUEiakBROLxbCwsFB4GBoaApBfKt6yZQsGDx4MLS0tODg44I8//lA4/vr16+jfvz+0tLRgbGyMqVOnIj8/XyHNjh070KlTJ4jFYlhaWiIoKEhhf1ZWFkaMGAGJRAInJyf8/fff3L7nz59j7NixMDU1hZaWFpycnKr8aCCkJaMgTEgrtnTpUowcORJxcXEYO3YsPvjgAyQkJAAACgoK4OfnB0NDQ1y6dAl79+7FsWPHFILsli1bMGPGDEydOhXXr1/H33//DUdHR4X3WLFiBd5//31cu3YNQ4YMwdixY/Hs2TPu/ePj43Ho0CEkJCRgy5YtMDExabwKIIRvDbY+EyGEV4GBgUxNTY1pa2srPL766ivGmHz5xGnTpikc4+3tzaZPn84YY+zHH39khoaGLD8/n9sfHh7OhEIhty62lZUV++KLL6otAwC2ZMkS7nV+fj4DwA4dOsQYYywgIIBNnDixfk6YkGaI+oQJacH69euHLVu2KGwzMjLinvv4+Cjs8/HxQWxsLAAgISEB7u7u0NbW5va//fbbkMlkSExMhEAgwJMnTzBgwIAay+Dm5sY919bWhp6eHjIyMgAA06dPx8iRI3H16lUMGjQIw4cPR48ePV7rXAlpjigIE9KCaWtrV7k8XF+0tLTqlE5DQ0PhtUAggEwmAwAMHjwYDx48wMGDBxEREYEBAwZgxowZWLNmTb2Xl5CmiPqECWnFzp8/X+V1x44dAQAdO3ZEXFwcCgoKuP3R0dEQCoVwdnaGrq4u7OzsEBkZ+UZlMDU1RWBgIH799VesX78eP/744xvlR0hzQi1hQlqw4uJipKWlKWxTV1fnBj/t3bsX3bp1Q8+ePfHbb7/h4sWL+N///gcAGDt2LIKDgxEYGIjly5cjMzMTM2fOxLhx42Bubg4AWL58OaZNmwYzMzMMHjwYeXl5iI6OxsyZM+tUvmXLlsHT0xOdOnVCcXEx/vnnH+5HACGtAQVhQlqww4cPw9LSUmGbs7Mzbt26BUA+cjksLAyffvopLC0tsWvXLri4uAAAJBIJjhw5glmzZqF79+6QSCQYOXIk1q1bx+UVGBiIoqIifPfdd5g3bx5MTEwwatSoOpdPJBJh0aJFuH//PrS0tNCrVy+EhYXVw5kT0jwIGGOM70IQQhqfQCDA/v37MXz4cL6LQkirRX3ChBBCCE8oCBNCCCE8oT5hQlop6okihH/UEiaEEEJ4QkGYEEII4QkFYUIIIYQnFIQJIYQQnlAQJoQQQnhCQZgQQgjhCQVhQgghhCcUhAkhhBCeUBAmhBBCePL/H30K4M5dIa4AAAAASUVORK5CYII=",
      "text/plain": [
       "<Figure size 500x300 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# plot accuracy \n",
    "epochs_tensor = torch.linspace(0, num_epochs, len(train_accs))\n",
    "examples_seen_tensor = torch.linspace(0, examples_seen, len(train_accs))\n",
    "plot_values(epochs_tensor, examples_seen_tensor, train_accs, val_accs, label=\"accuracy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "id": "7d8ecf93-eb35-4601-aeef-c335f0e6a5ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training accuracy: 100.00%\n",
      "Validation accuracy: 98.66%\n",
      "Test accuracy: 97.00%\n"
     ]
    }
   ],
   "source": [
    "# Print dataset accuracies\n",
    "train_accuracy = calc_accuracy_loader(train_loader, model, device)\n",
    "val_accuracy = calc_accuracy_loader(val_loader, model, device)\n",
    "test_accuracy = calc_accuracy_loader(test_loader, model, device)\n",
    "print(f\"Training accuracy: {train_accuracy*100:.2f}%\")\n",
    "print(f\"Validation accuracy: {val_accuracy*100:.2f}%\")\n",
    "print(f\"Test accuracy: {test_accuracy*100:.2f}%\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6bcacd4f-2e13-49e4-be80-efc50a68e18d",
   "metadata": {},
   "source": [
    "## Using LLM as a spam classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "id": "82117073-29a5-4f7b-b6d9-1cdd615ceb4e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "spam\n"
     ]
    }
   ],
   "source": [
    "def classify_review(text, model, tokenizer, device, max_length=None, pad_token_id=50256):\n",
    "    model.eval()\n",
    "    input_ids = tokenizer.encode(text) # list of ints\n",
    "    # pos_emb: (context_length,embed_dim)=(1024,768)\n",
    "    supported_context_length = model.pos_emb.weight.shape[0] # 1024\n",
    "    input_ids = input_ids[:min(max_length, supported_context_length)]\n",
    "    # pad input to reach 103 tokens length\n",
    "    input_ids += [pad_token_id] * (max_length-len(input_ids))\n",
    "    input_tensor = torch.tensor(\n",
    "        input_ids, device=device\n",
    "    ).unsqueeze(0) # (1,103)\n",
    "    with torch.no_grad():\n",
    "        logits = model(input_tensor)[:,-1,:] # (1,103,2)=>(1,2)\n",
    "    predicted_label = torch.argmax(logits, dim=-1).item()\n",
    "\n",
    "    return \"spam\" if predicted_label == 1 else \"not spam\"\n",
    "\n",
    "text_1 = \"You are a winner you have been specially selected to receive $1000 cash or $2000 award.\"\n",
    "print(classify_review(text_1, model, tokenizer, device, max_length=train_dataset.max_length)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "id": "d182e691-98f9-432f-8443-41821cc15787",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "not spam\n"
     ]
    }
   ],
   "source": [
    "text_2 = \"Hey, just wanted to check if we're still on for dinner tonight? Let me know!\"\n",
    "print(classify_review(text_2, model, tokenizer, device, max_length=train_dataset.max_length))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d45757b-d0bf-4128-95a5-0376ea527524",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
